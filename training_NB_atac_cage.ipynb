{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab370951-f6d4-4a16-858a-58d08b64c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import src.aformer_atac_cage as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "from src.optimizers import *\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_atac_cage as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d333d7e-5e30-4865-b2a0-f04221ade9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:16:50.196138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-25 16:16:50.196211: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-25 16:16:50.196254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:16:50.503944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 16:16:50.611735: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://localhost:42303\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-5')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    #options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83ee30b-bf73-4231-aff5-6cfd183387d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://picard-testing-176520/genformer_atac_rampage_globalacc_conv/preprocessed\n",
      "gs://picard-testing-176520/genformer_atac_rampage_globalacc_conv_TSS/preprocessed\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created train + val\n"
     ]
    }
   ],
   "source": [
    "g = tf.random.Generator.from_seed(datetime.now().timestamp())\n",
    "with strategy.scope():\n",
    "    \n",
    "    data_tr,data_val,data_val_TSS = training_utils.return_distributed_iterators(\"gs://picard-testing-176520/genformer_atac_rampage_globalacc_conv/preprocessed\",\n",
    "                                                                                \"gs://picard-testing-176520/genformer_atac_rampage_globalacc_conv_TSS/preprocessed\",\n",
    "                                                                               GLOBAL_BATCH_SIZE,\n",
    "                                                                               196608,\n",
    "                                                                               10, \n",
    "                                                                               1536,\n",
    "                                                                               320,\n",
    "                                                                               128,\n",
    "                                                                               8,\n",
    "                                                                               50,\n",
    "                                                                               strategy,\n",
    "                                                                               options,\n",
    "                                                                                True,\n",
    "                                                                                0.00,\n",
    "                                                                               g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f9d938-b205-4fc0-a3ab-5d2d438329b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.initializers.initializers_v2.Constant object at 0x7f870935d210>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    inits = training_utils.get_initializers_enformer_performer(\"gs://picard-testing-176520/enformer_performer_pretrain_atac_mean/models/enformer_performer_pretrain_atac_mean_EP_full_dataset__196k_load_init-True_freeze-False_LR1-1e-06_LR2-0.0001_T-4_F-1536_D-0.4_2023-02-24_16:27:50/iteration_16\",\n",
    "                                                               4,\n",
    "                                                               stable_variant=False)\n",
    "    #inits = training_utils.get_initializers_enformer_conv(\"/home/jupyter/dev/BE_CD69_paper_2022/enformer_fine_tuning/checkpoint/sonnet_weights\")\n",
    "    model = aformer.aformer(kernel_transformation = 'relu_kernel_transformation',\n",
    "                            dropout_rate = 0.05,\n",
    "                            pointwise_dropout_rate=0.05,\n",
    "                            input_length = 196608,\n",
    "                            output_length = 1536,\n",
    "                            final_output_length = 896,\n",
    "                             num_heads = 8,\n",
    "                             numerical_stabilizer = 0.001,\n",
    "                             nb_random_features = 256,\n",
    "                             hidden_size = 1552,\n",
    "                             num_transformer_layers = 4,\n",
    "                             d_model = 1552,\n",
    "                             norm=True,\n",
    "                             dim = 194, \n",
    "                            BN_momentum=0.90,\n",
    "                             max_seq_length = 1536,\n",
    "                             use_rot_emb = True,\n",
    "                            fc_dropout=0.25,\n",
    "                             use_mask_pos = False, \n",
    "                             normalize = True,\n",
    "                             seed = 3,\n",
    "                             load_init=True,\n",
    "                            stable_variant=False,\n",
    "                             inits=inits,\n",
    "                            freeze_conv_layers=False,\n",
    "                            predict_masked_atac_bool=True,\n",
    "                            use_global_acc=False,\n",
    "                            inits_type='enformer_performer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d8558d-6d83-4558-b8b5-db84a59e282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    optimizer1 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-06,\n",
    "        epsilon= 1.0e-14,\n",
    "        weight_decay= 1.0e-08,\n",
    "        rectify=True\n",
    "    )\n",
    "    optimizer2 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-04,\n",
    "        epsilon= 1.0e-14,\n",
    "        weight_decay= 1.0e-0,\n",
    "        rectify=True\n",
    "    )\n",
    "    optimizer3 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-04,\n",
    "        epsilon= 1.0e-14,\n",
    "        weight_decay= 0.0,\n",
    "        rectify=True\n",
    "    )\n",
    "    \n",
    "    optimizers_in=optimizer1,optimizer2,optimizer3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7839285-c85c-4bf9-9ca0-d8cd3ef7f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    train_step_masked_atac,train_step, \\\n",
    "        val_step_masked_atac,val_step, \\\n",
    "            val_step_TSS_masked_atac, val_step_TSS, \\\n",
    "                build_step, metric_dict = training_utils.return_train_val_functions(model,\n",
    "                                                                                     500,\n",
    "                                                                                     150,\n",
    "                                                                                     150,\n",
    "                                                                                      optimizers_in,\n",
    "                                                                                      strategy,\n",
    "                                                                                      metric_dict,\n",
    "                                                                                      GLOBAL_BATCH_SIZE,\n",
    "                                                                                        5.0,\n",
    "                                                                                      0.8,\n",
    "                                                                                    'poisson')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d7eb8-7b92-44d8-92a7-2759896f8c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params: tf.Tensor(132783826, shape=(), dtype=int32)\n",
      "hg_train_loss: 0.0034167897\n",
      "hg_val_loss: 0.012973947\n",
      "hg_val_loss_CAGE: 0.0040297396\n",
      "hg_val_loss_ATAC: 0.00894421\n",
      "hg_val_cage_pearson: [0.33343163]\n",
      "hg_val_cage_R2: [0.0725764]\n",
      "cell spec corr: 0.6574068744900461\n",
      "gene_spec_corr:0.40471770426476605\n",
      "completed epoch 1\n",
      "duration(mins): 12.527095707257589\n",
      "patience counter at: 0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "with strategy.scope():\n",
    "    def sum_log(x):\n",
    "        return np.log10(1.0 + np.nansum(x))\n",
    "    \n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, 10):\n",
    "        start = time.time()\n",
    "        if epoch_i == 1:\n",
    "            build_step(data_val)\n",
    "            total_params = 0\n",
    "            for k in model.trainable_variables:\n",
    "                var = k.values[0]\n",
    "                total_params += tf.size(var)\n",
    "            print('total params: ' + str(total_params))\n",
    "\n",
    "        train_step_masked_atac(data_tr)\n",
    "\n",
    "        print('hg_train_loss: ' + str(metric_dict['train_loss'].result().numpy()))\n",
    "        \n",
    "        val_step_masked_atac(data_val)\n",
    "\n",
    "        val_losses.append(metric_dict['val_loss'].result().numpy())\n",
    "        print('hg_val_loss: ' + str(metric_dict['val_loss'].result().numpy()))\n",
    "        print('hg_val_loss_CAGE: ' + str(metric_dict['val_loss_CAGE'].result().numpy()))\n",
    "        print('hg_val_loss_ATAC: ' + str(metric_dict['val_loss_ATAC'].result().numpy()))\n",
    "        print('hg_val_cage_pearson: ' + str(metric_dict['CAGE_PearsonR'].result()['PearsonR'].numpy()))\n",
    "        print('hg_val_cage_R2: ' + str(metric_dict['CAGE_R2'].result()['R2'].numpy()))\n",
    "        \n",
    "        #print('hg_val_atac_pearson: ' + str(metric_dict['ATAC_PearsonR'].result()['PearsonR'].numpy()))\n",
    "        #print('hg_val_atac_R2: ' + str(metric_dict['ATAC_R2'].result()['R2'].numpy()))\n",
    "        \n",
    "        \n",
    "        #print('hg_val_atac_baseline_pearson: ' + str(metric_dict['ATAC_PearsonR_baseline'].result()['PearsonR'].numpy()))\n",
    "        #print('hg_val_atac_baseline_R2: ' + str(metric_dict['ATAC_R2_baseline'].result()['R2'].numpy()))\n",
    "        \n",
    "        val_step_TSS_masked_atac(data_val_TSS)\n",
    "        \n",
    "        y_trues = metric_dict['corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['corr_stats'].result()['gene_map'].numpy()\n",
    "\n",
    "\n",
    "        figures, corrs_overall = training_utils.make_plots(y_trues,\n",
    "                                           y_preds, \n",
    "                                           cell_types, \n",
    "                                           gene_map)\n",
    "        \n",
    "        cell_spec,gene_spec = corrs_overall\n",
    "        \n",
    "        print('cell spec corr: ' + str(cell_spec))\n",
    "        print('gene_spec_corr:' + str(gene_spec))\n",
    "        \n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('duration(mins): ' + str(duration))\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "        \n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515e254-a5c0-4647-8f69-e57922160d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stem_res_conv._layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5230c78-07c2-41b0-b792-26954f2ec48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.final_pointwise_conv.layers[0].momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e07a2cf8-b806-4a6e-8d6f-0ed7eeadfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.final_pointwise_conv.layers[0].momentum = 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5557bf81-4afa-4000-a754-f9e53c730968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.final_pointwise_conv.layers[0].momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44daedaa-27cc-4603-8260-e922a1289699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_tr(serialized_example,\n",
    "                   input_length,\n",
    "                   max_shift,\n",
    "                   output_length,\n",
    "                   crop_size,\n",
    "                   output_res,\n",
    "                   predict_masked_atac_bool,\n",
    "                   atac_mask_dropout,\n",
    "                   g):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "        'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "        'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "        'cage': tf.io.FixedLenFeature([], tf.string),\n",
    "        'processed_gene_token': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    ### stochastic sequence shift and gaussian noise\n",
    "\n",
    "\n",
    "    rev_comp = tf.math.round(g.uniform([], 0, 1))\n",
    "\n",
    "    shift = g.uniform(shape=(),\n",
    "                      minval=0,\n",
    "                      maxval=max_shift,\n",
    "                      dtype=tf.int32)\n",
    "\n",
    "    for k in range(max_shift):\n",
    "        if k == shift:\n",
    "            interval_end = input_length + k\n",
    "            seq_shift = k\n",
    "        else:\n",
    "            seq_shift=0\n",
    "    \n",
    "    input_seq_length = input_length + max_shift\n",
    "\n",
    "\n",
    "    data = tf.io.parse_example(serialized_example, feature_map)\n",
    "    #sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "    #                             seq_shift,input_length))\n",
    "    \n",
    "    atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [output_length,1])\n",
    "    #atac = atac + tf.math.abs(g.normal(atac.shape,\n",
    "    #                                           mean=0.0,\n",
    "    #                                           stddev=0.05,\n",
    "    #                                           dtype=tf.float32))\n",
    "    \n",
    "    masked_atac=tf.nn.experimental.stateless_dropout(atac, \n",
    "                                                     rate=atac_mask_dropout, \n",
    "                                                     seed=[0,seq_shift]) / (1. / (1.0 -atac_mask_dropout))\n",
    "    \n",
    "    cage = tf.ensure_shape(tf.io.parse_tensor(data['cage'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [output_length - 2*crop_size,1])\n",
    "\n",
    "        \n",
    "    gene_token= tf.io.parse_tensor(data['processed_gene_token'],\n",
    "                                   out_type=tf.int32)\n",
    "        \n",
    "    if predict_masked_atac_bool:\n",
    "        atac_out = tf.slice(atac,\n",
    "                            [crop_size,0],\n",
    "                            [output_length-2*crop_size,-1])\n",
    "        target = tf.concat([atac_out,cage],axis=1)\n",
    "        \n",
    "    if predict_masked_atac_bool:\n",
    "    \n",
    "        return {#'sequence': tf.ensure_shape(sequence,\n",
    "                #                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(masked_atac,\n",
    "                                          [output_length,1]),\n",
    "                'gene_token':gene_token,\n",
    "                'target': tf.ensure_shape(target,\n",
    "                                          [output_length-crop_size*2,2])}\n",
    "    else:\n",
    "        return {#'sequence': tf.ensure_shape(sequence,\n",
    "                #                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(atac,\n",
    "                                          [output_length,1]),\n",
    "                'gene_token':gene_token}\n",
    "                #'target': tf.ensure_shape(cage,\n",
    "                #                          [output_length-crop_size*2,1])}\n",
    "    \n",
    "    \n",
    "g = tf.random.Generator.from_seed(datetime.now().timestamp())\n",
    "dataset = tf.data.TFRecordDataset(\"gs://picard-testing-176520/genformer_atac_rampage_globalacc_conv_TSS/valid/HG_A375.tfr\",\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=4)\n",
    "\n",
    "dataset = dataset.map(lambda record: deserialize_tr(record,\n",
    "                                                    196618,\n",
    "                                                    10,\n",
    "                                                    1536,\n",
    "                                                    320,\n",
    "                                                    128,\n",
    "                                                    False,\n",
    "                                                    0.0,\n",
    "                                                    g),\n",
    "                      deterministic=True,\n",
    "                      num_parallel_calls=4)\n",
    "        \n",
    "    \n",
    "dataset1 = tf.data.TFRecordDataset(\"gs://picard-testing-176520/enformer_atac_rampage_paired_basenji_tss/valid/HG_A375.tfr\",\n",
    "                                  compression_type='ZLIB',\n",
    "                                  num_parallel_reads=4)\n",
    "\n",
    "dataset1 = dataset1.map(lambda record: deserialize_tr(record,\n",
    "                                                    196618,\n",
    "                                                    10,\n",
    "                                                    1536,\n",
    "                                                    320,\n",
    "                                                    128,\n",
    "                                                    False,\n",
    "                                                    0.0,\n",
    "                                                    g),\n",
    "                      deterministic=True,\n",
    "                      num_parallel_calls=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b3c0f9-334f-4d38-a8c2-adb9aec16080",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "496f3b32-ec1c-414b-a9fd-d5960bbca98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atac': <tf.Tensor: shape=(1536, 1), dtype=float32, numpy=\n",
       " array([[0.45809558],\n",
       "        [0.47703928],\n",
       "        [1.2499237 ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]], dtype=float32)>,\n",
       " 'gene_token': <tf.Tensor: shape=(), dtype=int32, numpy=6870>}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95415017-6601-4cdc-9b2d-d2fd786d7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iter(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dc8672c-b49f-4fdc-9046-6c8ab54e238a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atac': <tf.Tensor: shape=(1536, 1), dtype=float32, numpy=\n",
       " array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.72191423],\n",
       "        ...,\n",
       "        [5.7844844 ],\n",
       "        [1.4600831 ],\n",
       "        [0.        ]], dtype=float32)>,\n",
       " 'gene_token': <tf.Tensor: shape=(), dtype=int32, numpy=15816>}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8242a-8b87-41a0-a720-d521b9a45a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
