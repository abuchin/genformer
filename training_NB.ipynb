{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1493709-0d03-4a45-a40e-7c3d5b5d171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 16:05:44.638595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-24 16:05:44.638655: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "## custom modules\n",
    "import src.genformer1 as genformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "import src.optimizers as optimizers\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f9a0ee-f9a1-4164-87c9-2573c3a32519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 16:05:47.136830: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-24 16:05:47.136890: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-24 16:05:47.136918: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 16:05:47.427442: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-24 16:05:47.439223: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.44.184.242:8470}\n",
      "2022-05-24 16:05:47.439282: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:37197}\n",
      "2022-05-24 16:05:47.455539: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.44.184.242:8470}\n",
      "2022-05-24 16:05:47.455591: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:37197}\n",
      "2022-05-24 16:05:47.456484: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:37197\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "try: # detect TPUs\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect('node-11') # TPU detection\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    \n",
    "mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "    options.deterministic=False\n",
    "    options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 4\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07af4201-f32c-4498-9222-5afaa700939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    train_steps=400\n",
    "    warmup_steps=10\n",
    "    val_steps= 200 ### 5562\n",
    "    num_epochs=40\n",
    "    lr_base=0.0005\n",
    "    warmup_lr=1.0e-04\n",
    "\n",
    "    data_it_tr_list = []\n",
    "    data_it_val_list = []\n",
    "\n",
    "    ### create dataset iterators\n",
    "    heads_dict = {}\n",
    "    orgs = [\"hg\",\"mm\"]\n",
    "    for k, org in enumerate(orgs):\n",
    "        heads_dict[org] = int(k)\n",
    "    data_dict_tr, data_dict_val = training_utils.return_distributed_iterators(heads_dict,\n",
    "                                                                              \"gs://picard-testing-176520/TSS_164k_82kstride_ATAC_scaled_blacklist0.10_4096outputres_logTPM/preprocessed\",\n",
    "                                                                              GLOBAL_BATCH_SIZE,\n",
    "                                                                              163840,\n",
    "                                                                              20,\n",
    "                                                                              8,\n",
    "                                                                              num_epochs,\n",
    "                                                                              strategy,\n",
    "                                                                              options)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b203efe-03bb-45d0-817e-92395a3a9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = genformer.genformer(kernel_transformation=\"softmax_kernel_transformation\",\n",
    "                                dropout_rate=0.35,\n",
    "                                final_out_length=20,\n",
    "                                num_heads=4,\n",
    "                                numerical_stabilizer=0.0000001,\n",
    "                                nb_random_features=256,\n",
    "                                hidden_size=96,\n",
    "                                d_model=96,\n",
    "                                dim=24,\n",
    "                                max_seq_length = 4096,\n",
    "                                rel_pos_bins=192,\n",
    "                                widening = 2, ## ratio between first and second dense layer units in transformer block\n",
    "                                conv_filter_size=15,\n",
    "                                transformer_depth=3,\n",
    "                                momentum=0.90,\n",
    "                                channels_list=[24,24,24,24,48,48,48,48,96,96,96],\n",
    "                                kernel_regularizer=0.001,\n",
    "                                heads_dict=heads_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89adb1ff-39b9-4758-ab2d-7dd4bafeff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    optimizer = tfa.optimizers.AdaBelief(learning_rate=0.0007,\n",
    "                                         weight_decay=1.0e-04,\n",
    "                                         warmup_proportion=0.1,\n",
    "                                         epsilon=1e-10,\n",
    "                                         rectify=True,\n",
    "                                         min_lr=1.0e-06,\n",
    "                                         total_steps=4000)\n",
    "    optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=6, slow_step_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac09f24e-14a5-41fd-a042-89bd35bf6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    train_step, val_step, metric_dict = training_utils.return_train_val_functions_hg_mm(model,\n",
    "                                                                                        optimizer,\n",
    "                                                                                        strategy,\n",
    "                                                                                        metric_dict, \n",
    "                                                                                        train_steps,\n",
    "                                                                                        val_steps,\n",
    "                                                                                        GLOBAL_BATCH_SIZE,\n",
    "                                                                                        10.0) # last is gradient clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8b3deb-12aa-4065-a191-bca9d9de19b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg_train_loss: 0.2905462\n",
      "hg_val_loss: 0.21245228\n",
      "hg_val_pearson: 0.4399658\n",
      "hg_val_R2: -0.54906523\n",
      "mm_train_loss: 0.2603066\n",
      "mm_val_loss: 0.20253713\n",
      "mm_val_pearson: 0.52819574\n",
      "mm_val_R2: -0.4305017\n",
      "completed epoch 1\n",
      "duration(mins): 3.4589707295099896\n",
      "patience counter at: 0\n",
      "hg_train_loss: 0.22135647\n",
      "hg_val_loss: 0.17066729\n",
      "hg_val_pearson: 0.43111372\n",
      "hg_val_R2: -1.223413\n",
      "mm_train_loss: 0.18181624\n",
      "mm_val_loss: 0.17141688\n",
      "mm_val_pearson: 0.5020159\n",
      "mm_val_R2: -0.8994833\n",
      "completed epoch 2\n",
      "duration(mins): 1.2804106871287029\n",
      "patience counter at: 0\n",
      "hg_train_loss: 0.22719371\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32660/326211845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  data_dict_val['mm'])\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hg_val_loss: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hg_val_pearson: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg_corr_stats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pearsonR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, num_epochs):\n",
    "        start = time.time()\n",
    "        train_step(data_dict_tr['hg'],\n",
    "                   data_dict_tr['mm'])\n",
    "        print('hg_train_loss: ' + str(metric_dict['hg_tr'].result().numpy()))\n",
    "        val_step(data_dict_val['hg'],\n",
    "                 data_dict_val['mm'])\n",
    "\n",
    "        val_losses.append(metric_dict['hg_val'].result().numpy())\n",
    "        print('hg_val_loss: ' + str(metric_dict['hg_val'].result().numpy()))\n",
    "        print('hg_val_pearson: ' + str(metric_dict['hg_corr_stats'].result()['pearsonR'].numpy()))\n",
    "        print('hg_val_R2: ' + str(metric_dict['hg_corr_stats'].result()['R2'].numpy()))\n",
    "        \n",
    "        print('mm_train_loss: ' + str(metric_dict['mm_tr'].result().numpy()))\n",
    "\n",
    "        print('mm_val_loss: ' + str(metric_dict['mm_val'].result().numpy()))\n",
    "        print('mm_val_pearson: ' + str(metric_dict['mm_corr_stats'].result()['pearsonR'].numpy()))\n",
    "        print('mm_val_R2: ' + str(metric_dict['mm_corr_stats'].result()['R2'].numpy()))\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('duration(mins): ' + str(duration))\n",
    "    \n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "\n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d482356-48e1-4cea-af40-1458b7a1c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"gs://picard-testing-176520/genformer_test_model22/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4acad2-9860-476d-968d-e37eb038ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def one_hot(sequence):\n",
    "        '''\n",
    "        convert input string tensor to one hot encoded\n",
    "        will replace all N character with 0 0 0 0\n",
    "        '''\n",
    "        vocabulary = tf.constant(['A', 'T', 'C', 'G', 'N'])\n",
    "        mapping = tf.constant([0, 1, 2, 3, 4])\n",
    "\n",
    "        init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                                   values=mapping)\n",
    "        table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "        input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "        out = tf.one_hot(table.lookup(input_characters), \n",
    "                          depth = 4, \n",
    "                          dtype=tf.float32)\n",
    "        return out\n",
    "\n",
    "    def return_dataset_validation(gcs_path,\n",
    "                       organism,\n",
    "                       batch,\n",
    "                       input_length,\n",
    "                       output_length_pre,\n",
    "                       output_length,\n",
    "                        crop_size,\n",
    "                       options,\n",
    "                       num_parallel,\n",
    "                       num_epoch):\n",
    "        \"\"\"\n",
    "        return a tf dataset object for given gcs path\n",
    "        \"\"\"\n",
    "        list_files = (tf.io.gfile.glob(os.path.join(gcs_path)))\n",
    "        random.shuffle(list_files)\n",
    "        files = tf.data.Dataset.list_files(list_files)\n",
    "\n",
    "        #dataset = files.interleave(lambda x: tf.data.TFRecordDataset(x, \n",
    "        ##                                                             compression_type='ZLIB',\n",
    "        #                                                             buffer_size=10000000,\n",
    "        #                                                             num_parallel_reads=num_parallel),\n",
    "        #                            num_parallel_calls=num_parallel,\n",
    "        #                            deterministic=False,\n",
    "        #                            cycle_length=num_parallel,\n",
    "        #                            block_length=1)\n",
    "        dataset = tf.data.TFRecordDataset(files,\n",
    "                                          compression_type='ZLIB',\n",
    "                                          buffer_size=10000000,\n",
    "                                          num_parallel_reads=num_parallel)\n",
    "        dataset = dataset.with_options(options)\n",
    "\n",
    "        dataset = dataset.map(lambda record: deserialize_validation(record,\n",
    "                                                         input_length,\n",
    "                                                         output_length,\n",
    "                                                                    output_length_pre,\n",
    "                                                                    crop_size,\n",
    "                                                                   output_length),\n",
    "                              deterministic=False,\n",
    "                          num_parallel_calls=num_parallel)\n",
    "\n",
    "\n",
    "        return dataset.repeat(num_epoch).batch(batch,drop_remainder=True).prefetch(1)\n",
    "    def deserialize_validation(serialized_example, input_length, output_length,\n",
    "                           output_length_pre,crop_size,out_length):\n",
    "        \"\"\"\n",
    "        Deserialize bytes stored in TFRecordFile.\n",
    "        \"\"\"\n",
    "        feature_map = {\n",
    "            'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "            'atac': tf.io.FixedLenFeature([],tf.string),\n",
    "            'target': tf.io.FixedLenFeature([],tf.string),\n",
    "            'tss_tokens': tf.io.FixedLenFeature([],tf.string),\n",
    "            'interval': tf.io.FixedLenFeature([],tf.string),\n",
    "            'genes_list': tf.io.FixedLenFeature([],tf.string),\n",
    "            'name': tf.io.FixedLenFeature([],tf.string)\n",
    "        }\n",
    "\n",
    "        data = tf.io.parse_example(serialized_example, feature_map)\n",
    "\n",
    "        return {\n",
    "            'inputs': tf.concat([tf.expand_dims(tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                                                                  out_type=tf.float32), \n",
    "                                                               [input_length,]), 1),\n",
    "                                        one_hot(data['sequence'])], axis=1),\n",
    "            'target': tf.slice(tf.ensure_shape(tf.io.parse_tensor(data['target'],\n",
    "                                                                          out_type=tf.float32), \n",
    "                                                       [output_length_pre,]),\n",
    "                               [crop_size],\n",
    "                               [out_length]),\n",
    "            'tss_tokens': tf.slice(tf.ensure_shape(tf.io.parse_tensor(data['tss_tokens'],\n",
    "                                                                      out_type=tf.int32),\n",
    "                                                   [output_length_pre,]),\n",
    "                                   [crop_size],\n",
    "                                   [out_length]),\n",
    "            'genes_list': data['genes_list'],\n",
    "            'interval': data['interval'],\n",
    "            'name': data['name']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6602b39-d3f8-4106-bcb1-42a93fd08da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    val_dataset_aorta =  return_dataset_validation(\"gs://picard-testing-176520/TSS_164k_82kstride_ATAC_scaled_blacklist0.10_4096outputres_logTPM/val/HG_AORTA_THORACIC_ENCDO451RUA_U.tfr\",\n",
    "                                                             \"hg\",\n",
    "                                                             1,\n",
    "                                                             163840,\n",
    "                                                             40,\n",
    "                                                             20,\n",
    "                                                             10,\n",
    "                                                             options,\n",
    "                                                             8,\n",
    "                                                             5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3410b3ff-dc29-4f1d-bd96-37c98d2536f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    File \"/home/jupyter/dev/genformer/src/genformer1.py\", line 230, in predict_on_batch  *\n        for head, head_module in self.heads.items()},att_matrices]\n\n    NameError: name 'training' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31024/3044868813.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_aorta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mout_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    File \"/home/jupyter/dev/genformer/src/genformer1.py\", line 230, in predict_on_batch  *\n        for head, head_module in self.heads.items()},att_matrices]\n\n    NameError: name 'training' is not defined\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    iter_aorta = iter(val_dataset_aorta)\n",
    "    test_input = next(iter_aorta)\n",
    "    out = model(test_input['inputs'])\n",
    "    out_batch = model.predict_on_batch(test_input['inputs'])['hg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494235cf-0dd9-403c-905d-011987bf1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    out = model.predict_on_batch(test_input['inputs'])['hg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17791e9-9729-4bbe-896c-7022bd467ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hg': <tf.Tensor: shape=(1, 20, 1), dtype=float32, numpy=\n",
       "  array([[[5.6010513e-03],\n",
       "          [7.6227435e-03],\n",
       "          [1.5766260e-01],\n",
       "          [1.2055477e-02],\n",
       "          [5.0479658e-03],\n",
       "          [5.4840301e-03],\n",
       "          [2.3615076e-03],\n",
       "          [3.1567132e-03],\n",
       "          [3.5262683e-03],\n",
       "          [3.9211889e-03],\n",
       "          [6.2533105e-03],\n",
       "          [1.3970923e-02],\n",
       "          [3.7721510e+00],\n",
       "          [4.8352489e+00],\n",
       "          [1.2712023e-02],\n",
       "          [3.4852293e-03],\n",
       "          [4.0731211e-03],\n",
       "          [4.2883577e-03],\n",
       "          [1.2541253e-02],\n",
       "          [3.2841098e-03]]], dtype=float32)>,\n",
       "  'mm': <tf.Tensor: shape=(1, 20, 1), dtype=float32, numpy=\n",
       "  array([[[1.0669067e-03],\n",
       "          [7.4587570e-04],\n",
       "          [4.4114627e-02],\n",
       "          [1.5640138e-03],\n",
       "          [8.3047088e-04],\n",
       "          [5.0095594e-03],\n",
       "          [1.1610591e-03],\n",
       "          [9.7850629e-04],\n",
       "          [1.9842002e-03],\n",
       "          [1.3435120e-03],\n",
       "          [3.7330305e-03],\n",
       "          [4.2950823e-03],\n",
       "          [3.0885413e+00],\n",
       "          [4.0418315e+00],\n",
       "          [7.9838972e-04],\n",
       "          [9.1402925e-04],\n",
       "          [1.1116082e-03],\n",
       "          [1.8001973e-03],\n",
       "          [2.9998461e-03],\n",
       "          [9.1705064e-04]]], dtype=float32)>},\n",
       " {'layer_0': (<tf.Tensor: shape=(1, 4, 256, 40), dtype=bfloat16, numpy=\n",
       "   array([[[[0.000371933, 1.05239e-07, 1.53482e-06, ..., 4.38094e-06,\n",
       "             1.67638e-06, 3.74392e-07],\n",
       "            [7.51019e-06, 6.48201e-07, 6.92904e-07, ..., 2.40803e-05,\n",
       "             2.22027e-06, 1.29342e-05],\n",
       "            [5.81741e-05, 1.64658e-06, 4.29153e-06, ..., 4.61936e-06,\n",
       "             3.93391e-06, 2.05822e-07],\n",
       "            ...,\n",
       "            [3.09944e-05, 3.50177e-07, 4.17233e-05, ..., 2.26498e-06,\n",
       "             3.8147e-05, 1.67638e-06],\n",
       "            [9.17912e-06, 5.32717e-07, 8.19564e-08, ..., 4.64916e-05,\n",
       "             1.50502e-06, 2.55182e-07],\n",
       "            [0.00778198, 8.9407e-08, 7.82311e-08, ..., 7.33882e-07,\n",
       "             7.03149e-08, 7.21775e-08]],\n",
       "   \n",
       "           [[1.93119e-05, 4.41447e-07, 3.74392e-07, ..., 1.45435e-05,\n",
       "             9.83477e-06, 3.66941e-07],\n",
       "            [5.05447e-05, 1.60933e-06, 6.44475e-07, ..., 6.22123e-07,\n",
       "             2.66731e-06, 3.66941e-07],\n",
       "            [4.02331e-06, 9.26666e-08, 1.59256e-07, ..., 6.10948e-06,\n",
       "             9.90927e-07, 1.43424e-07],\n",
       "            ...,\n",
       "            [0.000107765, 6.59376e-07, 9.95398e-06, ..., 1.00583e-06,\n",
       "             3.14713e-05, 9.31323e-07],\n",
       "            [0.000686646, 2.75671e-07, 4.58956e-06, ..., 1.05053e-06,\n",
       "             0.000778198, 1.68569e-07],\n",
       "            [7.67708e-05, 7.86036e-07, 2.19792e-07, ..., 0.000191689,\n",
       "             1.13994e-06, 4.06057e-07]],\n",
       "   \n",
       "           [[1.4782e-05, 8.14907e-08, 2.18861e-07, ..., 2.14204e-07,\n",
       "             2.84985e-07, 6.51926e-08],\n",
       "            [0.000797272, 1.2666e-07, 3.08454e-06, ..., 1.24797e-07,\n",
       "             3.78117e-07, 1.546e-07],\n",
       "            [0.000103951, 2.84612e-06, 1.20997e-05, ..., 5.1856e-06,\n",
       "             2.40281e-07, 2.04146e-06],\n",
       "            ...,\n",
       "            [3.05474e-06, 1.00117e-07, 1.73599e-06, ..., 2.70605e-05,\n",
       "             9.29832e-05, 8.801e-08],\n",
       "            [1.06636e-07, 6.56582e-08, 1.81049e-06, ..., 5.45382e-06,\n",
       "             4.74975e-07, 4.74975e-07],\n",
       "            [2.68221e-07, 1.20141e-07, 9.77889e-08, ..., 3.65078e-07,\n",
       "             2.73809e-07, 8.6613e-08]],\n",
       "   \n",
       "           [[2.77758e-05, 1.99676e-06, 4.4331e-07, ..., 7.15256e-06,\n",
       "             2.71946e-07, 7.00355e-07],\n",
       "            [0.000170708, 6.42613e-08, 2.80142e-05, ..., 1.3113e-05,\n",
       "             2.30074e-05, 1.2666e-07],\n",
       "            [2.02656e-06, 6.33299e-08, 1.25729e-07, ..., 3.79086e-05,\n",
       "             5.63264e-06, 6.51926e-08],\n",
       "            ...,\n",
       "            [4.8399e-05, 7.05719e-05, 3.60608e-06, ..., 2.15136e-07,\n",
       "             1.16825e-05, 1.49012e-07],\n",
       "            [1.83582e-05, 7.72998e-08, 3.56138e-06, ..., 8.56817e-08,\n",
       "             1.19209e-07, 6.61239e-08],\n",
       "            [1.65701e-05, 1.29342e-05, 1.42492e-07, ..., 0.000125885,\n",
       "             9.17353e-08, 7.15256e-06]]]], dtype=bfloat16)>,\n",
       "   <tf.Tensor: shape=(1, 40, 4, 256), dtype=bfloat16, numpy=\n",
       "   array([[[[0.000103474, 4.52995e-06, 6.91414e-05, ..., 0.00021553,\n",
       "             0.000175476, 0.0019989],\n",
       "            [1.95205e-06, 9.68575e-07, 1.43424e-07, ..., 2.44379e-06,\n",
       "             2.89679e-05, 7.26432e-08],\n",
       "            [4.91738e-07, 2.10479e-07, 1.8999e-07, ..., 9.05991e-05,\n",
       "             0.00180054, 1.89245e-06],\n",
       "            [6.00815e-05, 4.45843e-05, 1.35303e-05, ..., 0.000579834,\n",
       "             0.000219345, 0.000115395]],\n",
       "   \n",
       "           [[2.47955e-05, 1.75089e-07, 2.73809e-07, ..., 8.04663e-06,\n",
       "             2.30968e-06, 0.00037384],\n",
       "            [1.18613e-05, 3.19481e-05, 0.00346375, ..., 1.16229e-05,\n",
       "             0.000349045, 2.45571e-05],\n",
       "            [4.86374e-05, 0.00108337, 6.34193e-05, ..., 1.44541e-06,\n",
       "             4.57764e-05, 3.99351e-06],\n",
       "            [8.39233e-05, 6.4075e-06, 6.81877e-05, ..., 0.000364304,\n",
       "             1.71661e-05, 2.71797e-05]],\n",
       "   \n",
       "           [[3.93018e-07, 4.56348e-07, 5.55068e-07, ..., 4.94719e-06,\n",
       "             3.9041e-06, 2.13385e-05],\n",
       "            [5.60284e-05, 0.00075531, 0.000953674, ..., 8.58307e-06,\n",
       "             1.15633e-05, 2.81259e-07],\n",
       "            [0.000179291, 0.000108242, 5.96046e-05, ..., 1.80304e-06,\n",
       "             6.96182e-05, 0.0018692],\n",
       "            [8.34465e-05, 1.21593e-05, 3.45707e-05, ..., 0.000339508,\n",
       "             4.41447e-07, 3.30806e-06]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1.59442e-06, 2.15769e-05, 1.16229e-06, ..., 9.59635e-06,\n",
       "             1.6205e-07, 4.1008e-05],\n",
       "            [4.14848e-05, 6.29574e-07, 8.3074e-07, ..., 0.000743866,\n",
       "             1.2219e-05, 3.50475e-05],\n",
       "            [0.000193596, 0.000184059, 0.000915527, ..., 0.000207901,\n",
       "             9.67979e-05, 8.46386e-06],\n",
       "            [0.000135422, 1.66893e-05, 0.000118256, ..., 3.91006e-05,\n",
       "             5.73695e-07, 2.21729e-05]],\n",
       "   \n",
       "           [[0.000816345, 8.82149e-05, 2.26498e-05, ..., 0.000153542,\n",
       "             9.17912e-06, 0.00357056],\n",
       "            [0.000150681, 0.000549316, 2.57492e-05, ..., 0.000421524,\n",
       "             1.44243e-05, 1.60933e-05],\n",
       "            [8.9407e-07, 7.7486e-06, 1.87159e-05, ..., 1.92225e-06,\n",
       "             0.000341415, 4.85778e-06],\n",
       "            [2.90871e-05, 1.25915e-06, 6.79865e-08, ..., 3.57628e-05,\n",
       "             2.63453e-05, 0.000480652]],\n",
       "   \n",
       "           [[1.63317e-05, 6.04987e-06, 8.64267e-07, ..., 7.45058e-07,\n",
       "             1.82539e-06, 0.000220299],\n",
       "            [5.00679e-05, 3.33786e-05, 2.55182e-07, ..., 3.9041e-06,\n",
       "             0.000858307, 5.8651e-05],\n",
       "            [5.06639e-07, 8.12113e-07, 1.02073e-06, ..., 6.84522e-08,\n",
       "             7.09295e-06, 7.40401e-08],\n",
       "            [8.82149e-06, 4.88758e-06, 1.15018e-07, ..., 3.95775e-05,\n",
       "             1.50204e-05, 3.15905e-06]]]], dtype=bfloat16)>),\n",
       "  'layer_1': (<tf.Tensor: shape=(1, 4, 256, 40), dtype=bfloat16, numpy=\n",
       "   array([[[[7.26432e-08, 9.05991e-06, 2.23517e-06, ..., 1.80006e-05,\n",
       "             7.07805e-07, 2.86847e-07],\n",
       "            [4.97699e-06, 2.00272e-05, 1.2964e-06, ..., 6.49691e-06,\n",
       "             7.59959e-07, 2.5481e-06],\n",
       "            [1.08778e-06, 4.57764e-05, 2.58908e-07, ..., 1.2517e-05,\n",
       "             1.95205e-06, 2.45571e-05],\n",
       "            ...,\n",
       "            [2.39909e-06, 0.000224113, 6.1512e-05, ..., 1.74046e-05,\n",
       "             0.00177002, 3.31402e-05],\n",
       "            [3.93018e-07, 1.4782e-05, 4.32134e-07, ..., 6.3777e-06,\n",
       "             2.87294e-05, 2.92063e-06],\n",
       "            [1.40667e-05, 9.82285e-05, 6.34789e-06, ..., 2.64645e-05,\n",
       "             1.38283e-05, 6.67572e-06]],\n",
       "   \n",
       "           [[4.48897e-07, 0.000740051, 6.76513e-06, ..., 4.17233e-06,\n",
       "             2.09808e-05, 1.09673e-05],\n",
       "            [1.35042e-07, 2.89083e-06, 7.54371e-08, ..., 8.28877e-08,\n",
       "             1.79559e-06, 7.71135e-07],\n",
       "            [4.58211e-07, 7.689e-06, 1.51806e-07, ..., 6.75209e-08,\n",
       "             2.41399e-06, 7.97212e-07],\n",
       "            ...,\n",
       "            [6.34789e-06, 3.71933e-05, 4.44055e-06, ..., 1.08033e-07,\n",
       "             7.24196e-06, 6.58631e-06],\n",
       "            [2.6226e-05, 0.000226021, 2.5183e-06, ..., 5.126e-06,\n",
       "             3.69549e-05, 3.91006e-05],\n",
       "            [9.46224e-07, 4.673e-05, 6.29574e-07, ..., 8.42847e-08,\n",
       "             5.91278e-05, 5.69224e-06]],\n",
       "   \n",
       "           [[1.22935e-06, 0.00135803, 7.56979e-06, ..., 2.0396e-07,\n",
       "             9.05991e-05, 1.2368e-06],\n",
       "            [2.45869e-07, 1.63913e-07, 3.02792e-05, ..., 3.21865e-05,\n",
       "             8.22544e-06, 1.45286e-07],\n",
       "            [7.12462e-08, 8.46386e-06, 1.2368e-06, ..., 3.65078e-06,\n",
       "             3.20375e-06, 1.27591e-07],\n",
       "            ...,\n",
       "            [7.96281e-08, 0.000155449, 8.58307e-06, ..., 1.2517e-05,\n",
       "             0.000143051, 2.71201e-06],\n",
       "            [2.08616e-07, 1.81049e-06, 2.84985e-07, ..., 8.67993e-07,\n",
       "             4.76837e-06, 9.17353e-08],\n",
       "            [9.73232e-08, 5.39422e-06, 4.63799e-07, ..., 1.95205e-06,\n",
       "             3.02494e-06, 4.91738e-07]],\n",
       "   \n",
       "           [[1.82539e-07, 6.93835e-08, 2.5928e-06, ..., 4.67896e-06,\n",
       "             7.36117e-06, 2.30037e-07],\n",
       "            [7.03149e-08, 8.5216e-08, 5.06639e-06, ..., 1.85333e-07,\n",
       "             2.70084e-07, 1.30385e-07],\n",
       "            [2.10479e-07, 1.83471e-07, 8.45641e-07, ..., 9.17353e-08,\n",
       "             1.28895e-06, 2.29105e-07],\n",
       "            ...,\n",
       "            [1.44355e-07, 1.4782e-05, 2.12193e-05, ..., 1.39326e-06,\n",
       "             1.3411e-05, 1.14087e-07],\n",
       "            [7.26432e-07, 6.55651e-07, 1.26362e-05, ..., 1.49012e-07,\n",
       "             3.08454e-06, 7.15256e-07],\n",
       "            [6.79865e-08, 1.08965e-07, 6.74278e-07, ..., 1.40071e-06,\n",
       "             1.39326e-06, 1.74157e-07]]]], dtype=bfloat16)>,\n",
       "   <tf.Tensor: shape=(1, 40, 4, 256), dtype=bfloat16, numpy=\n",
       "   array([[[[1.56164e-05, 1.75834e-06, 2.13273e-07, ..., 3.7998e-06,\n",
       "             6.07222e-07, 1.46776e-06],\n",
       "            [1.03116e-05, 7.51019e-06, 7.15256e-05, ..., 2.41995e-05,\n",
       "             2.05822e-07, 6.96182e-05],\n",
       "            [4.29153e-05, 0.000366211, 0.000392914, ..., 4.26769e-05,\n",
       "             1.51992e-05, 0.000602722],\n",
       "            [4.74975e-07, 2.47732e-07, 1.3113e-06, ..., 2.29478e-06,\n",
       "             7.91624e-08, 8.97795e-07]],\n",
       "   \n",
       "           [[3.74317e-05, 6.49691e-06, 1.80304e-06, ..., 0.000268936,\n",
       "             1.73599e-06, 2.64645e-05],\n",
       "            [5.60284e-05, 5.57899e-05, 8.39233e-05, ..., 1.546e-07,\n",
       "             1.19209e-07, 2.09808e-05],\n",
       "            [4.84288e-07, 3.05176e-05, 1.54227e-06, ..., 2.05636e-06,\n",
       "             7.53999e-06, 1.27554e-05],\n",
       "            [8.10251e-08, 9.61125e-07, 2.62633e-07, ..., 2.31266e-05,\n",
       "             1.89058e-07, 6.03497e-07]],\n",
       "   \n",
       "           [[8.34465e-05, 1.84774e-06, 3.11062e-07, ..., 3.18885e-06,\n",
       "             1.72853e-06, 1.56462e-06],\n",
       "            [5.53131e-05, 3.65078e-06, 6.24657e-05, ..., 3.99351e-06,\n",
       "             1.32248e-07, 1.52588e-05],\n",
       "            [1.2666e-06, 8.53539e-05, 9.83477e-06, ..., 1.61678e-06,\n",
       "             0.000144005, 3.53158e-06],\n",
       "            [8.71718e-07, 3.51667e-06, 1.59442e-06, ..., 6.97374e-06,\n",
       "             4.76837e-07, 6.92904e-07]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1.62125e-05, 0.000130653, 5.40167e-07, ..., 1.60933e-06,\n",
       "             6.29425e-05, 1.27591e-07],\n",
       "            [7.80821e-06, 7.98702e-06, 5.45382e-06, ..., 1.95503e-05,\n",
       "             7.80821e-06, 1.27554e-05],\n",
       "            [2.55182e-07, 0.00268555, 4.91738e-07, ..., 8.98726e-08,\n",
       "             2.59876e-05, 1.07102e-07],\n",
       "            [2.58908e-07, 5.51343e-07, 2.07126e-06, ..., 0.000239372,\n",
       "             1.2219e-06, 9.29832e-06]],\n",
       "   \n",
       "           [[9.9659e-05, 9.58443e-05, 3.38554e-05, ..., 4.55976e-06,\n",
       "             2.77758e-05, 1.70469e-05],\n",
       "            [0.000473022, 1.4782e-05, 5.42402e-06, ..., 2.11596e-06,\n",
       "             2.3365e-05, 6.55651e-06],\n",
       "            [3.11062e-07, 0.000274658, 8.71718e-07, ..., 1.89245e-06,\n",
       "             2.68221e-06, 6.28829e-06],\n",
       "            [8.14907e-08, 5.96046e-07, 3.11062e-07, ..., 3.48687e-06,\n",
       "             6.56582e-08, 6.84522e-08]],\n",
       "   \n",
       "           [[4.95911e-05, 1.77324e-06, 6.61239e-08, ..., 2.08616e-07,\n",
       "             2.39909e-06, 1.39698e-07],\n",
       "            [4.29153e-05, 5.21541e-06, 4.36306e-05, ..., 1.36495e-05,\n",
       "             7.39098e-06, 1.18017e-05],\n",
       "            [7.15256e-07, 0.00154877, 3.66569e-06, ..., 2.27243e-07,\n",
       "             0.000270844, 9.71556e-06],\n",
       "            [7.68341e-08, 1.9744e-07, 9.83477e-07, ..., 0.000229836,\n",
       "             2.90573e-07, 1.24425e-06]]]], dtype=bfloat16)>),\n",
       "  'layer_2': (<tf.Tensor: shape=(1, 4, 256, 40), dtype=bfloat16, numpy=\n",
       "   array([[[[1.0198e-07, 6.70552e-08, 8.9407e-08, ..., 1.36904e-07,\n",
       "             1.00117e-07, 2.12342e-07],\n",
       "            [6.42613e-08, 6.47269e-08, 6.75209e-08, ..., 6.65896e-08,\n",
       "             6.93835e-08, 1.47149e-07],\n",
       "            [3.65078e-06, 1.68383e-06, 4.97699e-06, ..., 5.88894e-05,\n",
       "             1.78814e-06, 5.54323e-06],\n",
       "            ...,\n",
       "            [1.70432e-07, 2.07685e-07, 8.47504e-08, ..., 1.41561e-06,\n",
       "             7.77654e-08, 1.52737e-07],\n",
       "            [6.37956e-08, 7.31088e-08, 1.45286e-07, ..., 2.5481e-06,\n",
       "             1.02911e-07, 6.18398e-07],\n",
       "            [1.49012e-07, 3.8743e-07, 5.99772e-07, ..., 7.09295e-06,\n",
       "             2.99886e-07, 8.76188e-06]],\n",
       "   \n",
       "           [[7.82311e-08, 2.08616e-07, 1.06171e-07, ..., 9.11951e-06,\n",
       "             6.61239e-08, 1.3411e-05],\n",
       "            [2.08616e-07, 4.73112e-07, 2.64496e-07, ..., 2.78652e-06,\n",
       "             5.7742e-07, 1.79745e-07],\n",
       "            [4.00469e-07, 3.72529e-06, 3.61353e-07, ..., 2.77758e-05,\n",
       "             3.70666e-07, 7.56979e-06],\n",
       "            ...,\n",
       "            [3.18512e-07, 1.63168e-06, 1.08033e-06, ..., 4.98295e-05,\n",
       "             1.885e-06, 3.35276e-06],\n",
       "            [2.86102e-06, 1.18464e-06, 5.66244e-07, ..., 9.48906e-05,\n",
       "             5.51343e-07, 3.02792e-05],\n",
       "            [1.15484e-07, 9.26666e-08, 5.58794e-07, ..., 7.48783e-07,\n",
       "             8.15839e-07, 8.61473e-08]],\n",
       "   \n",
       "           [[3.14787e-07, 7.31088e-08, 1.82539e-06, ..., 6.7234e-05,\n",
       "             4.04194e-07, 1.09673e-05],\n",
       "            [6.42613e-08, 6.70552e-08, 8.5216e-08, ..., 5.1558e-06,\n",
       "             8.05594e-08, 1.49943e-07],\n",
       "            [1.08499e-07, 1.04774e-07, 1.83471e-07, ..., 1.80304e-06,\n",
       "             1.73226e-07, 4.58211e-07],\n",
       "            ...,\n",
       "            [1.03563e-06, 9.83477e-07, 2.71946e-07, ..., 5.21541e-06,\n",
       "             4.00469e-07, 3.72529e-06],\n",
       "            [9.45292e-08, 6.84522e-08, 9.68575e-08, ..., 1.95578e-07,\n",
       "             6.47269e-08, 7.17118e-08],\n",
       "            [1.75834e-06, 2.70084e-07, 1.08499e-07, ..., 2.84612e-06,\n",
       "             4.88013e-07, 1.43796e-06]],\n",
       "   \n",
       "           [[9.31323e-08, 9.0804e-08, 7.21775e-08, ..., 1.29454e-07,\n",
       "             6.61239e-08, 4.24683e-07],\n",
       "            [2.73809e-07, 1.94646e-07, 1.4063e-07, ..., 3.8743e-07,\n",
       "             2.13273e-07, 7.21216e-06],\n",
       "            [2.29478e-06, 9.31323e-07, 1.546e-07, ..., 5.55068e-07,\n",
       "             1.56462e-07, 6.22869e-06],\n",
       "            ...,\n",
       "            [3.70666e-07, 6.4075e-07, 3.44589e-07, ..., 5.03659e-06,\n",
       "             5.55068e-07, 1.43051e-06],\n",
       "            [1.60187e-07, 1.23866e-07, 1.51806e-07, ..., 1.50502e-06,\n",
       "             7.97212e-07, 7.41333e-07],\n",
       "            [7.82311e-08, 6.51926e-08, 1.29454e-07, ..., 4.4331e-07,\n",
       "             6.65896e-08, 2.77534e-07]]]], dtype=bfloat16)>,\n",
       "   <tf.Tensor: shape=(1, 40, 4, 256), dtype=bfloat16, numpy=\n",
       "   array([[[[0.000121117, 5.31673e-05, 1.30534e-05, ..., 3.99351e-06,\n",
       "             0.000189781, 1.24425e-06],\n",
       "            [4.62532e-05, 4.8399e-05, 0.000457764, ..., 0.000314713,\n",
       "             8.63075e-05, 0.000221252],\n",
       "            [1.3113e-05, 0.000236511, 0.000284195, ..., 0.00014019,\n",
       "             0.000101566, 0.0132446],\n",
       "            [5.45382e-06, 7.37607e-07, 1.78814e-07, ..., 4.67524e-07,\n",
       "             2.94298e-07, 1.49012e-07]],\n",
       "   \n",
       "           [[1.47223e-05, 4.02927e-05, 1.00583e-06, ..., 8.19564e-07,\n",
       "             2.61068e-05, 9.53674e-06],\n",
       "            [5.19753e-05, 2.82526e-05, 0.00050354, ..., 9.10759e-05,\n",
       "             1.49608e-05, 0.000205994],\n",
       "            [3.76701e-05, 0.000310898, 6.38962e-05, ..., 1.91927e-05,\n",
       "             0.000105381, 5.10216e-05],\n",
       "            [1.05053e-06, 8.9407e-06, 1.06543e-06, ..., 9.05246e-07,\n",
       "             4.99189e-07, 1.73226e-07]],\n",
       "   \n",
       "           [[1.07288e-06, 1.3262e-06, 9.87202e-08, ..., 7.35745e-08,\n",
       "             4.00543e-05, 4.13507e-07],\n",
       "            [1.86265e-06, 5.06639e-07, 2.45869e-06, ..., 7.78586e-07,\n",
       "             6.81728e-07, 8.70787e-08],\n",
       "            [3.24249e-05, 7.53403e-05, 0.000225067, ..., 3.62396e-05,\n",
       "             0.00117493, 0.000196457],\n",
       "            [9.12696e-07, 0.000103951, 3.15905e-06, ..., 3.05474e-07,\n",
       "             5.7742e-07, 4.63799e-07]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[1.08778e-06, 1.90921e-07, 1.69501e-07, ..., 2.81259e-07,\n",
       "             0.000133514, 7.15256e-07],\n",
       "            [9.0003e-06, 3.78489e-06, 0.000237465, ..., 3.83854e-05,\n",
       "             3.241e-07, 1.23866e-07],\n",
       "            [1.88351e-05, 0.000450134, 6.96182e-05, ..., 1.21444e-06,\n",
       "             5.79357e-05, 0.000125885],\n",
       "            [5.24521e-06, 1.27554e-05, 1.88351e-05, ..., 2.41399e-06,\n",
       "             1.11759e-06, 2.99513e-06]],\n",
       "   \n",
       "           [[2.36034e-05, 6.49691e-06, 6.63102e-07, ..., 2.19047e-06,\n",
       "             6.4373e-05, 1.13249e-05],\n",
       "            [6.58035e-05, 3.57628e-05, 0.000411987, ..., 0.000268936,\n",
       "             4.81606e-05, 3.0756e-05],\n",
       "            [1.97887e-05, 7.9155e-05, 6.7234e-05, ..., 0.000113964,\n",
       "             0.00082016, 2.80142e-05],\n",
       "            [4.56348e-07, 4.29153e-06, 1.68569e-07, ..., 7.26432e-08,\n",
       "             1.13621e-07, 6.56582e-08]],\n",
       "   \n",
       "           [[6.03497e-07, 4.61936e-07, 3.1665e-07, ..., 1.88127e-07,\n",
       "             3.9041e-06, 1.67638e-07],\n",
       "            [3.08454e-06, 4.63799e-07, 5.67436e-05, ..., 6.02007e-06,\n",
       "             4.32134e-06, 9.54606e-08],\n",
       "            [2.06232e-05, 8.53539e-05, 9.39369e-05, ..., 1.03712e-05,\n",
       "             1.34706e-05, 0.000740051],\n",
       "            [0.000198364, 0.000480652, 3.69549e-05, ..., 8.7738e-05,\n",
       "             6.10948e-06, 4.94719e-06]]]], dtype=bfloat16)>)}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ef0a8-4dc3-49c7-b6a3-1e0b4711a6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
