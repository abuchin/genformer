{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1493709-0d03-4a45-a40e-7c3d5b5d171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 16:05:44.638595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-24 16:05:44.638655: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "## custom modules\n",
    "import src.genformer1 as genformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "import src.optimizers as optimizers\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f9a0ee-f9a1-4164-87c9-2573c3a32519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 16:05:47.136830: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-24 16:05:47.136890: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-24 16:05:47.136918: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 16:05:47.427442: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-24 16:05:47.439223: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.44.184.242:8470}\n",
      "2022-05-24 16:05:47.439282: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:37197}\n",
      "2022-05-24 16:05:47.455539: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.44.184.242:8470}\n",
      "2022-05-24 16:05:47.455591: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:37197}\n",
      "2022-05-24 16:05:47.456484: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://localhost:37197\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "try: # detect TPUs\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect('node-11') # TPU detection\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    \n",
    "mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "    options.deterministic=False\n",
    "    options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 4\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07af4201-f32c-4498-9222-5afaa700939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    train_steps=400\n",
    "    warmup_steps=10\n",
    "    val_steps= 200 ### 5562\n",
    "    num_epochs=40\n",
    "    lr_base=0.0005\n",
    "    warmup_lr=1.0e-04\n",
    "\n",
    "    data_it_tr_list = []\n",
    "    data_it_val_list = []\n",
    "\n",
    "    ### create dataset iterators\n",
    "    heads_dict = {}\n",
    "    orgs = [\"hg\",\"mm\"]\n",
    "    for k, org in enumerate(orgs):\n",
    "        heads_dict[org] = int(k)\n",
    "    data_dict_tr, data_dict_val = training_utils.return_distributed_iterators(heads_dict,\n",
    "                                                                              \"gs://picard-testing-176520/TSS_164k_82kstride_ATAC_scaled_blacklist0.10_4096outputres_logTPM/preprocessed\",\n",
    "                                                                              GLOBAL_BATCH_SIZE,\n",
    "                                                                              163840,\n",
    "                                                                              20,\n",
    "                                                                              8,\n",
    "                                                                              num_epochs,\n",
    "                                                                              strategy,\n",
    "                                                                              options)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b203efe-03bb-45d0-817e-92395a3a9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = genformer.genformer(kernel_transformation=\"softmax_kernel_transformation\",\n",
    "                                dropout_rate=0.35,\n",
    "                                final_out_length=20,\n",
    "                                num_heads=4,\n",
    "                                numerical_stabilizer=0.0000001,\n",
    "                                nb_random_features=256,\n",
    "                                hidden_size=96,\n",
    "                                d_model=96,\n",
    "                                dim=24,\n",
    "                                max_seq_length = 4096,\n",
    "                                rel_pos_bins=192,\n",
    "                                widening = 2, ## ratio between first and second dense layer units in transformer block\n",
    "                                conv_filter_size=15,\n",
    "                                transformer_depth=3,\n",
    "                                momentum=0.90,\n",
    "                                channels_list=[24,24,24,24,48,48,48,48,96,96,96],\n",
    "                                kernel_regularizer=0.001,\n",
    "                                heads_dict=heads_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89adb1ff-39b9-4758-ab2d-7dd4bafeff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    optimizer = tfa.optimizers.AdaBelief(learning_rate=0.0007,\n",
    "                                         weight_decay=1.0e-04,\n",
    "                                         warmup_proportion=0.1,\n",
    "                                         epsilon=1e-10,\n",
    "                                         rectify=True,\n",
    "                                         min_lr=1.0e-06,\n",
    "                                         total_steps=4000)\n",
    "    optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=6, slow_step_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac09f24e-14a5-41fd-a042-89bd35bf6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    train_step, val_step, metric_dict = training_utils.return_train_val_functions_hg_mm(model,\n",
    "                                                                                        optimizer,\n",
    "                                                                                        strategy,\n",
    "                                                                                        metric_dict, \n",
    "                                                                                        train_steps,\n",
    "                                                                                        val_steps,\n",
    "                                                                                        GLOBAL_BATCH_SIZE,\n",
    "                                                                                        10.0) # last is gradient clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8b3deb-12aa-4065-a191-bca9d9de19b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_25/kernel:0', 'final_conv/conv1d_25/bias:0', 'final_conv/batch_normalization_24/gamma:0', 'final_conv/batch_normalization_24/beta:0', 'dense_7/kernel:0', 'dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['final_conv/conv1d_24/kernel:0', 'final_conv/conv1d_24/bias:0', 'final_conv/batch_normalization_23/gamma:0', 'final_conv/batch_normalization_23/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg_train_loss: 0.2905462\n",
      "hg_val_loss: 0.21245228\n",
      "hg_val_pearson: 0.4399658\n",
      "hg_val_R2: -0.54906523\n",
      "mm_train_loss: 0.2603066\n",
      "mm_val_loss: 0.20253713\n",
      "mm_val_pearson: 0.52819574\n",
      "mm_val_R2: -0.4305017\n",
      "completed epoch 1\n",
      "duration(mins): 3.4589707295099896\n",
      "patience counter at: 0\n",
      "hg_train_loss: 0.22135647\n",
      "hg_val_loss: 0.17066729\n",
      "hg_val_pearson: 0.43111372\n",
      "hg_val_R2: -1.223413\n",
      "mm_train_loss: 0.18181624\n",
      "mm_val_loss: 0.17141688\n",
      "mm_val_pearson: 0.5020159\n",
      "mm_val_R2: -0.8994833\n",
      "completed epoch 2\n",
      "duration(mins): 1.2804106871287029\n",
      "patience counter at: 0\n",
      "hg_train_loss: 0.22719371\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32660/326211845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  data_dict_val['mm'])\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hg_val_loss: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hg_val_pearson: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg_corr_stats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pearsonR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, num_epochs):\n",
    "        start = time.time()\n",
    "        train_step(data_dict_tr['hg'],\n",
    "                   data_dict_tr['mm'])\n",
    "        print('hg_train_loss: ' + str(metric_dict['hg_tr'].result().numpy()))\n",
    "        val_step(data_dict_val['hg'],\n",
    "                 data_dict_val['mm'])\n",
    "\n",
    "        val_losses.append(metric_dict['hg_val'].result().numpy())\n",
    "        print('hg_val_loss: ' + str(metric_dict['hg_val'].result().numpy()))\n",
    "        print('hg_val_pearson: ' + str(metric_dict['hg_corr_stats'].result()['pearsonR'].numpy()))\n",
    "        print('hg_val_R2: ' + str(metric_dict['hg_corr_stats'].result()['R2'].numpy()))\n",
    "        \n",
    "        print('mm_train_loss: ' + str(metric_dict['mm_tr'].result().numpy()))\n",
    "\n",
    "        print('mm_val_loss: ' + str(metric_dict['mm_val'].result().numpy()))\n",
    "        print('mm_val_pearson: ' + str(metric_dict['mm_corr_stats'].result()['pearsonR'].numpy()))\n",
    "        print('mm_val_R2: ' + str(metric_dict['mm_corr_stats'].result()['R2'].numpy()))\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('duration(mins): ' + str(duration))\n",
    "    \n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "\n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d482356-48e1-4cea-af40-1458b7a1c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"gs://picard-testing-176520/genformer_test_model22/checkpoint\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
