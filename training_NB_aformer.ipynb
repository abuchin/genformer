{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f3727c-cca0-414c-9bde-b2a3449eaac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 02:00:56.714620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 02:00:56.714667: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "## custom modules\n",
    "import src.aformer_TF_gc_separated as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "import src.optimizers as optimizers\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_aformer_TF_genecentered_separated as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554e5bc7-fc53-41ee-8dad-ee3251aab7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 02:00:58.824874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-08 02:00:58.824927: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-08 02:00:58.824952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 02:00:59.169941: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "2022-07-08 02:00:59.180778: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.23.82.178:8470}\n",
      "2022-07-08 02:00:59.180828: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:33892}\n",
      "2022-07-08 02:00:59.196622: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.23.82.178:8470}\n",
      "2022-07-08 02:00:59.196671: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:33892}\n",
      "2022-07-08 02:00:59.197507: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:33892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "try: # detect TPUs\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect('node-16') # TPU detection\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    \n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "    options.deterministic=False\n",
    "    options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 4\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c81633-2964-456b-8c46-bb7f2f292be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    train_steps=700#3200#5165 #320\n",
    "    warmup_steps=10\n",
    "    val_steps=250#3200#757 ### 5562\n",
    "    num_epochs=20\n",
    "    lr_base=0.001\n",
    "    warmup_lr=1.0e-06\n",
    "\n",
    "    data_it_tr_list = []\n",
    "    data_it_val_list = []\n",
    "\n",
    "    ### create dataset iterators\n",
    "    heads_dict = {}\n",
    "    orgs = [\"hg\"]\n",
    "    for k, org in enumerate(orgs):\n",
    "        heads_dict[org] = int(k)\n",
    "    data_dict_tr,data_dict_val = training_utils.return_distributed_iterators(heads_dict,\n",
    "                                                                             \"gs://picard-testing-176520/196k_genecentered_blacklist0.50/preprocessed\",\n",
    "                                                                              GLOBAL_BATCH_SIZE,\n",
    "                                                                              196608,\n",
    "                                                                              2000,\n",
    "                                                                              \"logTPM\",\n",
    "                                                                              4,\n",
    "                                                                              num_epochs,\n",
    "                                                                              strategy,\n",
    "                                                                              options,\n",
    "                                                                              1572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d8702c-380d-4263-8d95-566615f76ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = aformer.aformer(kernel_transformation=\"softmax_kernel_transformation\",\n",
    "                                dropout_rate=0.35,\n",
    "                                input_length=196608,\n",
    "                                num_heads=8,\n",
    "                                numerical_stabilizer=0.0000001,\n",
    "                                nb_random_features=256,\n",
    "                                hidden_size=512,\n",
    "                                d_model=512,\n",
    "                                norm=True,\n",
    "                                dim=64,\n",
    "                                max_seq_length = 1536,\n",
    "                                rel_pos_bins=128,\n",
    "                                widening = 2, ## ratio between first and second dense layer units in transformer block\n",
    "                                conv_filter_size_1=25,\n",
    "                                conv_filter_size_2=5,\n",
    "                                transformer_depth=2,\n",
    "                                momentum=0.90,\n",
    "                                channels_list=[192,192,224,224,256,256], \n",
    "                                kernel_regularizer=0.000001,\n",
    "                                TF_inputs=1572,\n",
    "                                use_mask_pos=False,\n",
    "                                use_rot_emb=True,\n",
    "                                heads_dict=heads_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19597c14-40cc-424c-9680-d75516580e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    optimizer = tfa.optimizers.AdaBelief(learning_rate=0.001,\n",
    "                                         weight_decay=5.0e-04,\n",
    "                                         warmup_proportion=0.10,\n",
    "                                         epsilon=1e-14,\n",
    "                                         rectify=True,\n",
    "                                         min_lr=0.000005,\n",
    "                                         total_steps=10000)\n",
    "    optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=6, slow_step_size=0.5)\n",
    "    \"\"\"\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate =0.001)\n",
    "    #optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=6, slow_step_size=0.5)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b410e6c0-6220-418a-b6e1-868776fc73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    train_step, val_step, metric_dict = training_utils.return_train_val_functions_hg(model,\n",
    "                                                                                     optimizer,\n",
    "                                                                                     strategy,\n",
    "                                                                                     metric_dict, \n",
    "                                                                                     train_steps,\n",
    "                                                                                     val_steps,\n",
    "                                                                                     GLOBAL_BATCH_SIZE,\n",
    "                                                                                     0.2,\n",
    "                                                                                     True) # last is uncropped length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e58bc6c-aa7a-44a8-b534-4dd4749ebf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d34035-65ed-44e7-9ad4-d6d2d402b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"while/mul:0\", shape=(), dtype=float32)\n",
      "Tensor(\"while/conv1d/Squeeze:0\", shape=(None, 196608, 1), dtype=float32)\n",
      "Tensor(\"while/sub_34:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"while/Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"while/add_4:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/jupyter/dev/aformer/training_utils_aformer_TF_genecentered_separated.py\", line 149, in train_step_hg  *\n        gradients = tape.gradient(loss, model.trainable_variables)\n\n    TypeError: Input 'y' of 'Mul' Op has type bfloat16 that does not match type float32 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1124/623007739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                    \u001b[0;31m#data_dict_tr['mm'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                    \u001b[0;31m#data_dict_tr['rm'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/aformer/training_utils_aformer_TF_genecentered_separated.py\u001b[0m in \u001b[0;36mtf__dist_train_step\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step_hg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__dist_train_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/aformer/training_utils_aformer_TF_genecentered_separated.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step_hg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/aformer/training_utils_aformer_TF_genecentered_separated.py\u001b[0m in \u001b[0;36mtrain_step_hg\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                             \u001b[0mfourier_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fourier_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                             \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_global_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/jupyter/dev/aformer/training_utils_aformer_TF_genecentered_separated.py\", line 149, in train_step_hg  *\n        gradients = tape.gradient(loss, model.trainable_variables)\n\n    TypeError: Input 'y' of 'Mul' Op has type bfloat16 that does not match type float32 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "with strategy.scope():\n",
    "    def sum_log(x):\n",
    "        return np.log10(1.0 + np.nansum(x))\n",
    "    \n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, 15):\n",
    "        start = time.time()\n",
    "        train_step(data_dict_tr['hg'])\n",
    "                   #data_dict_tr['mm'],\n",
    "                   #data_dict_tr['rm'])\n",
    "        print('hg_train_loss: ' + str(metric_dict['hg_tr'].result().numpy()))\n",
    "        val_step(data_dict_val['hg'])#,\n",
    "                 #data_dict_val['mm']\n",
    "                 #data_dict_val['rm'])\n",
    "\n",
    "        val_losses.append(metric_dict['hg_val'].result().numpy())\n",
    "        print('hg_val_loss: ' + str(metric_dict['hg_val'].result().numpy()))\n",
    "        print('hg_val_pearson: ' + str(metric_dict['hg_corr_stats'].result()['pearsonR'].numpy()))\n",
    "        print('hg_val_R2: ' + str(metric_dict['hg_corr_stats'].result()['R2'].numpy()))\n",
    "        \n",
    "        #print('hg_val_pearson_gene: ' + str(metric_dict['hg_corr_stats'].result()['feature_level_pearsonR'].numpy()))\n",
    "        #print('hg_val_R2_gene: ' + str(metric_dict['hg_corr_stats'].result()['feature_level_R2'].numpy()))\n",
    "        \n",
    "        y_trues = metric_dict['hg_corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['hg_corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['hg_corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['hg_corr_stats'].result()['gene_map'].numpy()\n",
    "\n",
    "        unique_preds = {}\n",
    "        unique_trues = {}\n",
    "        for k,x in enumerate(gene_map):\n",
    "            unique_preds[(cell_types[k],x)] = y_preds[k]\n",
    "            unique_trues[(cell_types[k],x)] = y_trues[k]\n",
    "        \n",
    "        unique_preds = dict(sorted(unique_preds.items()))\n",
    "        unique_trues = dict(sorted(unique_trues.items()))\n",
    "        \n",
    "        \n",
    "        print('overall gene correlation:', pearsonr(y_trues,\n",
    "                                                    y_preds)[0])\n",
    "        \n",
    "        \n",
    "        data = np.vstack([y_trues,y_preds])\n",
    "        kernel = stats.gaussian_kde(data)(data)\n",
    "        sns.scatterplot(\n",
    "            x=y_trues,\n",
    "            y=y_preds,\n",
    "            c=kernel,\n",
    "            cmap=\"viridis\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        ### now compute correlations across cell types\n",
    "        across_cells_preds = {}\n",
    "        across_cells_trues = {}\n",
    "        \n",
    "        for k,v in unique_preds.items():\n",
    "            cell_t,gene_name = k\n",
    "            if cell_t not in across_cells_preds.keys():\n",
    "                across_cells_preds[cell_t] = []\n",
    "                across_cells_trues[cell_t] = []\n",
    "            else:\n",
    "                across_cells_preds[cell_t].append(v)\n",
    "                across_cells_trues[cell_t].append(unique_trues[k])\n",
    "        cell_specific_corrs = []\n",
    "        for k,v in across_cells_preds.items():\n",
    "            trues = []\n",
    "            preds = []\n",
    "            for idx,x in enumerate(v):\n",
    "                preds.append(x)\n",
    "                trues.append(across_cells_trues[k][idx])\n",
    "            try: \n",
    "                cell_specific_corrs.append(pearsonr(trues, \n",
    "                                                    preds)[0])\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        sns.histplot(x=np.asarray(cell_specific_corrs), bins=50)\n",
    "        plt.show()\n",
    "        print('median_cell_crossgenes:', np.nanmedian(cell_specific_corrs))\n",
    "                \n",
    "            \n",
    "        ### now compute correlations across genes\n",
    "        across_genes_preds = {}\n",
    "        across_genes_trues = {}\n",
    "        \n",
    "        for k,v in unique_preds.items():\n",
    "            cell_t,gene_name = k\n",
    "            if gene_name not in across_genes_preds.keys():\n",
    "                across_genes_preds[gene_name] = []\n",
    "                across_genes_trues[gene_name] = []\n",
    "            else:\n",
    "                across_genes_preds[gene_name].append(v)\n",
    "                across_genes_trues[gene_name].append(unique_trues[k])\n",
    "        genes_specific_corrs = []\n",
    "        genes_specific_vars = []\n",
    "        for k,v in across_genes_preds.items():\n",
    "            trues = []\n",
    "            preds = []\n",
    "            for idx, x in enumerate(v):\n",
    "                #if len(x) > 0:\n",
    "                preds.append(x)\n",
    "                trues.append(across_genes_trues[k][idx])\n",
    "            try: \n",
    "                genes_specific_corrs.append(pearsonr(trues, \n",
    "                                                     preds)[0])\n",
    "                genes_specific_vars.append(np.var(trues))\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        sns.histplot(x=np.asarray(genes_specific_corrs), bins=50)\n",
    "        plt.show()\n",
    "        print('median_gene_crossdataset:', np.nanmedian(genes_specific_corrs))\n",
    "            \n",
    "        sns.scatterplot(\n",
    "            x=genes_specific_vars,\n",
    "            y=genes_specific_corrs)\n",
    "        plt.show()\n",
    "\n",
    "        #print('mm_train_loss: ' + str(metric_dict['mm_tr'].result().numpy()))\n",
    "\n",
    "        #print('mm_val_loss: ' + str(metric_dict['mm_val'].result().numpy()))\n",
    "        #print('mm_val_pearson: ' + str(metric_dict['mm_corr_stats'].result()['pearsonR'].numpy()))\n",
    "        #print('mm_val_R2: ' + str(metric_dict['mm_corr_stats'].result()['R2'].numpy()))\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('duration(mins): ' + str(duration))\n",
    "    \n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "\n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d71db5-6c78-4930-b4d1-d1e94a759e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db5b395-c6bb-4116-94f6-c55d1bf168d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3975/3085366239.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorr_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelation_stats_aformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hg_corr_stats'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorr_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorr_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "38,347,344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06946523-e8e1-4055-a094-89d6c57da0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsons_batch(y_true, y_pred):\n",
    "    '''\n",
    "    Helper function to compute r2 for tensors of shape (batch, length)\n",
    "    '''\n",
    "    y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
    "    y_true = tf.cast(y_true, 'float32')\n",
    "    y_pred = tf.cast(y_pred, 'float32')\n",
    "    \n",
    "    count = y_true.shape[1]\n",
    "    product_sum = tf.reduce_sum(y_true * y_pred, axis=1,keepdims=True)\n",
    "\n",
    "    sum_product = tf.reduce_sum(y_true, axis=1,keepdims=True) * tf.reduce_sum(y_pred, axis=1,keepdims=True)\n",
    "\n",
    "    numerator = product_sum - (count * tf.reduce_mean(y_true,axis=1,keepdims=True) * tf.reduce_mean(y_pred,axis=1,keepdims=True))\n",
    "    \n",
    "\n",
    "    stdev_pred = tf.math.reduce_std(y_pred, axis=1,keepdims=True)\n",
    "    stdev_true = tf.math.reduce_std(y_true, axis=1,keepdims=True)\n",
    "\n",
    "    denominator = stdev_pred * stdev_true * tf.constant(count,dtype=tf.float32)\n",
    "    \n",
    "    pearsons = (numerator / denominator)[:,0]\n",
    "    return pearsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06bd9dc-71cb-4e4f-aa91-095963574b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def r2_batch(y_true, y_pred):\n",
    "    '''\n",
    "    Helper function to compute r2 for tensors of shape (batch, length)\n",
    "    to do: check descrepancy w/ tensorflow implementation\n",
    "    '''\n",
    "    y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
    "    y_true = tf.cast(y_true, 'float32')\n",
    "    y_pred = tf.cast(y_pred, 'float32')\n",
    "    residual = tf.reduce_sum(tf.square(y_true - y_pred),axis=1,keepdims=True)\n",
    "    total = tf.reduce_sum(tf.square(y_true -  tf.reduce_mean(y_true)),axis=1,keepdims=True) + tf.constant(1.0e-06,dtype=tf.float32)\n",
    "    r2 = tf.constant(1.0,dtype=tf.float32) - residual / total\n",
    "    return r2#[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de8353f2-b50f-44c2-89a5-b6d91836f226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.94959736, -1.0186756 , -1.139405  , -0.84549165], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(r2_batch(y_true,y_pred), [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bb95825-515b-4e44-9984-52fdc9fb0487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[-0.94959736],\n",
       "       [-1.0186756 ],\n",
       "       [-1.139405  ],\n",
       "       [-0.84549165]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_batch(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d3c36c0-799f-4d8d-b5ea-8141413227ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.Variable([], shape=tf.TensorShape(None), validate_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfea0772-701c-456b-87db-1c9f79ed3479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.random.normal([1,896], 1e-02, 1.0e-07, tf.float32, seed=1)\n",
    "y_pred = tf.random.normal([1,896], 1e-02, 1.0e-07, tf.float32, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb26e138-76d8-40ff-bb04-6b7dd681947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = data_dict_tr['hg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1aa6d5e-c7d9-49c2-a6ff-1f497c0ed134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerReplica:{\n",
       "  0: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
       "  1: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.4514349]], dtype=float32)>,\n",
       "  2: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.5739595]], dtype=float32)>,\n",
       "  3: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.0050988]], dtype=float32)>,\n",
       "  4: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.954692]], dtype=float32)>,\n",
       "  5: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
       "  6: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.31018123]], dtype=float32)>,\n",
       "  7: <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.635968]], dtype=float32)>\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = next(out)\n",
    "test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a167aff3-5fd9-4443-8781-906dbe6f6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsons_batch(y_true, y_pred):\n",
    "    '''\n",
    "    Helper function to compute r2 for tensors of shape (batch, length)\n",
    "    '''\n",
    "    y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
    "    y_true = tf.cast(y_true, 'float64')\n",
    "    y_pred = tf.cast(y_pred, 'float64')\n",
    "    \n",
    "    true_sum = tf.reduce_sum(y_true,axis=1)\n",
    "    pred_sum = tf.reduce_sum(y_pred,axis=1)\n",
    "    \n",
    "    count = tf.reduce_sum(tf.ones_like(y_true),axis=1)\n",
    "    true_mean = true_sum / count\n",
    "    #print(true_mean)\n",
    "    true_sq_sum = tf.reduce_sum(tf.math.square(y_true),axis=1)\n",
    "    pred_mean = pred_sum / count\n",
    "    pred_sq_sum = tf.reduce_sum(tf.math.square(y_pred),axis=1)\n",
    "    product_sum = tf.reduce_sum(y_true*y_pred, axis=1)\n",
    "    \n",
    "    covariance = (product_sum - true_mean * pred_sum\n",
    "                      - pred_mean * true_sum\n",
    "                      + count * true_mean * pred_mean)\n",
    "    \n",
    "    true_var = true_sq_sum - count * tf.math.square(true_mean)\n",
    "    pred_var = pred_sq_sum - count * tf.math.square(pred_mean)\n",
    "    tp_var = tf.math.sqrt(true_var) * tf.math.sqrt(pred_var)\n",
    "    \n",
    "    pearsons = covariance / tp_var\n",
    "    #pearsons_not_nan = tf.dtypes.cast(tf.math.logical_not(tf.math.is_nan(pearsons)), dtype=tf.float32)\n",
    "    return pearsons\n",
    "\n",
    "def r2_batch(y_true, y_pred):\n",
    "    '''\n",
    "    Helper function to compute r2 for tensors of shape (batch, length)\n",
    "    to do: check descrepancy w/ tensorflow implementation\n",
    "    '''\n",
    "    y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
    "    y_true = tf.cast(y_true, 'float64')\n",
    "    y_pred = tf.cast(y_pred, 'float64')\n",
    "    residual = tf.reduce_sum(tf.square(y_true - y_pred),axis=1,keepdims=True)\n",
    "    total = tf.reduce_sum(tf.square(y_true -  tf.reduce_mean(y_true)),axis=1,keepdims=True)\n",
    "    r2 = tf.constant(1.0,dtype=tf.float64) - residual / total\n",
    "    return r2#[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99a359e3-844b-4c50-b1f3-230f9cc4ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.random.normal([4,896], 1e-07, 1.0e-08, tf.float64, seed=1)\n",
    "y_pred = tf.random.normal([4,896], 1e-02, 1.0e-08, tf.float64, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a964c4-bd93-40ab-9b39-9497e5d8fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 17:52:58.965433: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-04 17:52:58.965472: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-04 17:52:58.965493: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n",
      "2022-07-04 17:52:58.965841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.constant('ATCG')\n",
    "test_arr =  training_utils.one_hot(test)\n",
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d80451-3123-4a96-9ec7-6193c2b78819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.constant('cgat')\n",
    "test_arr =  training_utils.rev_comp_one_hot(test)\n",
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9161f3a3-0f56-4eb0-94d4-5937a09b185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([4, 3, 2, 1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reverse(trial,[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "855c37bd-6015-4294-b308-b1c13c029447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=64\n",
    "max_seq_len=1024\n",
    "\n",
    "\n",
    "inv_freq = 1. / (10000 ** (tf.range(start=0, limit=dim, delta=2, dtype='float32') / dim))\n",
    "position = tf.range(start=0, limit=max_seq_len, delta=1, dtype='float32')\n",
    "sinusoid_inp = tf.einsum(\"i,j->ij\", position, inv_freq)\n",
    "emb = tf.concat((tf.math.sin(sinusoid_inp), tf.math.cos(sinusoid_inp)), axis=-1)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "982258bd-2c0c-4625-b7bd-6cd939391e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repeat(x, r):\n",
    "    c = tf.ones_like(tf.shape(x), dtype=tf.int32)\n",
    "    c1 = c[:-1]\n",
    "    c2 = c[-1][None] * r\n",
    "    c_ = tf.concat([c1, c2], axis=0)\n",
    "\n",
    "    return tf.tile(x, c_)\n",
    "\n",
    "dim=64\n",
    "theta=10000\n",
    "freqs = tf.convert_to_tensor(1. / (theta ** (np.arange(0, dim, 2)[:(dim // 2)] / dim)), dtype=tf.float32)\n",
    "\n",
    "freqs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55696894-8557-4b67-a424-d23276d23190",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.ones((1024,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb6503fd-a325-4ef9-aa47-aa8052cd5b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1024, 1, 64), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584dc938-2304-43dc-888d-6cb53fd91861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c962c47-5362-46ee-a9af-90d54267a089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32, 128), dtype=float32, numpy=\n",
       "array([[[ 0.4624173 ,  0.0709485 ,  0.9875072 , ...,  0.7712948 ,\n",
       "         -0.44498843, -0.00588704],\n",
       "        [ 0.19986393, -1.1558427 ,  1.3676628 , ...,  0.13729247,\n",
       "          0.32130617,  0.04578542],\n",
       "        [ 0.65867066,  1.6272559 ,  0.22596528, ...,  0.6174097 ,\n",
       "          0.8941371 ,  0.6571273 ],\n",
       "        ...,\n",
       "        [-0.9744453 ,  2.1862698 , -1.9445254 , ..., -0.9426393 ,\n",
       "         -0.29811418,  0.23624428],\n",
       "        [ 0.20273659,  0.24291225, -0.40198046, ...,  0.42093408,\n",
       "         -0.27420944, -0.51285267],\n",
       "        [ 1.0759048 , -1.5710802 , -0.06107113, ..., -1.6967397 ,\n",
       "          0.64171076,  0.82089496]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.random.normal([1,32,128])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bc94a91-3a42-4ad1-98e3-4f4bd51387d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 32, 128), dtype=float32, numpy=\n",
       "array([[[ 0.4624173 ,  0.0709485 ,  0.9875072 , ...,  0.7712948 ,\n",
       "         -0.44498843, -0.00588704],\n",
       "        [ 0.19986393, -1.1558427 ,  1.3676628 , ...,  0.13729247,\n",
       "          0.32130617,  0.04578542],\n",
       "        [ 0.65867066,  1.6272559 ,  0.22596528, ...,  0.6174097 ,\n",
       "          0.8941371 ,  0.6571273 ],\n",
       "        ...,\n",
       "        [-0.9744453 ,  2.1862698 , -1.9445254 , ..., -0.9426393 ,\n",
       "         -0.29811418,  0.23624428],\n",
       "        [ 0.20273659,  0.24291225, -0.40198046, ...,  0.42093408,\n",
       "         -0.27420944, -0.51285267],\n",
       "        [ 1.0759048 , -1.5710802 , -0.06107113, ..., -1.6967397 ,\n",
       "          0.64171076,  0.82089496]],\n",
       "\n",
       "       [[ 0.4624173 ,  0.0709485 ,  0.9875072 , ...,  0.7712948 ,\n",
       "         -0.44498843, -0.00588704],\n",
       "        [ 0.19986393, -1.1558427 ,  1.3676628 , ...,  0.13729247,\n",
       "          0.32130617,  0.04578542],\n",
       "        [ 0.65867066,  1.6272559 ,  0.22596528, ...,  0.6174097 ,\n",
       "          0.8941371 ,  0.6571273 ],\n",
       "        ...,\n",
       "        [-0.9744453 ,  2.1862698 , -1.9445254 , ..., -0.9426393 ,\n",
       "         -0.29811418,  0.23624428],\n",
       "        [ 0.20273659,  0.24291225, -0.40198046, ...,  0.42093408,\n",
       "         -0.27420944, -0.51285267],\n",
       "        [ 1.0759048 , -1.5710802 , -0.06107113, ..., -1.6967397 ,\n",
       "          0.64171076,  0.82089496]],\n",
       "\n",
       "       [[ 0.4624173 ,  0.0709485 ,  0.9875072 , ...,  0.7712948 ,\n",
       "         -0.44498843, -0.00588704],\n",
       "        [ 0.19986393, -1.1558427 ,  1.3676628 , ...,  0.13729247,\n",
       "          0.32130617,  0.04578542],\n",
       "        [ 0.65867066,  1.6272559 ,  0.22596528, ...,  0.6174097 ,\n",
       "          0.8941371 ,  0.6571273 ],\n",
       "        ...,\n",
       "        [-0.9744453 ,  2.1862698 , -1.9445254 , ..., -0.9426393 ,\n",
       "         -0.29811418,  0.23624428],\n",
       "        [ 0.20273659,  0.24291225, -0.40198046, ...,  0.42093408,\n",
       "         -0.27420944, -0.51285267],\n",
       "        [ 1.0759048 , -1.5710802 , -0.06107113, ..., -1.6967397 ,\n",
       "          0.64171076,  0.82089496]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.4624173 ,  0.0709485 ,  0.9875072 , ...,  0.7712948 ,\n",
       "         -0.44498843, -0.00588704],\n",
       "        [ 0.19986393, -1.1558427 ,  1.3676628 , ...,  0.13729247,\n",
       "          0.32130617,  0.04578542],\n",
       "        [ 0.65867066,  1.6272559 ,  0.22596528, ...,  0.6174097 ,\n",
       "          0.8941371 ,  0.6571273 ],\n",
       "        ...,\n",
       "        [-0.9744453 ,  2.1862698 , -1.9445254 , ..., -0.9426393 ,\n",
       "         -0.29811418,  0.23624428],\n",
       "        [ 0.20273659,  0.24291225, -0.40198046, ...,  0.42093408,\n",
       "         -0.27420944, -0.51285267],\n",
       "        [ 1.0759048 , -1.5710802 , -0.06107113, ..., -1.6967397 ,\n",
       "          0.64171076,  0.82089496]],\n",
       "\n",
       "       [[ 0.4624173 ,  0.0709485 ,  0.9875072 , ...,  0.7712948 ,\n",
       "         -0.44498843, -0.00588704],\n",
       "        [ 0.19986393, -1.1558427 ,  1.3676628 , ...,  0.13729247,\n",
       "          0.32130617,  0.04578542],\n",
       "        [ 0.65867066,  1.6272559 ,  0.22596528, ...,  0.6174097 ,\n",
       "          0.8941371 ,  0.6571273 ],\n",
       "        ...,\n",
       "        [-0.9744453 ,  2.1862698 , -1.9445254 , ..., -0.9426393 ,\n",
       "         -0.29811418,  0.23624428],\n",
       "        [ 0.20273659,  0.24291225, -0.40198046, ...,  0.42093408,\n",
       "         -0.27420944, -0.51285267],\n",
       "        [ 1.0759048 , -1.5710802 , -0.06107113, ..., -1.6967397 ,\n",
       "          0.64171076,  0.82089496]],\n",
       "\n",
       "       [[ 0.4624173 ,  0.0709485 ,  0.9875072 , ...,  0.7712948 ,\n",
       "         -0.44498843, -0.00588704],\n",
       "        [ 0.19986393, -1.1558427 ,  1.3676628 , ...,  0.13729247,\n",
       "          0.32130617,  0.04578542],\n",
       "        [ 0.65867066,  1.6272559 ,  0.22596528, ...,  0.6174097 ,\n",
       "          0.8941371 ,  0.6571273 ],\n",
       "        ...,\n",
       "        [-0.9744453 ,  2.1862698 , -1.9445254 , ..., -0.9426393 ,\n",
       "         -0.29811418,  0.23624428],\n",
       "        [ 0.20273659,  0.24291225, -0.40198046, ...,  0.42093408,\n",
       "         -0.27420944, -0.51285267],\n",
       "        [ 1.0759048 , -1.5710802 , -0.06107113, ..., -1.6967397 ,\n",
       "          0.64171076,  0.82089496]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(test, multiples=[32,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a773098d-b41b-4daa-9da4-71433bc768e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.cast(tf.constant([0,1,2,3,4,5,6,7,8,9]),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88044cc4-15bf-45f5-8b30-b52471a50ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 2., 0., 0., 5., 6., 7., 8., 9.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.dropout(test, rate=0.2).numpy()*(1-0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8deb8-73b7-43ec-a25a-fe4da484a2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
