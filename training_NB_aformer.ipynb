{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f3727c-cca0-414c-9bde-b2a3449eaac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:24:00.502013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-17 20:24:00.502052: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import src.aformer_TF_gc_separated as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "from src.optimizers import *\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_aformer_TF_genecentered_separated as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554e5bc7-fc53-41ee-8dad-ee3251aab7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:24:02.546894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-17 20:24:02.546946: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-17 20:24:02.546972: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:24:02.824682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "2022-11-17 20:24:02.834389: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.113.28.194:8470}\n",
      "2022-11-17 20:24:02.834443: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:60086}\n",
      "2022-11-17 20:24:02.854478: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.113.28.194:8470}\n",
      "2022-11-17 20:24:02.854534: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:60086}\n",
      "2022-11-17 20:24:02.855215: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:60086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-4')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    #options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 12\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c81633-2964-456b-8c46-bb7f2f292be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    train_steps=50#3200#5165 #320\n",
    "    warmup_steps=10\n",
    "    val_steps_h=10#3200#757 ### 5562\n",
    "    val_steps_m=14\n",
    "    num_epochs=5\n",
    "    lr_base=0.001\n",
    "    warmup_lr=1.0e-06\n",
    "\n",
    "    data_it_tr_list = []\n",
    "    data_it_val_list = []\n",
    "\n",
    "    ### create dataset iterators\n",
    "    heads_dict = {}\n",
    "    data_dict_tr,data_dict_val,val_ho_it = training_utils.return_distributed_iterators(\"gs://picard-testing-176520/98k_genecentered_blacklist0.40_peaks_sep/preprocessed/\",\n",
    "                                                                                       \"gs://picard-testing-176520/98k_genecentered_blacklist0.40_peaks_sep/val_holdout/preprocessed\",\n",
    "                                                                                       GLOBAL_BATCH_SIZE,\n",
    "                                                                                       98304,\n",
    "                                                                                       768,\n",
    "                                                                                       196608,\n",
    "                                                                                       128,\n",
    "                                                                                       20,\n",
    "                                                                                       4,\n",
    "                                                                                       50,\n",
    "                                                                                       strategy,\n",
    "                                                                                       options)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d8702c-380d-4263-8d95-566615f76ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    inits = training_utils.get_initializers(\"/home/jupyter/dev/BE_CD69_paper_2022/enformer_fine_tuning/checkpoint/sonnet_weights\")\n",
    "    model = aformer.aformer(kernel_transformation = 'softmax_kernel_transformation',\n",
    "                            dropout_rate = 0.25,\n",
    "                            attention_dropout_rate = 0.15,\n",
    "                            pointwise_dropout_rate=0.05,\n",
    "                            input_length = 98304,\n",
    "                            dim_reduce_length_seq = 768,\n",
    "                            peaks_reduce_dim= 128,\n",
    "                             num_heads = 4,\n",
    "                             numerical_stabilizer = 0.001,\n",
    "                             nb_random_features = 256,\n",
    "                             hidden_size = 400,\n",
    "                             shared_transformer_depth = 2,\n",
    "                             pre_transf_channels = 400,\n",
    "                             d_model = 400,\n",
    "                             norm=True,\n",
    "                             dim = 100, \n",
    "                             max_seq_length = 768,\n",
    "                             use_rot_emb = True,\n",
    "                             use_mask_pos = False, \n",
    "                             normalize = True,\n",
    "                             seed = 3,\n",
    "                             load_init=False,\n",
    "                             inits=inits,\n",
    "                             filter_list_seq=[192,224,256,288,320,384], \n",
    "                             freeze_conv_layers=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19597c14-40cc-424c-9680-d75516580e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    scheduler1= tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=2.0e-05,\n",
    "        decay_steps=1000, alpha=1.0)\n",
    "    scheduler1=WarmUp(initial_learning_rate=5.0e-05,\n",
    "                                 warmup_steps=50,\n",
    "                                 decay_schedule_fn=scheduler1)\n",
    "    optimizer1 = tfa.optimizers.AdamW(learning_rate=scheduler1,\n",
    "                                           weight_decay=5.0e-07)\n",
    "    \n",
    "    scheduler2= tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=2.0e-05,\n",
    "    decay_steps=1000, alpha=1.0)\n",
    "    scheduler2=WarmUp(initial_learning_rate=2.0e-05,\n",
    "                                 warmup_steps=50,\n",
    "                                 decay_schedule_fn=scheduler2)\n",
    "    optimizer2 = tfa.optimizers.AdamW(learning_rate=scheduler2,\n",
    "                                          weight_decay=5.0e-07)\n",
    "    \n",
    "    optimizers_in=optimizer1,optimizer2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b410e6c0-6220-418a-b6e1-868776fc73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    train_step, val_step, val_ho_step,build_step, metric_dict = training_utils.return_train_val_functions(model,\n",
    "                                                                                                          optimizers_in,\n",
    "                                                                                                          strategy,\n",
    "                                                                                                          metric_dict,\n",
    "                                                                                                          150,\n",
    "                                                                                                          150,\n",
    "                                                                                                          150,\n",
    "                                                                                                          GLOBAL_BATCH_SIZE,\n",
    "                                                                                                          1.0,\n",
    "                                                                                                          BATCH_SIZE_PER_REPLICA,\n",
    "                                                                                                          loss_fn_main='poisson',\n",
    "                                                                                                          use_peaks=True,\n",
    "                                                                                                          use_atac=False,\n",
    "                                                                                                          use_coef_var=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e58bc6c-aa7a-44a8-b534-4dd4749ebf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d34035-65ed-44e7-9ad4-d6d2d402b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params: tf.Tensor(6190163, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "with strategy.scope():\n",
    "    def sum_log(x):\n",
    "        return np.log10(1.0 + np.nansum(x))\n",
    "    \n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(1, 15):\n",
    "        start = time.time()\n",
    "        if epoch_i == 1:\n",
    "            build_step(data_dict_val)\n",
    "            total_params = 0\n",
    "            for k in model.trainable_variables:\n",
    "                var = k.values[0]\n",
    "                total_params += tf.size(var)\n",
    "            print('total params: ' + str(total_params)) \n",
    "            \n",
    "        train_step(data_dict_tr)\n",
    "\n",
    "                   #data_dict_tr['mm'],\n",
    "                   #data_dict_tr['rm'])\n",
    "        print('hg_train_loss: ' + str(metric_dict['hg_tr'].result().numpy()))\n",
    "        \n",
    "        #print('hg_lr: ' + str(lr.numpy()))\n",
    "        #print('hg_it: ' + str(it.numpy()))\n",
    "        \n",
    "        val_step(data_dict_val)\n",
    "        val_ho_step(val_ho_it)\n",
    "\n",
    "        val_losses.append(metric_dict['hg_val'].result().numpy())\n",
    "        print('hg_val_loss: ' + str(metric_dict['hg_val'].result().numpy()))\n",
    "        print('hg_val_pearson: ' + str(metric_dict['hg_corr_stats'].result()['pearsonR'].numpy()))\n",
    "        print('hg_val_R2: ' + str(metric_dict['hg_corr_stats'].result()['R2'].numpy()))\n",
    "        \n",
    "        print('hg_val_pearson_ho: ' + str(metric_dict['hg_corr_stats_ho'].result()['pearsonR'].numpy()))\n",
    "        print('hg_val_R2_ho: ' + str(metric_dict['hg_corr_stats_ho'].result()['R2'].numpy()))\n",
    "        \n",
    "        #print('hg_val_pearson_gene: ' + str(metric_dict['hg_corr_stats'].result()['feature_level_pearsonR'].numpy()))\n",
    "        #print('hg_val_R2_gene: ' + str(metric_dict['hg_corr_stats'].result()['feature_level_R2'].numpy()))\n",
    "        \n",
    "        y_trues = metric_dict['hg_corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['hg_corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['hg_corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['hg_corr_stats'].result()['gene_map'].numpy()\n",
    "        quit_bool=False\n",
    "        if np.isnan(y_trues).any():\n",
    "            quit_bool=True\n",
    "            print('nan in trues')\n",
    "        if np.isnan(y_preds).any():\n",
    "            quit_bool=True\n",
    "            print('nan in preds')\n",
    "        if quit_bool:\n",
    "            continue\n",
    "\n",
    "        unique_preds = {}\n",
    "        unique_trues = {}\n",
    "        for k,x in enumerate(gene_map):\n",
    "            unique_preds[(cell_types[k],x)] = y_preds[k]\n",
    "            unique_trues[(cell_types[k],x)] = y_trues[k]\n",
    "        \n",
    "        unique_preds = dict(sorted(unique_preds.items()))\n",
    "        unique_trues = dict(sorted(unique_trues.items()))\n",
    "        \n",
    "        \n",
    "        print('overall gene pearsonsR:', pearsonr(y_trues,\n",
    "                                                    y_preds)[0])\n",
    "        \n",
    "        print('overall gene spearmanR:', spearmanr(y_trues,\n",
    "                                                    y_preds)[0])\n",
    "        data = np.vstack([y_trues,y_preds])\n",
    "        kernel = stats.gaussian_kde(data)(data)\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.scatterplot(\n",
    "            x=y_trues,\n",
    "            y=y_preds,\n",
    "            c=kernel,\n",
    "            cmap=\"viridis\",\n",
    "            ax = ax)\n",
    "        ax.set_xlim(0, max(y_trues))\n",
    "        ax.set_ylim(0, max(y_trues))\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        ### now compute correlations across cell types\n",
    "        across_cells_preds = {}\n",
    "        across_cells_trues = {}\n",
    "        \n",
    "        for k,v in unique_preds.items():\n",
    "            cell_t,gene_name = k\n",
    "            if cell_t not in across_cells_preds.keys():\n",
    "                across_cells_preds[cell_t] = []\n",
    "                across_cells_trues[cell_t] = []\n",
    "            else:\n",
    "                across_cells_preds[cell_t].append(v)\n",
    "                across_cells_trues[cell_t].append(unique_trues[k])\n",
    "        cell_specific_corrs = []\n",
    "        for k,v in across_cells_preds.items():\n",
    "            trues = []\n",
    "            preds = []\n",
    "            for idx,x in enumerate(v):\n",
    "                preds.append(x)\n",
    "                trues.append(across_cells_trues[k][idx])\n",
    "            try: \n",
    "                cell_specific_corrs.append(pearsonr(trues, \n",
    "                                                    preds)[0])\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        sns.histplot(x=np.asarray(cell_specific_corrs), bins=50)\n",
    "        plt.show()\n",
    "        print('median_cell_crossgenes:', np.nanmedian(cell_specific_corrs))\n",
    "                \n",
    "            \n",
    "        ### now compute correlations across genes\n",
    "        across_genes_preds = {}\n",
    "        across_genes_trues = {}\n",
    "        \n",
    "        for k,v in unique_preds.items():\n",
    "            cell_t,gene_name = k\n",
    "            if gene_name not in across_genes_preds.keys():\n",
    "                across_genes_preds[gene_name] = []\n",
    "                across_genes_trues[gene_name] = []\n",
    "            else:\n",
    "                across_genes_preds[gene_name].append(v)\n",
    "                across_genes_trues[gene_name].append(unique_trues[k])\n",
    "        genes_specific_corrs = []\n",
    "        genes_specific_vars = []\n",
    "        for k,v in across_genes_preds.items():\n",
    "            trues = []\n",
    "            preds = []\n",
    "            for idx, x in enumerate(v):\n",
    "                #if len(x) > 0:\n",
    "                preds.append(x)\n",
    "                trues.append(across_genes_trues[k][idx])\n",
    "            try: \n",
    "                genes_specific_corrs.append(spearmanr(trues, \n",
    "                                                     preds)[0])\n",
    "                genes_specific_vars.append(np.var(trues))\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        sns.histplot(x=np.asarray(genes_specific_corrs), bins=50)\n",
    "        plt.show()\n",
    "        print('median_gene_crossdataset:', np.nanmedian(genes_specific_corrs))\n",
    "            \n",
    "        sns.scatterplot(\n",
    "            x=genes_specific_vars,\n",
    "            y=genes_specific_corrs)\n",
    "        plt.show()\n",
    "\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('duration(mins): ' + str(duration))\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "        \n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d71db5-6c78-4930-b4d1-d1e94a759e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.lr(optimizer.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8deb8-73b7-43ec-a25a-fe4da484a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.reduce(\"SUM\",\n",
    "                optimizer.iterations, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169876a-a570-44bc-b124-760e024a6673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
