{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab370951-f6d4-4a16-858a-58d08b64c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import src.aformer_atac_cage as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "from src.optimizers import *\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_atac_cage as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d333d7e-5e30-4865-b2a0-f04221ade9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system node-6 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system node-6 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-6')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    #options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 64\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "797537b8-5aab-49a2-8cb6-53e04a27f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.random.Generator.from_seed(1)\n",
    "with strategy.scope():\n",
    "\n",
    "    tr_data_it,val_data_it,val_data_ho_it, val_data_TSS_it,val_data_TSS_ho_it = \\\n",
    "        training_utils.return_distributed_iterators(\"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_5prime\",\n",
    "                                     \"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_5prime_holdout\",\n",
    "                                     \"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_TSS_5prime\",\n",
    "                                     \"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_TSS_5prime_holdout\",\n",
    "                                     GLOBAL_BATCH_SIZE,\n",
    "                                     262144,\n",
    "                                     10,\n",
    "                                     65536,\n",
    "                                     2048,\n",
    "                                     576,\n",
    "                                     128,\n",
    "                                     32,\n",
    "                                     1,\n",
    "                                     strategy,\n",
    "                                     options,\n",
    "                                     0.025,\n",
    "                                     1024,\n",
    "                                     False,\n",
    "                                     True,\n",
    "                                     True,\n",
    "                                     False,\n",
    "                                     g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8f9d938-b205-4fc0-a3ab-5d2d438329b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "\n",
    "    model = aformer.aformer(kernel_transformation = 'relu_kernel_transformation',\n",
    "                             dropout_rate = 0.30,\n",
    "                             pointwise_dropout_rate=0.1,\n",
    "                             input_length = 262144,\n",
    "                             output_length = 2048,\n",
    "                             final_output_length = 896,\n",
    "                             num_heads = 8,\n",
    "                             numerical_stabilizer = 0.001,\n",
    "                             nb_random_features = 256,\n",
    "                             num_transformer_layers = 2,\n",
    "                             norm=True,\n",
    "                             BN_momentum=0.90,\n",
    "                             max_seq_length = 2048,\n",
    "                             use_rot_emb = True,\n",
    "                             use_mask_pos = False, \n",
    "                             normalize = True,\n",
    "                             seed = 3,\n",
    "                             load_init=False,\n",
    "                             stable_variant=False,\n",
    "                             inits=None,\n",
    "                             freeze_conv_layers=False,\n",
    "                             freeze_BN_layers=False,\n",
    "                             predict_atac=False,\n",
    "                             learnable_PE=True,\n",
    "                             final_point_scale=4,\n",
    "                             filter_list_seq=[384,512,640,768,896,1024])\n",
    "    \n",
    "    def build_step(iterator): #input_batch, model, optimizer, organism, gradient_clip):\n",
    "        @tf.function(jit_compile=True)\n",
    "        def test_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            #global_acc=tf.cast(inputs['global_acc'],dtype=tf.bfloat16)         \n",
    "            input_tuple = sequence,atac#,global_acc\n",
    "\n",
    "            output = model(input_tuple,\n",
    "                           training=False)\n",
    "\n",
    "        for _ in tf.range(1): ## for loop within @tf.fuction for improved TPU performance\n",
    "            strategy.run(test_step, args=(next(iterator),))\n",
    "            \n",
    "            \n",
    "    #build_step(val_data_it)\n",
    "\n",
    "    #print('ran test input')\n",
    "    #model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_262k_load-True_LR-0.01_T-7_D-0.3_2023-04-13_15:39:43/final/saved_model\")\n",
    "    #model.load_weights(\"gs://picard-testing-176520/paired_rampage_atac/genformer/models/aformer_baseline_GENFORMER_262k_load-True_LR1-2.5e-05_LR2-2.5e-05_LR3-0.0002_T-6_D-0.3_2023-05-03_03:07:39/iteration_8/saved_model\")\n",
    "    #print('loaded weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7839285-c85c-4bf9-9ca0-d8cd3ef7f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    \"\"\"\n",
    "    optimizer1 = tf.keras.optimizers.Adam(learning_rate=1.0e-07,\n",
    "                                          epsilon=1.0e-08)\n",
    "    optimizer2 = tf.keras.optimizers.Adam(learning_rate=1.0e-07,\n",
    "                                          epsilon=1.0e-08)\n",
    "    optimizer3 = tf.keras.optimizers.Adam(learning_rate=1.0e-04,\n",
    "                                          epsilon=1.0e-08)\n",
    "    \"\"\"\n",
    "    optimizer1 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-08, \n",
    "        epsilon=1.0e-14,\n",
    "        rectify=True)\n",
    "    optimizer2 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-08, \n",
    "        epsilon=1.0e-14,\n",
    "        rectify=True)\n",
    "    optimizer3 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-04, \n",
    "        epsilon=1.0e-14,\n",
    "        rectify=True)\n",
    "    optimizers_in=optimizer1,optimizer2,optimizer3\n",
    "\n",
    "    loss_fn = tf.keras.losses.Poisson(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    metric_dict[\"train_loss\"] = tf.keras.metrics.Mean(\"train_loss\",\n",
    "                                                 dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    metric_dict[\"corr_stats\"] = metrics.correlation_stats_gene_centered(name='corr_stats')\n",
    "    \n",
    "    def dist_train_step_cage_only(iterator):    \n",
    "        @tf.function(jit_compile=True)\n",
    "        def train_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            mask=tf.cast(inputs['mask'],dtype=tf.float32)\n",
    "            mask_gathered=tf.cast(inputs['mask_gathered'],dtype=tf.int32)\n",
    "            peaks=tf.cast(inputs['peaks'],dtype=tf.int32)\n",
    "            atac_orig=tf.cast(inputs['atac_orig'],dtype=tf.bfloat16)\n",
    "            tss_tokens=tf.cast(inputs['tss_tokens'],dtype=tf.int32)\n",
    "            \n",
    "\n",
    "            input_tuple = sequence, atac\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                conv_vars = model.stem_conv.trainable_variables + \\\n",
    "                            model.stem_res_conv.trainable_variables + \\\n",
    "                            model.stem_pool.trainable_variables + \\\n",
    "                            model.conv_tower.trainable_variables + \\\n",
    "                            model.stem_conv_atac.trainable_variables + \\\n",
    "                                model.stem_res_conv_atac.trainable_variables + \\\n",
    "                                        model.stem_pool_atac.trainable_variables + \\\n",
    "                                            model.conv_tower_atac.trainable_variables\n",
    "                \n",
    "                performer_vars =model.pos_embedding_learned.trainable_variables + \\\n",
    "                                    model.performer.trainable_variables + \\\n",
    "                                        model.final_pointwise_conv.trainable_variables\n",
    "                                                \n",
    "\n",
    "                heads_vars = model.final_dense_profile_FT.trainable_variables \n",
    "\n",
    "                vars_all = conv_vars + performer_vars + heads_vars\n",
    "\n",
    "                output_profile = model(input_tuple,\n",
    "                                       training=True)\n",
    "\n",
    "                output_profile = tf.cast(output_profile,dtype=tf.float32)\n",
    "                \n",
    "\n",
    "                cage_loss = tf.reduce_mean(loss_fn(target[:,:,:],\n",
    "                                                             output_profile[:,:,:])) * (1. / 24)\n",
    "                loss = cage_loss\n",
    "            \n",
    "\n",
    "            gradients = tape.gradient(loss, vars_all)\n",
    "            \"\"\"\n",
    "            gradients, _ = tf.clip_by_global_norm(gradients, \n",
    "                                                  0.2)\n",
    "\n",
    "            optimizer1.apply_gradients(zip(gradients[:len(conv_vars)], \n",
    "                                           conv_vars))\n",
    "            optimizer2.apply_gradients(zip(gradients[len(conv_vars):len(conv_vars+pointwise_vars)], \n",
    "                                           pointwise_vars))\n",
    "            optimizer3.apply_gradients(zip(gradients[len(conv_vars+pointwise_vars):], \n",
    "                                           heads_vars))\n",
    "            metric_dict[\"train_loss\"].update_state(loss)\n",
    "            \"\"\"\n",
    "            return gradients,loss,output_profile,sequence,atac,target,atac_orig,mask,tss_tokens\n",
    "\n",
    "        for _ in tf.range(1):\n",
    "            strategy.run(train_step,\n",
    "                         args=(next(iterator),))\n",
    "            \n",
    "            \n",
    "    def dist_val_step_TSS_c_only(iterator): #input_batch, model, optimizer, organism, gradient_clip):\n",
    "        @tf.function(jit_compile=True)\n",
    "        def val_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            \n",
    "            input_tuple = sequence, atac\n",
    "\n",
    "            #output_profile = model(input_tuple,\n",
    "            #                       training=False)\n",
    "\n",
    "            #output_profile = tf.cast(output_profile,dtype=tf.float32) \n",
    "\n",
    "            tss_tokens = tf.cast(inputs['tss_tokens'],dtype=tf.float32)\n",
    "            gene_token = inputs['gene_token']\n",
    "            cell_type = inputs['cell_type']\n",
    "            \n",
    "            pred = tf.reduce_sum(tf.cast(target,dtype=tf.float32)[:,:,:] * tss_tokens,axis=1)\n",
    "            true = tf.reduce_sum(target[:,:,:] * tss_tokens,axis=1)\n",
    "\n",
    "            return pred,true,gene_token,cell_type\n",
    "        \n",
    "        ta_pred = tf.TensorArray(tf.float32, size=0, dynamic_size=True) # tensor array to store preds\n",
    "        ta_true = tf.TensorArray(tf.float32, size=0, dynamic_size=True) # tensor array to store vals\n",
    "        ta_celltype = tf.TensorArray(tf.int32, size=0, dynamic_size=True) # tensor array to store preds\n",
    "        ta_genemap = tf.TensorArray(tf.int32, size=0, dynamic_size=True)        \n",
    "\n",
    "        for _ in tf.range(1500): ## for loop within @tf.fuction for improved TPU performance\n",
    "\n",
    "            pred_rep, true_rep, gene_rep, cell_type_rep = strategy.run(val_step,\n",
    "                                                                       args=(next(iterator),))\n",
    "            \n",
    "            pred_reshape = tf.reshape(strategy.gather(pred_rep, axis=0), [-1]) # reshape to 1D\n",
    "            true_reshape = tf.reshape(strategy.gather(true_rep, axis=0), [-1])\n",
    "            cell_type_reshape = tf.reshape(strategy.gather(cell_type_rep, axis=0), [-1])\n",
    "            gene_map_reshape = tf.reshape(strategy.gather(gene_rep, axis=0), [-1])\n",
    "            \n",
    "            ta_pred = ta_pred.write(_, pred_reshape)\n",
    "            ta_true = ta_true.write(_, true_reshape)\n",
    "            ta_celltype = ta_celltype.write(_, cell_type_reshape)\n",
    "            ta_genemap = ta_genemap.write(_, gene_map_reshape)\n",
    "        metric_dict[\"corr_stats\"].update_state(ta_true.concat(),\n",
    "                                                  ta_pred.concat(),\n",
    "                                                  ta_celltype.concat(),\n",
    "                                                  ta_genemap.concat())\n",
    "        ta_true.close()\n",
    "        ta_pred.close()\n",
    "        ta_celltype.close()\n",
    "        ta_genemap.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d13d7eb8-7b92-44d8-92a7-2759896f8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "with strategy.scope():\n",
    "    def sum_log(x):\n",
    "        return np.log10(1.0 + np.nansum(x))\n",
    "    \n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(2, 3):\n",
    "        start = time.time()\n",
    "        if epoch_i == 1:\n",
    "            build_step(tr_data_it)\n",
    "            total_params = 0\n",
    "            for k in model.trainable_variables:\n",
    "                var = k.values[0]\n",
    "                total_params += tf.size(var)\n",
    "            print('total params: ' + str(total_params))\n",
    "        \n",
    "\n",
    "        #dist_train_step_cage_only(tr_data_it)\n",
    "        \n",
    "        #print([tf.reduce_sum(tf.cast(tf.math.is_nan(x.values[0]),dtype=tf.float32)) for x in grads_out])\n",
    "        #print(loss)\n",
    "        #train_step(data_tr)\n",
    "        \n",
    "        #print('hg_train_loss: ' + str(metric_dict['train_loss'].result().numpy()))\n",
    "        \n",
    "        dist_val_step_TSS_c_only(val_data_TSS_it)\n",
    "        y_trues = metric_dict['corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['corr_stats'].result()['gene_map'].numpy()\n",
    "        \n",
    "        #continue\n",
    "        '''\n",
    "        val_step(data_val)\n",
    "        #val_step(data_val)\n",
    "\n",
    "        val_losses.append(metric_dict['val_loss'].result().numpy())\n",
    "        print('hg_val_loss: ' + str(metric_dict['val_loss'].result().numpy()))\n",
    "        #print('hg_val_loss_CAGE: ' + str(metric_dict['val_loss_CAGE'].result().numpy()))\n",
    "        #print('hg_val_loss_ATAC: ' + str(metric_dict['val_loss_ATAC'].result().numpy()))\n",
    "        #print('hg_val_cage_pearson: ' + str(metric_dict['CAGE_PearsonR'].result()['PearsonR'].numpy()))\n",
    "        #print('hg_val_cage_R2: ' + str(metric_dict['CAGE_R2'].result()['R2'].numpy()))\n",
    "        \n",
    "        print('hg_val_atac_pearson: ' + str(metric_dict['ATAC_PearsonR'].result()['PearsonR'].numpy()))\n",
    "        print('hg_val_atac_R2: ' + str(metric_dict['ATAC_R2'].result()['R2'].numpy()))\n",
    "        \n",
    "        \n",
    "        #print('hg_val_atac_baseline_pearson: ' + str(metric_dict['ATAC_PearsonR_baseline'].result()['PearsonR'].numpy()))\n",
    "        #print('hg_val_atac_baseline_R2: ' + str(metric_dict['ATAC_R2_baseline'].result()['R2'].numpy()))\n",
    "        \"\"\"\n",
    "        val_step_TSS(data_val_TSS)\n",
    "        #val_step_TSS(data_val_TSS)\n",
    "        \n",
    "        y_trues = metric_dict['corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['corr_stats'].result()['gene_map'].numpy()\n",
    "\n",
    "\n",
    "        figures, corrs_overall = training_utils.make_plots(y_trues,\n",
    "                                           y_preds, \n",
    "                                           cell_types, \n",
    "                                           gene_map,50)\n",
    "        \n",
    "        cell_spec,gene_spec,cell_spec_sp,gene_spec_sp = corrs_overall\n",
    "        \n",
    "        print('cell spec corr: ' + str(cell_spec))\n",
    "        print('gene_spec_corr:' + str(gene_spec))\n",
    "        print('cell spec corr_sp: ' + str(cell_spec_sp))\n",
    "        print('gene_spec_corr_sp:' + str(gene_spec_sp))\n",
    "        \"\"\"\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('duration(mins): ' + str(duration))\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "        \n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43d381dd-a44a-4ed5-9afe-e0f8acc6bfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,    13, ..., 19937, 19958, 20010], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(gene_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a442fb-a2f1-46d8-9490-2dc0408417c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 04:02:17.240200: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:58] Ignoring an error encountered when deleting remote tensors handles: INVALID_ARGUMENT: Unable to find the relevant tensor remote_handle: Op ID: 337879, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1683172937.236734538\",\"description\":\"Error received from peer ipv4:10.85.112.90:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 337879, Output num: 1\",\"grpc_status\":3} [type.googleapis.com/tensorflow.core.platform.ErrorSourceProto='\\x08\\x05']\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    649\u001b[0m     return control_flow_ops.cond(\n\u001b[0;32m--> 650\u001b[0;31m         num_replicas_with_values > 0, _value_or_dummy, _eof, strict=True)\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1683172937.235319412\",\"description\":\"Error received from peer ipv4:10.85.112.90:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"End of sequence\",\"grpc_status\":11}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25618/783973020.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcell_types_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_TSS_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "cell_types_all = []\n",
    "for k in range(3000):\n",
    "    test = next(val_data_TSS_it)\n",
    "    for k in range(8):\n",
    "        for i in range(4):\n",
    "            cell_types_all.append(test['cell_type'].values[k][i])\n",
    "            num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9b1bd-ff1d-4e6d-8b92-db19e1759131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
