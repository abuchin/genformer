{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab370951-f6d4-4a16-858a-58d08b64c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 03:48:19.133891: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 03:48:19.310676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-26 03:48:19.310712: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-26 03:48:20.180442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-26 03:48:20.180561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-26 03:48:20.180574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import src.aformer_atac_cage as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "from src.optimizers import *\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_atac_cage as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d333d7e-5e30-4865-b2a0-f04221ade9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 03:48:21.584929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-26 03:48:21.584979: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-26 03:48:21.585005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-6')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    #options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797537b8-5aab-49a2-8cb6-53e04a27f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.random.Generator.from_seed(1)\n",
    "with strategy.scope():\n",
    "\n",
    "    tr_data_it,val_data_it,val_data_ho_it, val_data_TSS_it,val_data_TSS_ho_it = \\\n",
    "        training_utils.return_distributed_iterators(\"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_5prime\",\n",
    "                                     \"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_5prime_holdout\",\n",
    "                                     \"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_TSS_5prime\",\n",
    "                                     \"gs://picard-testing-176520/paired_rampage_atac/262k/genformer_atac_rampage_globalacc_conv_rpgc_TSS_5prime_holdout\",\n",
    "                                     24,\n",
    "                                     262144,\n",
    "                                     10,\n",
    "                                     65536,\n",
    "                                     2048,\n",
    "                                     256,\n",
    "                                     128,\n",
    "                                     4,\n",
    "                                     5,\n",
    "                                     strategy,\n",
    "                                     options,\n",
    "                                     0.00,\n",
    "                                     1024,\n",
    "                                     True,\n",
    "                                     True,\n",
    "                                     True,\n",
    "                                     False,\n",
    "                                     g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938f2e7-12e4-4b74-99d3-69fe81e86373",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(tr_data_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9d938-b205-4fc0-a3ab-5d2d438329b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "\n",
    "    model = aformer.aformer(kernel_transformation = 'relu_kernel_transformation',\n",
    "                             dropout_rate = 0.30,\n",
    "                             pointwise_dropout_rate=0.1,\n",
    "                             input_length = 262144,\n",
    "                             output_length = 2048,\n",
    "                             final_output_length = 1536,\n",
    "                             num_heads = 8,\n",
    "                             numerical_stabilizer = 0.001,\n",
    "                             nb_random_features = 256,\n",
    "                             num_transformer_layers = 6,\n",
    "                             norm=True,\n",
    "                             BN_momentum=0.90,\n",
    "                             max_seq_length = 2048,\n",
    "                             use_rot_emb = True,\n",
    "                             use_mask_pos = False, \n",
    "                             normalize = True,\n",
    "                             seed = 3,\n",
    "                             load_init=False,\n",
    "                             stable_variant=False,\n",
    "                             inits=None,\n",
    "                             freeze_conv_layers=False,\n",
    "                             freeze_BN_layers=False,\n",
    "                             predict_atac=False,\n",
    "                             learnable_PE=True,\n",
    "                             filter_list_seq=[768,896,1024,1152,1280,1536],\n",
    "                             inits_type='enformer_performer')\n",
    "    \n",
    "    def build_step(iterator): #input_batch, model, optimizer, organism, gradient_clip):\n",
    "        @tf.function(jit_compile=True)\n",
    "        def test_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            #global_acc=tf.cast(inputs['global_acc'],dtype=tf.bfloat16)         \n",
    "            input_tuple = sequence,atac#,global_acc\n",
    "\n",
    "            output = model(input_tuple,\n",
    "                           training=False)\n",
    "\n",
    "        for _ in tf.range(1): ## for loop within @tf.fuction for improved TPU performance\n",
    "            strategy.run(test_step, args=(next(iterator),))\n",
    "            \n",
    "            \n",
    "    build_step(val_data_it)\n",
    "\n",
    "    print('ran test input')\n",
    "    #model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_262k_load-True_LR-0.01_T-7_D-0.3_2023-04-13_15:39:43/final/saved_model\")\n",
    "    model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_mm_rm_rat_262k_load-True_LR-0.01_T-6_D-0.3_2023-04-24_19:58:40/iteration_8/saved_model\")\n",
    "    print('loaded weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7839285-c85c-4bf9-9ca0-d8cd3ef7f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    \"\"\"\n",
    "    optimizer1 = tf.keras.optimizers.Adam(learning_rate=1.0e-07,\n",
    "                                          epsilon=1.0e-08)\n",
    "    optimizer2 = tf.keras.optimizers.Adam(learning_rate=1.0e-07,\n",
    "                                          epsilon=1.0e-08)\n",
    "    optimizer3 = tf.keras.optimizers.Adam(learning_rate=1.0e-04,\n",
    "                                          epsilon=1.0e-08)\n",
    "    \"\"\"\n",
    "    optimizer1 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-08, \n",
    "        epsilon=1.0e-14,\n",
    "        rectify=True)\n",
    "    optimizer2 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-08, \n",
    "        epsilon=1.0e-14,\n",
    "        rectify=True)\n",
    "    optimizer3 = tfa.optimizers.AdaBelief(\n",
    "        learning_rate= 1.0e-04, \n",
    "        epsilon=1.0e-14,\n",
    "        rectify=True)\n",
    "    optimizers_in=optimizer1,optimizer2,optimizer3\n",
    "\n",
    "    loss_fn = tf.keras.losses.Poisson(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    metric_dict[\"train_loss\"] = tf.keras.metrics.Mean(\"train_loss\",\n",
    "                                                 dtype=tf.float32)\n",
    "    \n",
    "    def dist_train_step_cage_only(iterator):    \n",
    "        @tf.function(jit_compile=True)\n",
    "        def train_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            mask=tf.cast(inputs['mask'],dtype=tf.float32)\n",
    "            mask_gathered=tf.cast(inputs['mask_gathered'],dtype=tf.int32)\n",
    "            peaks=tf.cast(inputs['peaks'],dtype=tf.int32)\n",
    "\n",
    "            input_tuple = sequence, atac\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                conv_vars = model.stem_conv.trainable_variables + \\\n",
    "                            model.stem_res_conv.trainable_variables + \\\n",
    "                            model.stem_pool.trainable_variables + \\\n",
    "                            model.conv_tower.trainable_variables + \\\n",
    "                            model.stem_conv_atac.trainable_variables + \\\n",
    "                                model.stem_res_conv_atac.trainable_variables + \\\n",
    "                                        model.stem_pool_atac.trainable_variables + \\\n",
    "                                            model.conv_tower_atac.trainable_variables\n",
    "                \n",
    "                performer_vars =model.pos_embedding_learned.trainable_variables + \\\n",
    "                                            model.performer.trainable_variables + \\\n",
    "                                                model.final_pointwise_conv.trainable_variables\n",
    "\n",
    "                heads_vars = model.final_dense_profile_FT.trainable_variables \n",
    "\n",
    "                vars_all = conv_vars + performer_vars + heads_vars\n",
    "\n",
    "                output_profile = model(input_tuple,\n",
    "                                       training=True)\n",
    "\n",
    "                output_profile = tf.cast(output_profile,dtype=tf.float32)\n",
    "                \n",
    "\n",
    "                cage_loss = tf.reduce_mean(loss_fn(target[:,:,:],\n",
    "                                                             output_profile[:,:,:])) * (1. / 24)\n",
    "                loss = cage_loss\n",
    "            \n",
    "\n",
    "            gradients = tape.gradient(loss, vars_all)\n",
    "            \"\"\"\n",
    "            gradients, _ = tf.clip_by_global_norm(gradients, \n",
    "                                                  0.2)\n",
    "\n",
    "            optimizer1.apply_gradients(zip(gradients[:len(conv_vars)], \n",
    "                                           conv_vars))\n",
    "            optimizer2.apply_gradients(zip(gradients[len(conv_vars):len(conv_vars+pointwise_vars)], \n",
    "                                           pointwise_vars))\n",
    "            optimizer3.apply_gradients(zip(gradients[len(conv_vars+pointwise_vars):], \n",
    "                                           heads_vars))\n",
    "            metric_dict[\"train_loss\"].update_state(loss)\n",
    "            \"\"\"\n",
    "            return gradients,loss\n",
    "\n",
    "        for _ in tf.range(1):\n",
    "            gradients_out,loss = strategy.run(train_step,\n",
    "                         args=(next(iterator),))\n",
    "        return gradients_out,loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13d7eb8-7b92-44d8-92a7-2759896f8c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 03:28:53.883583: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:77] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: 9 root error(s) found.\n",
      "  (0) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n",
      "\t [[{{node cluster_tpu_function/_execute_7_0}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[cluster_tpu_function/control_after/_1/_231]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (1) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n",
      "\t [[{{node cluster_tpu_function/_execute_7_0}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "\t [[cluster_tpu_function/_execute_1_0/_183]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (2) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n",
      "\t [[{{node cluster_tpu_function/_execute_7_0}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "  (3) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n",
      "\t [[{{node cluster_tpu_function/_execute_6_0}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode ... [truncated]\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1682479733.873598465\",\"description\":\"Error received from peer ipv4:10.60.243.218:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"9 root error(s) found.\\n  (0) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n\\t [[cluster_tpu_function/control_after/_1/_231]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (1) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n\\t [[cluster_tpu_function/_execute_1_0/_183]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (2) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (3) RESOURCE_EXHAUSTED: {{function_node __inference_tpu_function_40501}} Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_6_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode ... [truncated]\",\"grpc_status\":8}\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n9 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_tpu_function/control_after/_1/_231]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_tpu_function/_execute_1_0/_183]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (3) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode ... [truncated]\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1682479733.873598465\",\"description\":\"Error received from peer ipv4:10.60.243.218:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"9 root error(s) found.\\n  (0) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n\\t [[cluster_tpu_function/control_after/_1/_231]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (1) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n\\t [[cluster_tpu_function/_execute_1_0/_183]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (2) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (3) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_6_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode ... [truncated]\",\"grpc_status\":8} [Op:__inference_tpu_function_40501]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8721/620281479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mgrads_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_train_step_cage_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_data_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8721/622418616.py\u001b[0m in \u001b[0;36mdist_train_step_cage_only\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             gradients_out,loss = strategy.run(train_step,\n\u001b[0;32m---> 89\u001b[0;31m                          args=(next(iterator),))\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgradients_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fn, args, kwargs, options)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mtpu_run\u001b[0;34m(self, fn, args, kwargs, options)\u001b[0m\n\u001b[1;32m   1559\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtpu_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu_function_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_tpu_function_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n9 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_tpu_function/control_after/_1/_231]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_tpu_function/_execute_1_0/_183]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (3) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\n\t [[{{node cluster_tpu_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode ... [truncated]\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1682479733.873598465\",\"description\":\"Error received from peer ipv4:10.60.243.218:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"9 root error(s) found.\\n  (0) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n\\t [[cluster_tpu_function/control_after/_1/_231]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (1) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n\\t [[cluster_tpu_function/_execute_1_0/_183]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (2) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_7_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (3) RESOURCE_EXHAUSTED:  Attempting to reserve 14.19G at the bottom of memory. That was not possible. There are 14.06G free, 0B reserved, and 14.05G reservable. If fragmentation is eliminated, the maximum reservable bytes would be 14.06G, so compaction wouldn't help.  The nearest obstacle is at 14.05G from the bottom with size 6.25M.\\n\\t [[{{node cluster_tpu_function/_execute_6_0}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode ... [truncated]\",\"grpc_status\":8} [Op:__inference_tpu_function_40501]"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "with strategy.scope():\n",
    "    def sum_log(x):\n",
    "        return np.log10(1.0 + np.nansum(x))\n",
    "    \n",
    "    global_step = 0\n",
    "    val_losses = []\n",
    "    val_pearsons = []\n",
    "    val_R2 = []\n",
    "    patience_counter = 0\n",
    "    stop_criteria = False\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch_i in range(2, 10):\n",
    "        start = time.time()\n",
    "        if epoch_i == 1:\n",
    "            build_step(tr_data_it)\n",
    "            total_params = 0\n",
    "            for k in model.trainable_variables:\n",
    "                var = k.values[0]\n",
    "                total_params += tf.size(var)\n",
    "            print('total params: ' + str(total_params))\n",
    "        \n",
    "\n",
    "        grads_out,loss = dist_train_step_cage_only(tr_data_it)\n",
    "        \n",
    "        print([tf.reduce_sum(tf.cast(tf.math.is_nan(x.values[0]),dtype=tf.float32)) for x in grads_out])\n",
    "        print(loss)\n",
    "        #train_step(data_tr)\n",
    "        \n",
    "        print('hg_train_loss: ' + str(metric_dict['train_loss'].result().numpy()))\n",
    "        \n",
    "        #continue\n",
    "        '''\n",
    "        val_step(data_val)\n",
    "        #val_step(data_val)\n",
    "\n",
    "        val_losses.append(metric_dict['val_loss'].result().numpy())\n",
    "        print('hg_val_loss: ' + str(metric_dict['val_loss'].result().numpy()))\n",
    "        #print('hg_val_loss_CAGE: ' + str(metric_dict['val_loss_CAGE'].result().numpy()))\n",
    "        #print('hg_val_loss_ATAC: ' + str(metric_dict['val_loss_ATAC'].result().numpy()))\n",
    "        #print('hg_val_cage_pearson: ' + str(metric_dict['CAGE_PearsonR'].result()['PearsonR'].numpy()))\n",
    "        #print('hg_val_cage_R2: ' + str(metric_dict['CAGE_R2'].result()['R2'].numpy()))\n",
    "        \n",
    "        print('hg_val_atac_pearson: ' + str(metric_dict['ATAC_PearsonR'].result()['PearsonR'].numpy()))\n",
    "        print('hg_val_atac_R2: ' + str(metric_dict['ATAC_R2'].result()['R2'].numpy()))\n",
    "        \n",
    "        \n",
    "        #print('hg_val_atac_baseline_pearson: ' + str(metric_dict['ATAC_PearsonR_baseline'].result()['PearsonR'].numpy()))\n",
    "        #print('hg_val_atac_baseline_R2: ' + str(metric_dict['ATAC_R2_baseline'].result()['R2'].numpy()))\n",
    "        \"\"\"\n",
    "        val_step_TSS(data_val_TSS)\n",
    "        #val_step_TSS(data_val_TSS)\n",
    "        \n",
    "        y_trues = metric_dict['corr_stats'].result()['y_trues'].numpy()\n",
    "        y_preds = metric_dict['corr_stats'].result()['y_preds'].numpy()\n",
    "        cell_types = metric_dict['corr_stats'].result()['cell_types'].numpy()\n",
    "        gene_map = metric_dict['corr_stats'].result()['gene_map'].numpy()\n",
    "\n",
    "\n",
    "        figures, corrs_overall = training_utils.make_plots(y_trues,\n",
    "                                           y_preds, \n",
    "                                           cell_types, \n",
    "                                           gene_map,50)\n",
    "        \n",
    "        cell_spec,gene_spec,cell_spec_sp,gene_spec_sp = corrs_overall\n",
    "        \n",
    "        print('cell spec corr: ' + str(cell_spec))\n",
    "        print('gene_spec_corr:' + str(gene_spec))\n",
    "        print('cell spec corr_sp: ' + str(cell_spec_sp))\n",
    "        print('gene_spec_corr_sp:' + str(gene_spec_sp))\n",
    "        \"\"\"\n",
    "        end = time.time()\n",
    "        duration = (end - start) / 60.\n",
    "        print('completed epoch ' + str(epoch_i))\n",
    "        print('duration(mins): ' + str(duration))\n",
    "        print('patience counter at: ' + str(patience_counter))\n",
    "        \n",
    "        for key, item in metric_dict.items():\n",
    "            item.reset_state()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ac7e69-44a6-4184-a21b-7ec02d704400",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grads_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2558/3861325662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grads_out' is not defined"
     ]
    }
   ],
   "source": [
    "sum([tf.reduce_sum(tf.cast(tf.math.is_nan(x.values[0]),dtype=tf.float32)) for x in grads_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0778d1-feb2-4f0c-aa74-5f9a53d9c8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerReplica:{\n",
       "  0: <tf.Tensor: shape=(), dtype=float32, numpy=0.056567904>,\n",
       "  1: <tf.Tensor: shape=(), dtype=float32, numpy=0.057292085>,\n",
       "  2: <tf.Tensor: shape=(), dtype=float32, numpy=0.05961571>,\n",
       "  3: <tf.Tensor: shape=(), dtype=float32, numpy=0.057243254>,\n",
       "  4: <tf.Tensor: shape=(), dtype=float32, numpy=0.055594444>,\n",
       "  5: <tf.Tensor: shape=(), dtype=float32, numpy=0.06037442>,\n",
       "  6: <tf.Tensor: shape=(), dtype=float32, numpy=0.93506026>,\n",
       "  7: <tf.Tensor: shape=(), dtype=float32, numpy=0.057733983>\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af28eec-8702-4387-b1ad-2ecc92ae6ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
