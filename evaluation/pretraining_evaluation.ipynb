{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fce1a7-ac1b-4f1c-8aae-f7f4c3f25420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 16:29:25.106961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 16:29:25.276914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-24 16:29:25.276946: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-24 16:29:26.216157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 16:29:26.216297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 16:29:26.216311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import src.aformer_atac as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "from src.optimizers import *\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_atac as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f91bfd-ee1f-428d-8c76-aa0bcdd8f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 16:29:27.673487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-24 16:29:27.673545: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-24 16:29:27.673576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 16:29:28.034811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "2023-04-24 16:29:28.056926: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://localhost:48277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-2')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    #options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb91825-4d60-46de-b695-f446906af355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    def one_hot(sequence):\n",
    "        '''\n",
    "        convert input string tensor to one hot encoded\n",
    "        will replace all N character with 0 0 0 0\n",
    "        '''\n",
    "        vocabulary = tf.constant(['A', 'C', 'G', 'T'])\n",
    "        mapping = tf.constant([0, 1, 2, 3])\n",
    "\n",
    "        init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                                   values=mapping)\n",
    "        table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "        input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "        out = tf.one_hot(table.lookup(input_characters), \n",
    "                          depth = 4, \n",
    "                          dtype=tf.float32)\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "g = tf.random.Generator.from_seed(1)\n",
    "\n",
    "with strategy.scope():\n",
    "    list_files = tf.io.gfile.glob(\"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_test_holdout/peak_atlas/*.tfr\")\n",
    "\n",
    "\n",
    "    files = tf.data.Dataset.list_files(list_files)\n",
    "\n",
    "    def deserialize_val(serialized_example,\n",
    "                       input_length,\n",
    "                       max_shift,\n",
    "                       output_length_ATAC,\n",
    "                       output_length,\n",
    "                       crop_size,\n",
    "                       output_res,\n",
    "                       #seq_mask_dropout,\n",
    "                       atac_mask_dropout,\n",
    "                       mask_size,\n",
    "                       log_atac,\n",
    "                       use_atac,\n",
    "                       use_seq,\n",
    "                        g):\n",
    "        \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "        ## parse out feature map\n",
    "        feature_map = {\n",
    "            'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "            'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "            'tss_tokens': tf.io.FixedLenFeature([], tf.string),\n",
    "            'peaks': tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "        ### stochastic sequence shift and gaussian noise\n",
    "\n",
    "        seq_shift=5\n",
    "        stupid_random_seed = g.uniform([], 0, 10000000,dtype=tf.int32)\n",
    "        input_seq_length = input_length + max_shift\n",
    "\n",
    "        ## now parse out the actual data\n",
    "        data = tf.io.parse_example(serialized_example, feature_map)\n",
    "        sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "                                     seq_shift,input_length))\n",
    "        atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                                  out_type=tf.float32),\n",
    "                               [output_length_ATAC,1])\n",
    "        peaks = tf.ensure_shape(tf.io.parse_tensor(data['peaks'],\n",
    "                                                  out_type=tf.int32),\n",
    "                               [output_length])\n",
    "        peaks = tf.expand_dims(peaks,axis=1)\n",
    "        peaks_crop = tf.slice(peaks,\n",
    "                         [crop_size,0],\n",
    "                         [output_length-2*crop_size,-1])\n",
    "\n",
    "\n",
    "        center = (output_length-2*crop_size)//2\n",
    "        ### here set up masking of one of the peaks\n",
    "        mask_indices_temp = tf.where(peaks_crop[:,0] > 0)[:,0]\n",
    "        ridx = tf.concat([tf.constant([center],dtype=tf.int64)],axis=0)   ### concatenate the middle in case theres no peaks\n",
    "        mask_indices=[[ridx[0]-2+crop_size],\n",
    "                      [ridx[0]-1+crop_size],[ridx[0]+crop_size],[ridx[0]+1+crop_size],\n",
    "                      [ridx[0]+2+crop_size]]\n",
    "\n",
    "        st=tf.SparseTensor(\n",
    "            indices=mask_indices,\n",
    "            values=[1.0]*len(mask_indices),\n",
    "            dense_shape=[output_length])\n",
    "        dense_peak_mask=tf.sparse.to_dense(st)\n",
    "        dense_peak_mask_store = dense_peak_mask\n",
    "        dense_peak_mask=1.0-dense_peak_mask\n",
    "        dense_peak_mask = tf.expand_dims(dense_peak_mask,axis=1)\n",
    "\n",
    "        atac_target = atac ## store the target\n",
    "\n",
    "        ### here set up the ATAC masking\n",
    "        num_mask_bins = mask_size // output_res\n",
    "        out_length_cropped = output_length-2*crop_size\n",
    "        edge_append = tf.ones((crop_size,1),dtype=tf.float32)\n",
    "        atac_mask = tf.ones(out_length_cropped // num_mask_bins,dtype=tf.float32)\n",
    "        atac_mask=tf.nn.experimental.stateless_dropout(atac_mask,\n",
    "                                                  rate=(atac_mask_dropout),\n",
    "                                                  seed=[stupid_random_seed+16,stupid_random_seed+10]) / (1. / (1.0-(atac_mask_dropout))) \n",
    "        atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "        atac_mask = tf.tile(atac_mask, [1,num_mask_bins])\n",
    "        atac_mask = tf.reshape(atac_mask, [-1])\n",
    "        atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "        atac_mask_store = 1.0 - atac_mask\n",
    "        full_atac_mask = tf.concat([edge_append,atac_mask,edge_append],axis=0)\n",
    "        full_comb_mask = tf.math.floor((dense_peak_mask+full_atac_mask)/2)\n",
    "        full_comb_mask_store = 1.0 - full_comb_mask\n",
    "        full_comb_mask_store = full_comb_mask_store[crop_size:-crop_size,:]\n",
    "        tiling_req = output_length_ATAC // output_length\n",
    "        full_comb_mask = tf.expand_dims(tf.reshape(tf.tile(full_comb_mask, [1,tiling_req]),[-1]),axis=1)\n",
    "        masked_atac = atac * full_comb_mask\n",
    "\n",
    "        ### now that we have masked specific tokens by setting them to 0, we want to randomly add wrong tokens to these positions\n",
    "        ## first, invert the mask\n",
    "        random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,seed=[10,stupid_random_seed+10])\n",
    "        masked_atac = masked_atac + (1.0-full_comb_mask)*random_shuffled_tokens\n",
    "\n",
    "        if log_atac: \n",
    "            masked_atac = tf.math.log1p(masked_atac)\n",
    "\n",
    "        diff = tf.math.sqrt(tf.nn.relu(masked_atac - 100.0 * tf.ones(masked_atac.shape)))\n",
    "        masked_atac = tf.clip_by_value(masked_atac, clip_value_min=0.0, clip_value_max=100.0) + diff\n",
    "\n",
    "        atac_out = tf.reduce_sum(tf.reshape(atac_target, [-1,tiling_req]),axis=1,keepdims=True)\n",
    "        diff = tf.math.sqrt(tf.nn.relu(atac_out - 2500.0 * tf.ones(atac_out.shape)))\n",
    "        atac_out = tf.clip_by_value(atac_out, clip_value_min=0.0, clip_value_max=2500.0) + diff\n",
    "        atac_out = tf.slice(atac_out,\n",
    "                            [crop_size,0],\n",
    "                            [output_length-2*crop_size,-1])\n",
    "\n",
    "        peaks_gathered = tf.reduce_max(tf.reshape(peaks_crop, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                       axis=1,keepdims=True)\n",
    "        mask_gathered = tf.reduce_max(tf.reshape(full_comb_mask_store, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                       axis=1,keepdims=True)\n",
    "\n",
    "        random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,\n",
    "                                                                         seed=[11,stupid_random_seed+11])\n",
    "        if not use_atac:\n",
    "            masked_atac = random_shuffled_tokens\n",
    "        if not use_seq:\n",
    "            sequence = tf.random.experimental.stateless_shuffle(sequence,\n",
    "                                                                seed=[1,stupid_random_seed+12])\n",
    "\n",
    "\n",
    "        return {'sequence': tf.ensure_shape(sequence,\n",
    "                                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(masked_atac,\n",
    "                                        [output_length_ATAC,1]),\n",
    "                'mask': tf.ensure_shape(full_comb_mask_store,\n",
    "                                        [output_length-crop_size*2,1]),\n",
    "                'mask_gathered': tf.ensure_shape(mask_gathered,\n",
    "                                        [(output_length-crop_size*2)//2,1]),\n",
    "                'peaks': tf.ensure_shape(peaks_gathered,\n",
    "                                          [(output_length-2*crop_size) // 2,1]),\n",
    "                'target': tf.ensure_shape(atac_out,\n",
    "                                          [output_length-crop_size*2,1])}\n",
    "\n",
    "\n",
    "    files = tf.data.Dataset.list_files(list_files)\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(files,\n",
    "                                      compression_type='ZLIB',\n",
    "                                      num_parallel_reads=4)\n",
    "    dataset = dataset.with_options(options)\n",
    "    dataset = dataset.map(lambda record: deserialize_val(record,\n",
    "                                                        262144,\n",
    "                                                        10,\n",
    "                                                        65536,\n",
    "                                                        2048,\n",
    "                                                        256,\n",
    "                                                        128,\n",
    "                                                         #seq_mask_dropout,\n",
    "                                                        0.0,\n",
    "                                                        512,\n",
    "                                                        True,\n",
    "                                                       True,\n",
    "                                                       True,\n",
    "                                                        g),\n",
    "                  deterministic=False,\n",
    "                  num_parallel_calls=4)\n",
    "\n",
    "    dataset = dataset.batch(64,drop_remainder=True).prefetch(tf.data.AUTOTUNE).repeat(1)\n",
    "\n",
    "    test_dist = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "    test_it = iter(test_dist)\n",
    "    test_it_build = iter(test_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0305b462-08ba-4a3a-a07a-f54475f54b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran test input\n",
      "loaded weights\n"
     ]
    }
   ],
   "source": [
    "#with strategy.scope():\n",
    "with strategy.scope():\n",
    "    model = aformer.aformer(kernel_transformation='relu_kernel_transformation',\n",
    "                            dropout_rate=0.30,\n",
    "                            pointwise_dropout_rate=0.10,\n",
    "                            input_length=262144,\n",
    "                            output_length=2048,\n",
    "                            final_output_length=1536,\n",
    "                            num_heads=8,\n",
    "                            numerical_stabilizer=0.0000001,\n",
    "                            nb_random_features=256,\n",
    "                            max_seq_length=2048,\n",
    "                            rel_pos_bins=2048,\n",
    "                            norm=True,\n",
    "                            normalize = True,\n",
    "                            BN_momentum=0.90,\n",
    "                            use_rot_emb = True,\n",
    "                            use_mask_pos = False,\n",
    "                            num_transformer_layers=6,\n",
    "                            inits_type=\"enformer_performer\",\n",
    "                            load_init=True,\n",
    "                            stable_variant=False,\n",
    "                            freeze_conv_layers=False,\n",
    "                            filter_list_seq=[512,640, 768,896,1024,1152],\n",
    "                            filter_list_atac=[32,64],\n",
    "                            output_heads=[\"human\",\"mouse\",\"rhesus\",\"rat\"],\n",
    "                            learnable_PE=True)\n",
    "\n",
    "\n",
    "    def build_step(iterator): #input_batch, model, optimizer, organism, gradient_clip):\n",
    "        @tf.function(jit_compile=True)\n",
    "        def test_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            #global_acc=tf.cast(inputs['global_acc'],dtype=tf.bfloat16)         \n",
    "            input_tuple = sequence,atac#,global_acc\n",
    "\n",
    "            output = model(input_tuple,\n",
    "                           training=False)\n",
    "\n",
    "        for _ in tf.range(1): ## for loop within @tf.fuction for improved TPU performance\n",
    "            strategy.run(test_step, args=(next(iterator),))\n",
    "            \n",
    "            \n",
    "build_step(test_it_build)\n",
    "print('ran test input')\n",
    "#model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_262k_load-True_LR-0.01_T-7_D-0.3_2023-04-13_15:39:43/final/saved_model\")\n",
    "model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_262k_load-True_LR-0.01_T-7_D-0.3_2023-04-14_18:27:56/iteration_30/saved_model\")\n",
    "print('loaded weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71878139-2569-40ab-a0b9-744b82a1e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    metric_dict[\"corr_stats_atac\"] = metrics.correlation_stats_gene_centered(name='corr_stats')\n",
    "    metric_dict[\"corr_stats_peaks\"] = metrics.correlation_stats_gene_centered(name='corr_stats')\n",
    "    def dist_test_step(iterator):\n",
    "        @tf.function(jit_compile=True)\n",
    "        def test_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            mask=tf.cast(inputs['mask'],dtype=tf.int32)\n",
    "            mask_gathered=tf.cast(inputs['mask_gathered'],dtype=tf.int32)\n",
    "            peaks=tf.cast(inputs['peaks'],dtype=tf.float32)\n",
    "            \n",
    "            input_tuple = sequence,atac#,global_acc\n",
    "\n",
    "            output_profile,output_peaks = model(input_tuple,\n",
    "                                                training=False)\n",
    "            output_profile = tf.cast(output_profile['human'],dtype=tf.float32) # ensure cast to float32\n",
    "            output_peaks = tf.cast(output_peaks['human'],dtype=tf.float32)\n",
    "            \n",
    "            mask_indices = tf.where(mask[0,:,0] == 1)[:,0]\n",
    "            \n",
    "            target_atac = tf.gather(target[:,:,0], mask_indices,axis=1)\n",
    "            output_atac = tf.gather(output_profile[:,:,0], mask_indices,axis=1)\n",
    "            \n",
    "            \n",
    "            mask_gather_indices = tf.where(mask_gathered[0,:,0] == 1)[:,0]\n",
    "            target_peaks = tf.gather(peaks[:,:,0], mask_gather_indices,axis=1)\n",
    "            output_peaks = tf.gather(output_peaks[:,:,0], mask_gather_indices,axis=1)\n",
    "\n",
    "            #dummy_var = tf.ones(target_atac.shape,dtype=tf.int32)\n",
    "            \n",
    "            return target_atac, output_atac, target_peaks, output_peaks#,dummy_var\n",
    "            \n",
    "        \n",
    "        ta_pred_atac = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False) # tensor array to store preds\n",
    "        ta_true_atac = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False) # tensor array to store vals\n",
    "        ta_pred_peaks = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False) # tensor array to store preds\n",
    "        ta_true_peaks = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False)  \n",
    "        ta_dummy_pk = tf.TensorArray(tf.int32, size=0, dynamic_size=True,clear_after_read=False) \n",
    "        ta_dummy_atac = tf.TensorArray(tf.int32, size=0, dynamic_size=True,clear_after_read=False) \n",
    "            \n",
    "        for _ in tf.range(1018): ## for loop within @tf.fuction for improved TPU performance\n",
    "            pred_atac_rep,true_atac_rep, pred_peaks_rep,true_peaks_rep = \\\n",
    "                strategy.run(test_step,\n",
    "                             args=(next(iterator),))\n",
    "            \n",
    "            #print(pred_atac_rep)\n",
    "            \n",
    "            pred_atac_reshape = tf.reshape(strategy.gather(pred_atac_rep, axis=1), [-1]) # reshape to 1D\n",
    "            true_atac_reshape = tf.reshape(strategy.gather(true_atac_rep, axis=1), [-1])\n",
    "            pred_peaks_reshape = tf.reshape(strategy.gather(pred_peaks_rep, axis=1), [-1]) # reshape to 1D\n",
    "            true_peaks_reshape = tf.reshape(strategy.gather(true_peaks_rep, axis=1), [-1])\n",
    "            \n",
    "            dummy_reshape_pk = tf.ones(true_peaks_reshape.shape,dtype=tf.int32)#tf.reshape(strategy.gather(dummy_int, axis=0), [-1])\n",
    "            dummy_reshape_atac = tf.ones(true_peaks_reshape.shape,dtype=tf.int32)\n",
    "\n",
    "            ta_pred_atac = ta_pred_atac.write(_, pred_atac_reshape)\n",
    "            ta_true_atac = ta_true_atac.write(_, true_atac_reshape)\n",
    "            ta_pred_peaks = ta_pred_peaks.write(_, pred_peaks_reshape)\n",
    "            ta_true_peaks = ta_true_peaks.write(_, true_peaks_reshape)\n",
    "            \n",
    "            ta_dummy_pk = ta_dummy_pk.write(_, dummy_reshape_pk)\n",
    "            ta_dummy_atac = ta_dummy_atac.write(_, dummy_reshape_atac)\n",
    "            \n",
    "        metric_dict[\"corr_stats_atac\"].update_state(ta_pred_atac.concat(),\n",
    "                                                    ta_true_atac.concat(),\n",
    "                                                    ta_dummy_atac.concat(),\n",
    "                                                    ta_dummy_atac.concat())\n",
    "        metric_dict[\"corr_stats_peaks\"].update_state(ta_pred_peaks.concat(),\n",
    "                                                     ta_true_peaks.concat(),\n",
    "                                                     ta_dummy_pk.concat(),\n",
    "                                                     ta_dummy_pk.concat())\n",
    "        ta_pred_atac.close()\n",
    "        ta_true_atac.close()\n",
    "        ta_pred_peaks.close()\n",
    "        ta_true_peaks.close()\n",
    "        ta_dummy_pk.close()\n",
    "        ta_dummy_atac.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510472c2-3278-4a5a-84e0-f1c8d0822fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    for k in range(1):\n",
    "        dist_test_step(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0532a8-303c-48d3-884f-fed17a487ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_trues_peaks = metric_dict['corr_stats_peaks'].result()['y_trues'].numpy()\n",
    "y_preds_peaks = metric_dict['corr_stats_peaks'].result()['y_preds'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6f944f-46b3-4025-a412-f6689ea1b36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAArVklEQVR4nO3deXhUZZrH/e+dhCXsQUKAALLKTlACuIDiyiKKKCoqIGgTcRt73pl+7XZ6m7Gnu6enX3vsBhFEQEBBbBaxQR0FRVxAg7KHHYGw7/ue+/2jCslgKIoklaokv8911ZWqU0+dc58j1q/O8jzH3B0REZGLiYt2ASIiEtsUFCIiEpKCQkREQlJQiIhISAoKEREJSUEhIiIhKSik2DCzR8zsf8No96qZ/aooaioKZva9md0WfP5bM5sY7ZqkdFFQSKEIfpkdN7MjZrbTzMaaWaXCXIa7v+nud4TRbqi7v1iYyz7HzNzMjgbXc6uZvWRm8ZFYVn6YWRUz+x8z2xyscV3wdY1o1ybFl4JCCtNd7l4JuAboAPzywgZmllDkVRW+tOB63gQ8CDwW5XoAMLOywBygFdAdqAJcD+wFOuZjfiXhv5UUAgWFFDp33wq8D7SGH36FP21ma4G1wWm9zGyxmR0wsy/NrO25z5tZPTObZma7zWyvmQ0LTh9kZp8Hn5uZ/cXMdpnZQTNbambnljfOzH6Xa35Dgr+s95nZTDOrk+s9N7OhZrbWzPab2XAzszDXcx3wBdAu1/zys16NzWxucNoeM3vTzKpd5mYHGAjUB/q4+0p3z3H3Xe7+orvPzrW+TXLV9MO2MrOuZpZtZs+b2Q5grJllmVmvXO0TgjVeE3x9bXA9D5jZEjPrmo+6JcYpKKTQmVk9oCfwXa7J9wCdgJbBL5kxwBPAFcBIYKaZlQsexvkHsAloAKQCk/NYzB3AjcBVQDUCv+z35lHLLcAfgAeA2sH5Xji/XgT2gNKC7bqFuZ7NgS7AuuDr/K6XBWusA7QA6gG/DaeGC9wGfODuR/Lx2XNqAdWBK4EMYBLwUK73uwF73P1bM0sFZgG/C37mX4GpZpZcgOVLDFJQSGGaYWYHgM+BecDvc733B3ff5+7HgSHASHdf6O5n3f0N4CRwLYFDJHWAn7n7UXc/4e6f57Gs00BloDlg7p7l7tvzaPcIMMbdv3X3k8AvgOvMrEGuNn909wPuvhn4hFx7CBfxrZkdBbKAT4FXgtPztV7uvs7dP3L3k+6+G3iJwGGty3UFkNc2uBw5wG+CtRwH3gLuNrMKwfcfDk4D6A/MdvfZwb2Xj4BMAj8SpARRUEhhusfdq7n7le7+VPCL5pwtuZ5fCfxL8HDFgWC41CPwRVoP2OTuZ0ItyN3nAsOA4cBOMxtlZlXyaFqHwK/4c587QmDPIzVXmx25nh8DKgGY2YrgCeEjZtYlV5trgm0eJLCXVLEg62VmNc1scvDk+CFgIpCfk897Cew1FcRudz9x7kXw8FoWcFcwLO7mfFBcCdx/wfp2LoQaJMYoKKSo5B6meAvwn8FQOfeo4O6Tgu/VD+dEqrv/1d3bEzh5exXwszyabSPwhQaAmVUk8Mt7axjzb+XulYKP+Re85+4+BfgK+HUB1+sPBLZPW3evQuCXeljnSS7wMdAtuI4XcwyokOt1rQvez2s46XOHn3oDK4PhAYF1mnDB+lZ09z/mo3aJYQoKiYbXgKFm1il4Urqimd1pZpWBrwkcPvljcHp5M7vhwhmYWYfg58sAR4ETwNk8lvUWMNjM2plZOQKHwxa6+/eFtC5/BDLMrFYB1qsycAQ4EDzun1fghWMCgS/vqWbW3MzizOwKM3vBzM4dDloMPGxm8WbWnfAOcU0mcE7oSc7vTUBgz+cuM+sWnF/54AnxuvmsX2KUgkKKnLtnEjiePwzYT+Bk8KDge2eBu4AmwGYgm8AhngtVIfDFvJ/AoaW9wJ/zWNYc4FfAVAJf1I2BfoW4LssInI/5WQHW698JHM46SODk8LR81nKSwAntVcBHwCECAVUDWBhs9lywjgMEzt/MCGO+2wnsOV0PvJ1r+hYCexkvALsJhNTP0PdKiWO6cZGIiISi5BcRkZAiFhRmNsYCnaGWX+R9M7O/WqAj1NJzHXhERCS2RHKPYhyBYQQupgfQNPjIAEZEsBYREcmniAWFu38G7AvRpDcwPniZ4QKgmpnp+msRkRgTzUG/Uvm/nbCyg9N+1LPUzDII7HWQSGL7alQDoFJKJarUzauPlYiI5LZo0aI97p6v4VWiGRR5dSjK8xIsdx8FjAK4uu3VPm/2PF6//nUadG1An/F9crfj7Kmz5JzJoWzFshEpWkSkODKzTZdulbdoBkU2gWENzqlLoBdtSPFl46lStwonD51k6YSlnD15lrrX1+Xrv33NgY0H8JxA1lRvUp3Ujqlc+8/XUuvqWsTF6wIvEZH8iGZQzASeMbPJBMbLOXiRQd3y1OzuZiydsJQVU1awYsoKLM5ocV8LqjWsRnyZeLZ+vZWsaVkse2sZVepWIbVjKklNkmjaoyl10utQtpL2OEREwhGxDndmNgnoSqBX6E7gN0AZAHd/1cyMQA/W7gTGnxkc7NkaUnp6umdmBprtztrNGze/Qe8xvWnas+mP2u7fuJ81/1jD93O/Z8+qPezfsJ+zpwKjPJRPKk+zu5tRpW4VqtavSu32tanepDrlq5YvhLUXEYktZrbI3dPz9dni1jM7d1BcrtPHTrP6vdUc3HSQtbPWsmPJDk4dPvXD4aqExASuvPFKKtepTIXkCrS4twWpHVKxuPyMzyYiEjsUFAXg7uxatot96/ex7v11bP16K8f3HufwtsN4jpN4RSLpT6bTpFsT6neuX2jLFREpSgqKCDiy4whr31/L6hmrWT1zNQBJjZOILxNP3WvrknhFIq37taZ2+9pYeHfOFBGJGgVFhB3cfJClby5l68KtnDlxhu3fbufE/hPknMmhSr0qNO7WmGoNqlHhigokXpFIzVY1SWqURHy5eIWIiMSEggRFNK96Kjaq1q9Kl190+T/Tju87Ttb0LNbOWkvW37M4ceDEjz6XeEUi1ZtUp37n+tTvXJ8rml1BUqMkEspps4tI8aE9ikJy5uQZTuw/wZGdR9i5ZCcHNx9k/8b97Fuzj61fbz1/tVW18jS+ozGpnVJJ7ZRK7WtqUyaxTJSrF5GSTnsUMSChXAKValWiUq1K1Er7v3eXPHPiDNu/287+DftZ/8F6Nn22iRVTVgAQlxBHSloKqZ1SqXttXZr2aEqFGhXyWoSISFRojyJKjuw4QvbCbLIXZLN14Va2fbONU0dOUb5aea666yqu6nUVTbo3oVyVctEuVURKAJ3MLgFyzuaw/dvtLHhpARs+3sCxPceIKxNHg64NaHZ3Mxre0pBqDapRpoIOU4nI5VNQlDA5Z3PI/iqb1TNXs/rd1exdsxeAMhXKUPfauiS3TqZWWi1S0lKo2aomCeV1BFFEQlNQlHB71+wle0E22Quz2Z65nV0rdnH66GkALN6o0bwGbfu3pX6X+iS3TCYxKTHKFYtIrFFQlDKe4+xbv4+dS3ayY8kONs3bxOb5m394v1LtStS9ti6t+7WmcbfGGr9KRBQUAgc2HWDX8l3sXrGb3St2s+7DdRzdeZS4hDjq3VCP5FbJ1Glfh/qd61O9aXV1BBQpZRQU8iM5Z3LIXpDNmllr2PDRBvat3cfJQycBqFizYqATYJdAR8Ba7WoRl6D7dYiUZAoKuSTPcfas3sPm+ZvZ/HngcWDjAQDKVCxDk+5NaNK9CakdU0lulawbPYmUMAoKyZdD2YfY/MVmNs3bRNbULI7uOgpAhRoVaNWvFe2HtKdmm5o6TCVSAigopMDcnX3r9rF14VbWzlrLyqkryTmdQ8WUijS8pSGNbmtEo9saUbV+1WiXKiL5oKCQQndumPWNH29kw5wNHN0Z2NtISUuhxX0taHx7Y2pdXUsDHIoUEwoKiSh3/+FKqlXTVrHlyy0AlK1UlqZ3NqV5n+Y07dmUcpU13IhIrFJQSJE6suMIW77cwroP17F6xmqO7jpKfNl4Gt3WiCY9mtD4jsa6BFckxigoJGpyzuaw5cstrJq+itXvrmb/hv0AVGtQjeZ9mpM2MI2UtBSFhkiUKSgkZuxbv4/1H65n3fvrWPfhOnJO55CSlsI1Q66h0W2NqNGsRrRLFCmVFBQSk47tPcaKt1fw7ehv2fHdDgBa3NeCFve2oEmPJhqTSqQIKSgk5u1asYsl45fw3ejvOL7vOAnlE2h+T3PaDW5H/S71dZc/kQhTUEixcfbUWbZ+vZVlby1j2VvLOHnwJOWTytP+ifa0faQtNVvXjHaJIiWSgkKKpdPHTvP9p9+T+Woma2evxc86NdvU5Joh13DNT67RXoZIIVJQSLF3ZOcRVr6zkqUTlrL1662UTypP2sA0rn78amq21jAiIgWloJASw93Z9NkmFr266IdhRKo3rU7ao2m0z2hPxeSK0S5RpFhSUEiJdHTXUbKmZbFiygq+/+R74svF07Z/Wzo914mUNinRLk+kWFFQSIm3e+VuFv51IUvGL+HM8TM0uLkB1/70Wpre2VRDoouEQUEhpcbxfcf5dvS3fD3saw5tOURSoyQ6PtuRqx+7mnJVNNaUyMUoKKTUyTmTQ9b0LBa+vJAtX2yhbOWytBvcjk7PdqJ6k+rRLk8k5igopFTblrmNhS8vZPnby8k5k8NVva6i03OdaHhLQ10tJRKkoBABDm8/TOaITDJfzeTY7mPUbF2T9CfTaf1Qaw0XIqWegkIklzMnzrB88nIWvryQHYt3EF82nmZ3NyNtUBpNujUhLkEnv6X0UVCI5MHd2bF4B4vHLWb5W8s5tucYFVMqcvXjV9PlhS6UrVg22iWKFJmYDQoz6w68DMQDo939jxe8XxWYCNQHEoA/u/vYUPNUUEh+nD11lrWz17J43GJWv7uaxCsSuePPd9DmkTbEl4mPdnkiEReTQWFm8cAa4HYgG/gGeMjdV+Zq8wJQ1d2fN7NkYDVQy91PXWy+CgopqOwF2bz/T++z7Ztt1OlQh57De5LaITXaZYlEVEGCIpIHazsC69x9Q/CLfzLQ+4I2DlS2wKUplYB9wJkI1iRC3Wvr8pMFP+G+Sfexf8N+RncczZT7pnBsz7FolyYSkyIZFKnAllyvs4PTchsGtAC2AcuA59w958IZmVmGmWWaWebu3bsjVa+UIhZntO7Xmuc2PkfX/+jKmn+s4S/1/sK7j73LzmU7o12eSEyJZFDkdQH7hce5ugGLgTpAO2CYmVX50YfcR7l7urunJycnF3adUoqVq1yOm351E0Myh5A2KI0Vb6/g1bavMuGOCaz7YB3F7WIPkUiIZFBkA/Vyva5LYM8ht8HANA9YB2wEmkewJpE8pbRJodeIXvzzln/mlt/fwq7lu3izx5uMaD2Cb0d/y5kTOiIqpVckg+IboKmZNTSzskA/YOYFbTYDtwKYWQrQDNgQwZpEQkqsnkiXX3Thp9//lHvG30N82XjeG/Iew5oNY+XUldrDkFIpYkHh7meAZ4APgSxgiruvMLOhZjY02OxF4HozWwbMAZ539z2RqkkkXPFl40kbkEbGtxkM+GgA5auV552+7zCx20T2rNI/USld1OFOJAw5Z3LIfDWTub+cy+mjp+n0XCdu+vVNGrFWio1YvTxWpMSIS4ij4zMdeXbNs6Q9msZXL33FsGbDWDZpmQ5HSYmnoBC5DBVrVuTu0Xfzk4U/oXJqZaY9PI0Jt01gd5Yu25aSS0Ehkg+pHVL5ycKf0POVnmxbtI1XWr3C233e1vkLKZEUFCL5FBcfR4cnO/Dsmme58Zc3smHOBkZePZJvRnyD5+hwlJQcCgqRAqpYsyI3/8fNPLv2Wep3rs/sp2YztstYdq3YFe3SRAqFgkKkkFRKqUT//+1P73G92bNqDyOvHsncX81VZz0p9hQUIoXIzGj3aDueXvU0rfu1Zv7v5jOi7QiypmfpcJQUWwoKkQiomFyRPuP70P9/+4PDlHun8FrH19j8+eZolyZy2RQUIhHU+PbGPJ31NPeMv4cjO44wtstY/v7g3znw/YFolyYSNgWFSITFJcSRNiCNZ1Y/w02/uYnV761mWPNhzPm3OZw8fDLa5YlckoJCpIiUrViWrr/tyjOrn6Fl35Z8/vvPGdF6BNkLs6NdmkhICgqRIla1XlXunXgvj33xGBZnjLlhDLOensXx/cejXZpInhQUIlFS7/p6ZHybQfsn2rNo5CJeS3+NzFczyTn7o5s8ikSVgkIkihKTErlz+J0M+nQQ5auVZ9aTs3j9utfZ+s3WaJcm8gMFhUgMqN+5PkMyh3Df5Ps4uPkgozuOZvrA6RzedjjapYkoKERihZnR+sHWPLvmWW74+Q2smLKC4S2H8+3obzWUuUSVgkIkxpSrUo7b/nAbTy1/ilrtavHekPeYcNsE9m/YH+3SpJRSUIjEqOpNqvPo3Ee589U72frNVka0GcEXf/pCY0dJkVNQiMQwizPSn0jn6ZVP0/DWhnz8/McMazaMJROW6HCUFBkFhUgxUKVuFR6a+RAD5wykQo0KzBg4g/G3jmf9R+sVGBJxCgqRYqThLQ0Z8s0Qeg7vye6Vu5l4x0TGXD8mMDqtAkMiREEhUsxYnNHhqQ78dNNP6TWyF4eyDzHl3imMuWGM+l9IRCgoRIqphHIJtM9oz3PfP0fvsb3Zv2E/ozuOZsagGRzerv4XUngUFCLFXFx8HO0GtQv0v3j+BpZPWs6wq4Yx/w/zdYWUFAoFhUgJUa5KOW774208tfIpGt3WiLkvzGVU+1Fs/257tEuTYk5BIVLCVG9cnQenP8gj7z/CiQMnGN1pNAteXqBbsUq+KShESqgm3Zvw5LInadK9CR/+9EMmdpvIvnX7ol2WFEMKCpESLLF6Ig9Of5Aew3qw+YvNDGs+jPcy3uPIjiPRLk2KEQWFSAkXFx9Hx6c78tyG5+jwdAcWj13M35r+jfm/n8/p46ejXZ4UAwoKkVKiUq1K9Hi5R+Bk9+2NmPtvcxndaTR71+6NdmkS4xQUIqXMFU2v4MFpD/Lw7Ic5vO0wo9qPYvnby9WzWy5KQSFSSjXt0ZQnvnuCmq1qMrXfVCb3nsyBTQeiXZbEIAWFSClWtV5VBs8fzO1/vp2NczcyvMVw5v9+PmdPn412aRJDFBQipVxcQhzX/8v1PJ31NE17NmXuv81lbJex7FiyI9qlSYyIaFCYWXczW21m68zs5xdp09XMFpvZCjObF8l6ROTiqtarygN/f4C+b/dl//r9jO08luWTl0e7LIkBEQsKM4sHhgM9gJbAQ2bW8oI21YBXgLvdvRVwf6TqEZHwtHqgFUOXDCW5VTJTH5rKrKdm6TLaUi6SexQdgXXuvsHdTwGTgd4XtHkYmObumwHcfVcE6xGRMFWuU5nHPn+M6/71OjJHZPJyw5dZ+ubSaJclURLJoEgFtuR6nR2clttVQJKZfWpmi8xsYF4zMrMMM8s0s8zdu3dHqFwRyS0uIY47/vsOHv30Uao1qMb0/tOZOWSmRqQthSIZFJbHtAsv1E4A2gN3At2AX5nZVT/6kPsod0939/Tk5OTCr1RELqrBTQ147IvH6PxCZ74b/R1jOo9hd5Z+sJUmkQyKbKBertd1gW15tPnA3Y+6+x7gMyAtgjWJSD7Excdx63/eyoMzHuTAxgOM7jSa78Z8pxFpS4mwgsLMbjCzj8xsjZltMLONZrbhEh/7BmhqZg3NrCzQD5h5QZt3gS5mlmBmFYBOQNblroSIFI3mvZuT8W0GKW1TmPn4TMbdNE530ysFwt2jeB14CegMdADSg38vyt3PAM8AHxL48p/i7ivMbKiZDQ22yQI+AJYCXwOj3V3X44nEsGpXVmPwZ4PpPbY327/bzmsdXmPbogsPFkhJYuGM72JmC929UxHUc0np6ememZkZ7TJEBNi5dCeT7prE0V1H6TWqF2kDdOQ4VpnZIndPz89nw92j+MTM/tvMrjOza8498rNAESk5UtqmMCRzCHWvrcuMgTOY+ZOZnDp6KtplSSFLCLPdub2J3GnkwC2FW46IFDcVkysy4KMBfPrbT5n/+/ls+XILfd/uS0qblGiXJoUkrENPsUSHnkRi14Y5G5jefzrH9x+n21+6kT40HbO8rpSXohbxQ09mVtXMXjrX6c3M/j8zq5qfBYpIydXo1kYMXTKUhjc3ZPZTsxnbZazu010ChHuOYgxwGHgg+DgEjI1UUSJSfFWsWZGHZz1Mr5G92Ll0J6+0foUv/vSF+lwUY+Fe9bTY3dtdalpR0KEnkeLj8LbDvP/s+2RNy6LR7Y3oPbY3VVKrRLusUqkorno6bmadcy3wBuB4fhYoIqVH5TqVuf/v99NrZC82zdvEKy1fYe3stdEuSy5TuEHxJDDczL43s03AMGBo5MoSkZLCzGif0Z6hS4dSrUE13rrzLT759Se6i14xcllXPZlZFQB3PxSxii5Bh55Eiq/Tx08z+6nZLB63mNrta9NnQh+SW2igz6JQkENPIYPCzPq7+0Qz+3/yet/dX8rPQgtCQSFS/GVNy+K9jPc4few03f7SjfYZ7XUZbYRF8hxFxeDfyhd5iIhcthb3tuDJZU9S7/p6zBo6ize7v8mBTQeiXZZchDrciUjU5JzJIfPVTOb8Yg5xCXHcN+k+mnRvEu2ySqSi6HD3JzOrYmZlzGyOme0xs/75WaCIyDlxCXF0fKYjQ5cMpWr9qrzZ803mvTiPnLM50S5Ncgn3qqc7giewexG42dBVwM8iVpWIlCpJjZJ4/KvHafNwGz799ae82eNNDS4YQ8INijLBvz2BSe6uPvkiUqjKVChDnwl96DWqFxvnbGT8rePZt15fNbEg3KB4z8xWERg9do6ZJQMnIleWiJRGZkb7Ie25/5372bNqDyOvHsn6j9ZHu6xSL6ygcPefA9cB6e5+GjgK9I5kYSJSerW4twVPLn2SpIZJvHXnWyz860KK24U3JUnIoDCzW4J/7wVuBnoHn3cHro98eSJSWlWtX5VHP32UJt2b8MFzHzDxjokc2hq1vr6l2qX2KG4K/r0rj0evCNYlIkJiUiL93u3Hna/eyZavtgTuz52p+3MXNfWjEJFiYeeynUzqNYnD2w/T9d+7csPPbiAuIdzTrFIU/Sh+b2bVcr1OMrPf5WeBIiL5kdImhYxFGTS/pzlzX5jL+FvH6xLaIhJuHPdw9wPnXrj7fgKXyoqIFJkKNSpw/5T7ueeNe9j8+WbeuvMtju09Fu2ySrxwgyLezMqde2FmiUC5EO1FRCImbWAafSb0YcsXW3il1Sts+HhDtEsq0cINiokE+k88bmaPAR8Bb0SuLBGR0No83IYh3wwhMSmRCXdM4NPffqpLaCMkIZxG7v4nM1sK3AYY8KK7fxjRykRELqFWu1pkLMpg1lOzmPfv8zjw/QF6Du9J2Yplo11aiRJWUARlAWfc/WMzq2Bmld39cKQKExEJR5kKZQL34q5Xhfm/m8/OpTt5YOoDJDVMinZpJUa4Vz0NAf4OjAxOSgVmRKgmEZHLYmbc8uItPPTeQxzYeIBR14xi6cSl0S6rxAj3HMXTwA3AIQB3XwvUjFRRIiL5cVWvq8hYlMEVV13B9AHT+cfQf5BzRkOWF1S4QXHS3X+4YNnMEgCdNRKRmJPUKInHvniM6/7lOhaNXMSkuydx8vDJaJdVrIUbFPPM7AUg0cxuB94B3otcWSIi+ReXEMcdf76DnsN7su6Ddbx+7eu61WoBhBsUzwO7gWXAE8Bs4JeRKkpEpDB0eKoDAz4awOFthxlz/RhWz1ytS2jz4ZJBYWZxwDJ3f83d73f3vsHn2toiEvMa3dqIQfMGUT6pPJN7T+ad+9/h5CEdiroclwwKd88BlphZ/SKoR0Sk0KW0TeGJ757glt/fwqrpqxjWbJhGob0M4R56qg2sMLM5Zjbz3COShYmIFKb4MvF0+UUXHl/wOAnlExh30zhWTl0Z7bKKhbCGGTezm/Ka7u7zCr2iS9Aw4yJSUEd2HmFy78lsXbiVm1+8mS7/1gUzi3ZZERWxYcbNrLyZ/RS4H2gOfOHu8849wiisu5mtNrN1ZvbzEO06mNlZM+t7uSsgInK5KqVUYvBng2nzSBs++dUnvDfkPc6eOhvtsmLWpYbweAM4DcwHegAtgefCmbGZxQPDgduBbOAbM5vp7ivzaPdfgMaOEpEiE182nj4T+lCtYTXm/24+e7L2cP/f76dy7crRLi3mXOocRUt37+/uI4G+QJfLmHdHYJ27bwh21psM9M6j3bPAVGDXZcxbRKTAzg390fftvuxYvINR7Uexc+nOaJcVcy4VFKfPPXH3M5c571RgS67X2cFpPzCzVKAP8GqoGZlZhpllmlnm7t27L7MMEZHQWj3QiscXPI7FGW/c/AZrZq2Jdkkx5VJBkWZmh4KPw0Dbc8/N7NAlPpvXmaELz5z/D/C8u4c8OOjuo9w93d3Tk5OTL7FYEZHLl9ImhUHzBlG5TmUm9ZrEZ//5mTrnBYU8R+Hu8QWYdzZQL9frusCFFy6nA5ODVxvUAHqa2Rl3n1GA5YqI5Ev1xtUZkjmEmY/N5JNffsLu5bu5+/W7KVOhTLRLi6rLuR/F5foGaGpmDYGtQD/g4dwN3L3huedmNg74h0JCRKIpoVwCfSb2oWabmsx5YQ571+6l34x+VKlbJdqlRU24He4uW/CcxjMErmbKAqa4+wozG2pmQyO1XBGRgjIzOv+8M/3e7cfe1XsZ3Wk0h7IvdbS95Aqrw10sUYc7ESlKO5bsYGyXsVSsWZGHZj5EcsvieZ40Yh3uRERKu1pptej/YX9OHT7Fax1fI2t6VrRLKnIKChGRS6h3XT0yvs2gZquaTLl3Cgv/tjDaJRUpBYWISBiqpFZh0LxBNOvdjA/+6QM+/JcP8Zzideg+vxQUIiJhSiifwP1T7qfDMx1Y8NICpvWfVirGiIrk5bEiIiVOfNl4evy1B5XrVGbuC3M5tvsYD0x7gHKVy0W7tIjRHoWIyGUyM7r8ogu9x/Zm4ycbeaPrGxzZeSTaZUWMgkJEJJ/aDWrHQzMfYs+qPYztPJbD2w9Hu6SIUFCIiBRA055NGfDRAA5vP8z4W8ZzdPfRaJdU6BQUIiIFVO/6ejwy+xEOfH+AcTeOY//G/dEuqVApKERECsGVN15J/w/7c2TnEcZ2HsuB7w9Eu6RCo6AQESkkV954JYM/G8zp46cZ13UcO5bsiHZJhUJBISJSiGq2rsmAjwaQcyaH1697neVvL492SQWmoBARKWR12tchIzOD2lfXZmq/qXz+x8+jXVKBKChERCKgUq1KPPrJo7R+qDVzfjGHef8xr9jeMU89s0VEIiS+bDx9xvchvkw8n/7mU04cPMEdf76D4F09iw0FhYhIBMUlxNF7bG/KVS3HgpcWcOLACe4aeRdxCcXngI6CQkQkwizO6P5yd8pXK89nL37GiX0nuPeteymTWDzuxV18Ik1EpBgzM27+j5vp/tfurHp3FRO7TeTEwRPRLissCgoRkSLU6dlO3DfpPrK/yuatnm9x6uipaJd0SQoKEZEi1vrB1tw3+T6yF2Qz/pbxHN4W24MJKihERKKg5X0teWDqA+xavosRbUeQvTA72iVdlIJCRCRKmt/TnIxFGZSvWp43u7/JzmU7o11SnhQUIiJRVKN5DQbOGUhCYgLjbhrH+o/WR7ukH1FQiIhEWbUG1Rg8fzBVUqvwZvc3+eJPX8RUL24FhYhIDKjeuDqPf/U4Le5rwcfPf8w7fd/h+P7j0S4LUFCIiMSMspXK0vftvtz+37ezeuZqRl0ziv0bon8TJAWFiEgMMTOu/9frGfz5YE4eOsmYzmPYs2pPVGtSUIiIxKC6neoyaN4gzp46y2sdXmPpxKVRq0VBISISo2q2rskT3z1BratrMX3AdGY8OoNTR4q+J7eCQkQkhlWtV5VH5z7Kjb++kSUTlvBah9fYtWJXkdagoBARiXFxCXHc/O83M3DOQI7vP87ojqNZNmlZkV1Cq6AQESkmGt7ckCe+e4KUtBSmPTyNKfdN4ciOIxFfroJCRKQYqVy7MoM/G8xt/3Uba2evZXjL4SwZvySiexcKChGRYiYuIY4b/t8bGLpkKMktk5nx6Aze6vkWB7ccjMzyIjLXIDPrbmarzWydmf08j/cfMbOlwceXZpYWyXpEREqSGs1qMPizwfT4Ww82zd/EiDYjWPv+2kJfTsSCwszigeFAD6Al8JCZtbyg2UbgJndvC7wIjIpUPSIiJZHFGR2f6ciTS58kqVESk3pN4pNff8LZ02cLbRmR3KPoCKxz9w3ufgqYDPTO3cDdv3T3c/3TFwB1I1iPiEiJldQoicHzB9N2QFs+e/EzxnYZy771+wpl3pEMilRgS67X2cFpF/M48H5eb5hZhpllmlnm7t27C7FEEZGSo2zFstwz7h76vt2Xvav3MrLdSNb/b8GHLY9kUFge0/I8LW9mNxMIiufzet/dR7l7urunJycnF2KJIiIlT6sHWjF06VCSGicx6a5JrJm1pkDzi2RQZAP1cr2uC2y7sJGZtQVGA73dfW8E6xERKTXO9ehObpXMtEemFWhekQyKb4CmZtbQzMoC/YCZuRuYWX1gGjDA3QsWeSIi8n8kVk/k7tF3c/LQyQLNJ2JB4e5ngGeAD4EsYIq7rzCzoWY2NNjs18AVwCtmttjMMiNVj4hIaVT7mtq0G9SuQPOwWLrdXjjS09M9M1N5IiISrpyzOcQnxC9y9/T8fF49s0VESri4+IJ91SsoREQkJAWFiIiEpKAQEZGQFBQiIhKSgkJEREJSUIiISEgKChERCUlBISIiISkoREQkJAWFiIiEpKAQEZGQFBQiIhKSgkJEREJSUIiISEgKChERCUlBISIiISkoREQkJAWFiIiEpKAQEZGQFBQiIhKSgkJEREJSUIiISEgKChERCUlBISIiISkoREQkJAWFiIiEpKAQEZGQFBQiIhKSgkJEREJSUIiISEgKChERCUlBISIiISkoREQkJAWFiIiEFNGgMLPuZrbazNaZ2c/zeN/M7K/B95ea2TWRrEdERC5fxILCzOKB4UAPoCXwkJm1vKBZD6Bp8JEBjIhUPSIikj+R3KPoCKxz9w3ufgqYDPS+oE1vYLwHLACqmVntCNYkIiKXKSGC804FtuR6nQ10CqNNKrA9dyMzyyCwxwFw0syWF26pxVYNYE+0i4gR2hbnaVucp21xXrP8fjCSQWF5TPN8tMHdRwGjAMws093TC15e8adtcZ62xXnaFudpW5xnZpn5/WwkDz1lA/Vyva4LbMtHGxERiaJIBsU3QFMza2hmZYF+wMwL2swEBgavfroWOOju2y+ckYiIRE/EDj25+xkzewb4EIgHxrj7CjMbGnz/VWA20BNYBxwDBocx61ERKrk40rY4T9viPG2L87Qtzsv3tjD3H50SEBER+YF6ZouISEgKChERCSlmg0LDf5wXxrZ4JLgNlprZl2aWFo06i8KltkWudh3M7KyZ9S3K+opSONvCzLqa2WIzW2Fm84q6xqISxv8jVc3sPTNbEtwW4ZwPLXbMbIyZ7bpYX7N8f2+6e8w9CJz8Xg80AsoCS4CWF7TpCbxPoC/GtcDCaNcdxW1xPZAUfN6jNG+LXO3mErhYom+0647iv4tqwEqgfvB1zWjXHcVt8QLwX8HnycA+oGy0a4/AtrgRuAZYfpH38/W9Gat7FBr+47xLbgt3/9Ld9wdfLiDQH6UkCuffBcCzwFRgV1EWV8TC2RYPA9PcfTOAu5fU7RHOtnCgspkZUIlAUJwp2jIjz90/I7BuF5Ov781YDYqLDe1xuW1Kgstdz8cJ/GIoiS65LcwsFegDvFqEdUVDOP8urgKSzOxTM1tkZgOLrLqiFc62GAa0INChdxnwnLvnFE15MSVf35uRHMKjIApt+I8SIOz1NLObCQRF54hWFD3hbIv/AZ5397OBH48lVjjbIgFoD9wKJAJfmdkCd18T6eKKWDjbohuwGLgFaAx8ZGbz3f1QhGuLNfn63ozVoNDwH+eFtZ5m1hYYDfRw971FVFtRC2dbpAOTgyFRA+hpZmfcfUaRVFh0wv1/ZI+7HwWOmtlnQBpQ0oIinG0xGPijBw7UrzOzjUBz4OuiKTFm5Ot7M1YPPWn4j/MuuS3MrD4wDRhQAn8t5nbJbeHuDd29gbs3AP4OPFUCQwLC+3/kXaCLmSWYWQUCozdnFXGdRSGcbbGZwJ4VZpZCYCTVDUVaZWzI1/dmTO5ReOSG/yh2wtwWvwauAF4J/pI+4yVwxMwwt0WpEM62cPcsM/sAWArkAKPdvcQN0R/mv4sXgXFmtozA4Zfn3b3EDT9uZpOArkANM8sGfgOUgYJ9b2oIDxERCSlWDz2JiEiMUFCIiEhICgoREQlJQSEiIiEpKEREJCQFhUgegiPPLjaz5cFRR6sV8vy/N7MawedHCnPeIoVNQSGSt+Pu3s7dWxMYZO3paBckEi0KCpFL+4rgwGlm1tjMPggOsjffzJoHp6eY2fTg/Q6WmNn1wekzgm1XmFlGFNdBJN9isme2SKwws3gCQz+8Hpw0Chjq7mvNrBPwCoGB5v4KzHP3PsHPVAq2f8zd95lZIvCNmU0twWNxSQmloBDJW6KZLQYaAIsIjDZaicBNot7JNTJtueDfW4CBAO5+FjgYnP5PZtYn+Lwe0BRQUEixoqAQydtxd29nZlWBfxA4RzEOOODu7cKZgZl1BW4DrnP3Y2b2KVA+EsWKRJLOUYiE4O4HgX8C/hU4Dmw0s/vhh/sPn7s/+RzgyeD0eDOrAlQF9gdDojmBW0+KFDsKCpFLcPfvCNyHuR/wCPC4mS0BVnD+lpvPATcHRyddBLQCPgASzGwpgdFLFxR17SKFQaPHiohISNqjEBGRkBQUIiISkoJCRERCUlCIiEhICgoREQlJQSEiIiEpKEREJKT/H23/eGo8isCFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6960048077054592\n"
     ]
    }
   ],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_trues_peaks, y_preds_peaks)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_xlim(0,1.0)\n",
    "ax.set_ylim(0,1.0)\n",
    "\n",
    "#display plot\n",
    "plt.savefig(\"PR_curve_FULL_iteration30_homegrown.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036f9d9-e24a-43df-bb95-cd12665697ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_peaks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704a5fe-7eff-4ba2-b1d7-4b226492d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL: 0.649\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597978de-b857-4d61-95f4-42b0e5ca9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_trues_peaks, y_preds_peaks)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()\n",
    "\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febaf41a-0d1a-4a62-b4e9-aa6c744c93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_trues_peaks, y_preds_peaks)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()\n",
    "\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd041675-44c8-49b2-bb30-687134f1a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues_atac = metric_dict['corr_stats_atac'].result()['y_trues'].numpy()\n",
    "y_preds_atac = metric_dict['corr_stats_atac'].result()['y_preds'].numpy()\n",
    "\n",
    "y_trues_atac = np.log2(1.0+y_trues_atac)\n",
    "y_preds_atac = np.log2(1.0+y_preds_atac)\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_trues_atac)), 15000, replace=False)\n",
    "\n",
    "data = np.vstack([y_trues_atac[idx],\n",
    "                  y_preds_atac[idx]])\n",
    "\n",
    "min_true = min(y_trues_atac[idx])\n",
    "max_true = max(y_trues_atac[idx])\n",
    "\n",
    "min_pred = min(y_preds_atac[idx])\n",
    "max_pred = max(y_preds_atac[idx])\n",
    "\n",
    "fig_overall,ax_overall=plt.subplots(figsize=(6,6))\n",
    "kernel = stats.gaussian_kde(data)(data)\n",
    "sns.scatterplot(\n",
    "    x=y_trues_atac[idx],\n",
    "    y=y_preds_atac[idx],\n",
    "    c=kernel,\n",
    "    cmap=\"viridis\")\n",
    "ax_overall.set_xlim(min_true,max_true)\n",
    "ax_overall.set_ylim(min_pred,max_pred)\n",
    "plt.xlabel(\"log-true\")\n",
    "plt.ylabel(\"log-pred\")\n",
    "plt.title(\"overall ATAC bin level correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18d0f3-1832-4dca-9016-8c8a7f58b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_atac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571dbf4-3fd6-49fd-89d0-75c0fdc8bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "50 * 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264baaa4-b3ad-499b-83df-ebaa9d3eb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    def one_hot(sequence):\n",
    "        '''\n",
    "        convert input string tensor to one hot encoded\n",
    "        will replace all N character with 0 0 0 0\n",
    "        '''\n",
    "        vocabulary = tf.constant(['A', 'C', 'G', 'T'])\n",
    "        mapping = tf.constant([0, 1, 2, 3])\n",
    "\n",
    "        init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                                   values=mapping)\n",
    "        table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "        input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "        out = tf.one_hot(table.lookup(input_characters), \n",
    "                          depth = 4, \n",
    "                          dtype=tf.float32)\n",
    "        return out\n",
    "\n",
    "    \n",
    "list_files = tf.io.gfile.glob(\"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_test_holdout/test/*.tfr\")\n",
    "\n",
    "files_list = []\n",
    "for list_file in list_files:\n",
    "    files = tf.data.Dataset.list_files(list_file)\n",
    "\n",
    "    g = tf.random.Generator.from_seed(42)\n",
    "    h = tf.random.Generator.from_seed(43)\n",
    "\n",
    "    with strategy.scope():\n",
    "\n",
    "            def deserialize_val(serialized_example,\n",
    "                               input_length,\n",
    "                               max_shift,\n",
    "                               output_length_ATAC,\n",
    "                               output_length,\n",
    "                               crop_size,\n",
    "                               output_res,\n",
    "                               #seq_mask_dropout,\n",
    "                               atac_mask_dropout,\n",
    "                               mask_size,\n",
    "                               log_atac,\n",
    "                               use_atac,\n",
    "                               use_seq,\n",
    "                                g,h):\n",
    "                \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "                ## parse out feature map\n",
    "                feature_map = {\n",
    "                    'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'tss_tokens': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'peaks': tf.io.FixedLenFeature([], tf.string)\n",
    "                }\n",
    "                ### stochastic sequence shift and gaussian noise\n",
    "\n",
    "                seq_shift=5\n",
    "                stupid_random_seed = g.uniform([], 0, 10000000,dtype=tf.int32)\n",
    "                stupid_random_seed2 = h.uniform([], 0, 10000000,dtype=tf.int32)\n",
    "                input_seq_length = input_length + max_shift\n",
    "\n",
    "                ## now parse out the actual data\n",
    "                data = tf.io.parse_example(serialized_example, feature_map)\n",
    "                sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "                                             seq_shift,input_length))\n",
    "                atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                                          out_type=tf.float32),\n",
    "                                       [output_length_ATAC,1])\n",
    "                peaks = tf.ensure_shape(tf.io.parse_tensor(data['peaks'],\n",
    "                                                          out_type=tf.int32),\n",
    "                                       [output_length])\n",
    "                peaks = tf.expand_dims(peaks,axis=1)\n",
    "                peaks_crop = tf.slice(peaks,\n",
    "                                 [crop_size,0],\n",
    "                                 [output_length-2*crop_size,-1])\n",
    "\n",
    "\n",
    "                center = (output_length-2*crop_size)//2\n",
    "                ### here set up masking of one of the peaks\n",
    "                mask_indices_temp = tf.where(peaks_crop[:,0] > 0)[:,0]\n",
    "                ridx = tf.concat([tf.random.experimental.stateless_shuffle(mask_indices_temp,seed=[11,stupid_random_seed+1]),\n",
    "                                  tf.constant([center],dtype=tf.int64)],axis=0)   ### concatenate the middle in case theres no peaks\n",
    "                mask_indices=[[ridx[0]-4+crop_size],[ridx[0]-3+crop_size],[ridx[0]-2+crop_size],\n",
    "                              [ridx[0]-1+crop_size],[ridx[0]+crop_size],[ridx[0]+1+crop_size],\n",
    "                              [ridx[0]+2+crop_size],[ridx[0]+3+crop_size]]\n",
    "\n",
    "                st=tf.SparseTensor(\n",
    "                    indices=mask_indices,\n",
    "                    values=[1.0]*len(mask_indices),\n",
    "                    dense_shape=[output_length])\n",
    "                dense_peak_mask=tf.sparse.to_dense(st)\n",
    "                dense_peak_mask_store = dense_peak_mask\n",
    "                dense_peak_mask=1.0-dense_peak_mask\n",
    "                dense_peak_mask = tf.expand_dims(dense_peak_mask,axis=1)\n",
    "\n",
    "                atac_target = atac ## store the target\n",
    "\n",
    "                ### here set up the ATAC masking\n",
    "                num_mask_bins = mask_size // output_res\n",
    "                out_length_cropped = output_length-2*crop_size\n",
    "                edge_append = tf.ones((crop_size,1),dtype=tf.float32)\n",
    "                atac_mask = tf.ones(out_length_cropped // num_mask_bins,dtype=tf.float32)\n",
    "                atac_mask=tf.nn.experimental.stateless_dropout(atac_mask,\n",
    "                                                          rate=(atac_mask_dropout),\n",
    "                                                          seed=[stupid_random_seed+16,stupid_random_seed+10]) / (1. / (1.0-(atac_mask_dropout))) \n",
    "                atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "                atac_mask = tf.tile(atac_mask, [1,num_mask_bins])\n",
    "                atac_mask = tf.reshape(atac_mask, [-1])\n",
    "                atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "                atac_mask_store = 1.0 - atac_mask\n",
    "                full_atac_mask = tf.concat([edge_append,atac_mask,edge_append],axis=0)\n",
    "                full_comb_mask = tf.math.floor((dense_peak_mask + full_atac_mask)/2)\n",
    "                full_comb_mask_store = 1.0 - full_comb_mask\n",
    "                full_comb_mask_store = full_comb_mask_store[crop_size:-crop_size,:]\n",
    "                tiling_req = output_length_ATAC // output_length\n",
    "                full_comb_mask = tf.expand_dims(tf.reshape(tf.tile(full_comb_mask, [1,tiling_req]),[-1]),axis=1)\n",
    "                masked_atac = atac * full_comb_mask\n",
    "\n",
    "                ### now that we have masked specific tokens by setting them to 0, we want to randomly add wrong tokens to these positions\n",
    "                ## first, invert the mask\n",
    "                random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,seed=[10,stupid_random_seed+10])\n",
    "                masked_atac = masked_atac + (1.0-full_comb_mask)*random_shuffled_tokens\n",
    "\n",
    "                if log_atac: \n",
    "                    masked_atac = tf.math.log1p(masked_atac)\n",
    "\n",
    "                diff = tf.math.sqrt(tf.nn.relu(masked_atac - 100.0 * tf.ones(masked_atac.shape)))\n",
    "                masked_atac = tf.clip_by_value(masked_atac, clip_value_min=0.0, clip_value_max=100.0) + diff\n",
    "\n",
    "                atac_out = tf.reduce_sum(tf.reshape(atac_target, [-1,tiling_req]),axis=1,keepdims=True)\n",
    "                diff = tf.math.sqrt(tf.nn.relu(atac_out - 2500.0 * tf.ones(atac_out.shape)))\n",
    "                atac_out = tf.clip_by_value(atac_out, clip_value_min=0.0, clip_value_max=2500.0) + diff\n",
    "                atac_out = tf.slice(atac_out,\n",
    "                                    [crop_size,0],\n",
    "                                    [output_length-2*crop_size,-1])\n",
    "\n",
    "                peaks_gathered = tf.reduce_max(tf.reshape(peaks_crop, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                               axis=1,keepdims=True)\n",
    "                mask_gathered = tf.reduce_max(tf.reshape(full_comb_mask_store, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                               axis=1,keepdims=True)\n",
    "\n",
    "                random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,\n",
    "                                                                                 seed=[11,stupid_random_seed+11])\n",
    "                if not use_atac:\n",
    "                    masked_atac = random_shuffled_tokens\n",
    "                if not use_seq:\n",
    "                    sequence = tf.random.experimental.stateless_shuffle(sequence,\n",
    "                                                                        seed=[12,stupid_random_seed+12])\n",
    "\n",
    "\n",
    "                mask_seed = tf.cast(full_comb_mask_store,dtype=tf.int32)*stupid_random_seed + stupid_random_seed2\n",
    "                masked_gathered_seed = tf.cast(mask_gathered,dtype=tf.int32)*stupid_random_seed + stupid_random_seed2\n",
    "\n",
    "                return {'sequence': tf.ensure_shape(sequence,\n",
    "                                                    [input_length,4]),\n",
    "                        'atac': tf.ensure_shape(masked_atac,\n",
    "                                                [output_length_ATAC,1]),\n",
    "                        'mask': tf.ensure_shape(full_comb_mask_store,\n",
    "                                                [output_length-crop_size*2,1]),\n",
    "                        'mask_seed': tf.ensure_shape(mask_seed,\n",
    "                                                [output_length-crop_size*2,1]),\n",
    "                        'mask_gathered': tf.ensure_shape(mask_gathered,\n",
    "                                                [(output_length-crop_size*2)//2,1]),\n",
    "                        'mask_gathered_seed': tf.ensure_shape(masked_gathered_seed,\n",
    "                                                [(output_length-crop_size*2)//2,1]),\n",
    "                        'peaks': tf.ensure_shape(peaks_gathered,\n",
    "                                                  [(output_length-2*crop_size) // 2,1]),\n",
    "                        'target': tf.ensure_shape(atac_out,\n",
    "                                                  [output_length-crop_size*2,1])}\n",
    "\n",
    "\n",
    "            files = tf.data.Dataset.list_files(list_file)\n",
    "\n",
    "            dataset = tf.data.TFRecordDataset(files,\n",
    "                                              compression_type='ZLIB',\n",
    "                                              num_parallel_reads=4)\n",
    "            dataset = dataset.with_options(options)\n",
    "            dataset = dataset.map(lambda record: deserialize_val(record,\n",
    "                                                                262144,\n",
    "                                                                10,\n",
    "                                                                65536,\n",
    "                                                                2048,\n",
    "                                                                256,\n",
    "                                                                128,\n",
    "                                                                 #seq_mask_dropout,\n",
    "                                                                0.10,\n",
    "                                                                1024,\n",
    "                                                                True,\n",
    "                                                               False,\n",
    "                                                               True,\n",
    "                                                                g,h),\n",
    "                          deterministic=False,\n",
    "                          num_parallel_calls=4)\n",
    "\n",
    "            dataset = dataset.batch(64,drop_remainder=True).prefetch(tf.data.AUTOTUNE).repeat()\n",
    "\n",
    "            test_dist = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "            test_it = iter(test_dist)\n",
    "            test_it_build = iter(test_dist)\n",
    "            files_list.append(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd2b8827-dd6f-4be1-be67-c0316a8d084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aformer/conv1d_42/kernel:0\n",
      "aformer/conv1d_42/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_38/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_38/beta:0\n",
      "conv1d_43/kernel:0\n",
      "conv1d_43/bias:0\n",
      "aformer/conv1d_44/kernel:0\n",
      "aformer/conv1d_44/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_39/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_39/beta:0\n",
      "conv1d_45/kernel:0\n",
      "conv1d_45/bias:0\n",
      "aformer/stem_pool_atac/dense_1/kernel:0\n",
      "aformer/stem_pool/dense/kernel:0\n",
      "aformer/embedding_2/embeddings:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_40/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_40/beta:0\n",
      "conv1d_46/kernel:0\n",
      "conv1d_46/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_41/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_41/beta:0\n",
      "conv1d_47/kernel:0\n",
      "conv1d_47/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_42/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_42/beta:0\n",
      "conv1d_48/kernel:0\n",
      "conv1d_48/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_43/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_43/beta:0\n",
      "conv1d_49/kernel:0\n",
      "conv1d_49/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_44/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_44/beta:0\n",
      "conv1d_50/kernel:0\n",
      "conv1d_50/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_45/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_45/beta:0\n",
      "conv1d_51/kernel:0\n",
      "conv1d_51/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_46/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_46/beta:0\n",
      "conv1d_52/kernel:0\n",
      "conv1d_52/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_47/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_47/beta:0\n",
      "conv1d_53/kernel:0\n",
      "conv1d_53/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_48/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_48/beta:0\n",
      "conv1d_54/kernel:0\n",
      "conv1d_54/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_49/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_49/beta:0\n",
      "conv1d_55/kernel:0\n",
      "conv1d_55/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_50/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_50/beta:0\n",
      "conv1d_56/kernel:0\n",
      "conv1d_56/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_51/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_51/beta:0\n",
      "conv1d_57/kernel:0\n",
      "conv1d_57/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_52/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_52/beta:0\n",
      "conv1d_58/kernel:0\n",
      "conv1d_58/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_53/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_53/beta:0\n",
      "conv1d_59/kernel:0\n",
      "conv1d_59/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_54/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_54/beta:0\n",
      "conv1d_60/kernel:0\n",
      "conv1d_60/bias:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_55/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_55/beta:0\n",
      "conv1d_61/kernel:0\n",
      "conv1d_61/bias:0\n",
      "SoftmaxPooling1D/dense/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_26/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_26/beta:0\n",
      "aformer/shared_transformer/transformer_layer/attention_12/query/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_12/key/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_12/value/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_12/output_transform/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_27/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_27/beta:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_34/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_34/bias:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_35/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_35/bias:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_28/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_28/beta:0\n",
      "aformer/shared_transformer/transformer_layer/attention_13/query/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_13/key/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_13/value/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_13/output_transform/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_29/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_29/beta:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_36/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_36/bias:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_37/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_37/bias:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_30/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_30/beta:0\n",
      "aformer/shared_transformer/transformer_layer/attention_14/query/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_14/key/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_14/value/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_14/output_transform/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_31/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_31/beta:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_38/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_38/bias:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_39/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_39/bias:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_32/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_32/beta:0\n",
      "aformer/shared_transformer/transformer_layer/attention_15/query/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_15/key/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_15/value/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_15/output_transform/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_33/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_33/beta:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_40/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_40/bias:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_41/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_41/bias:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_34/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_34/beta:0\n",
      "aformer/shared_transformer/transformer_layer/attention_16/query/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_16/key/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_16/value/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_16/output_transform/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_35/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_35/beta:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_42/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_42/bias:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_43/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_43/bias:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_36/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/layer_norm_fp32/layer_normalization_36/beta:0\n",
      "aformer/shared_transformer/transformer_layer/attention_17/query/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_17/key/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_17/value/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/attention_17/output_transform/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_37/gamma:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/layer_norm_fp32/layer_normalization_37/beta:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_44/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_44/bias:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_45/kernel:0\n",
      "aformer/shared_transformer/transformer_layer/FFN/dense_45/bias:0\n",
      "aformer/shared_transformer/layer_norm_fp32/layer_normalization_38/gamma:0\n",
      "aformer/shared_transformer/layer_norm_fp32/layer_normalization_38/beta:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_56/gamma:0\n",
      "sync_batch_norm_fp32/sync_batch_normalization_56/beta:0\n",
      "conv1d_62/kernel:0\n",
      "conv1d_62/bias:0\n",
      "aformer/dense_46/kernel:0\n",
      "aformer/dense_46/bias:0\n",
      "aformer/dense_47/kernel:0\n",
      "aformer/dense_47/bias:0\n",
      "aformer/dense_49/kernel:0\n",
      "aformer/dense_49/bias:0\n",
      "aformer/dense_48/kernel:0\n",
      "aformer/dense_48/bias:0\n",
      "peaks_pool/dense/kernel:0\n",
      "dense_50/kernel:0\n",
      "dense_50/bias:0\n",
      "peaks_pool/dense/kernel:0\n",
      "dense_51/kernel:0\n",
      "dense_51/bias:0\n",
      "peaks_pool/dense/kernel:0\n",
      "dense_53/kernel:0\n",
      "dense_53/bias:0\n",
      "peaks_pool/dense/kernel:0\n",
      "dense_52/kernel:0\n",
      "dense_52/bias:0\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(model.trainable_variables):\n",
    "    print(k.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6d34d-4169-4c97-a864-0f41d79647ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TPUDistributedVariable:{\n",
       "  0: <tf.Variable 'aformer/embedding_1/embeddings:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>,\n",
       "  1: <tf.Variable 'aformer/embedding_1/embeddings/replica_1:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>,\n",
       "  2: <tf.Variable 'aformer/embedding_1/embeddings/replica_2:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>,\n",
       "  3: <tf.Variable 'aformer/embedding_1/embeddings/replica_3:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>,\n",
       "  4: <tf.Variable 'aformer/embedding_1/embeddings/replica_4:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>,\n",
       "  5: <tf.Variable 'aformer/embedding_1/embeddings/replica_5:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>,\n",
       "  6: <tf.Variable 'aformer/embedding_1/embeddings/replica_6:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>,\n",
       "  7: <tf.Variable 'aformer/embedding_1/embeddings/replica_7:0' shape=(2048, 1600) dtype=float32, numpy=\n",
       "array([[ 0.0164609 ,  0.02749372, -0.01542488, ...,  0.08125965,\n",
       "        -0.10188409,  0.08790673],\n",
       "       [ 0.03011785,  0.0357183 ,  0.0394407 , ..., -0.0041007 ,\n",
       "        -0.05729758,  0.05099118],\n",
       "       [ 0.02117763, -0.00183437, -0.01333619, ..., -0.01716687,\n",
       "        -0.09254447,  0.06225032],\n",
       "       ...,\n",
       "       [-0.02391185,  0.02890328,  0.04887392, ..., -0.00027385,\n",
       "        -0.00844594,  0.0621284 ],\n",
       "       [ 0.0331138 ,  0.01647806,  0.00799965, ...,  0.00052548,\n",
       "        -0.07112795,  0.08235224],\n",
       "       [ 0.01340021,  0.03641171,  0.03264887, ...,  0.07121241,\n",
       "        -0.03582776, -0.04955046]], dtype=float32)>\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
