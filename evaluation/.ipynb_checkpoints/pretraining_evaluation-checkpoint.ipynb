{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fce1a7-ac1b-4f1c-8aae-f7f4c3f25420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 01:51:22.726522: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 01:51:22.908751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:51:22.908800: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-24 01:51:23.837798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:51:23.837964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:51:23.837980: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import src.aformer_atac as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "from src.optimizers import *\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_atac as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f91bfd-ee1f-428d-8c76-aa0bcdd8f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 01:51:25.243990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:51:25.244039: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-24 01:51:25.244064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 01:51:25.557656: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "2023-04-24 01:51:25.579733: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://localhost:42691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-2')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    #options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb91825-4d60-46de-b695-f446906af355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    def one_hot(sequence):\n",
    "        '''\n",
    "        convert input string tensor to one hot encoded\n",
    "        will replace all N character with 0 0 0 0\n",
    "        '''\n",
    "        vocabulary = tf.constant(['A', 'C', 'G', 'T'])\n",
    "        mapping = tf.constant([0, 1, 2, 3])\n",
    "\n",
    "        init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                                   values=mapping)\n",
    "        table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "        input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "        out = tf.one_hot(table.lookup(input_characters), \n",
    "                          depth = 4, \n",
    "                          dtype=tf.float32)\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "g = tf.random.Generator.from_seed(1)\n",
    "\n",
    "with strategy.scope():\n",
    "    list_files = tf.io.gfile.glob(\"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_test_holdout/peak_atlas_with_negatives/*.tfr\")\n",
    "\n",
    "\n",
    "    files = tf.data.Dataset.list_files(list_files)\n",
    "\n",
    "    def deserialize_val(serialized_example,\n",
    "                       input_length,\n",
    "                       max_shift,\n",
    "                       output_length_ATAC,\n",
    "                       output_length,\n",
    "                       crop_size,\n",
    "                       output_res,\n",
    "                       #seq_mask_dropout,\n",
    "                       atac_mask_dropout,\n",
    "                       mask_size,\n",
    "                       log_atac,\n",
    "                       use_atac,\n",
    "                       use_seq,\n",
    "                        g):\n",
    "        \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "        ## parse out feature map\n",
    "        feature_map = {\n",
    "            'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "            'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "            'tss_tokens': tf.io.FixedLenFeature([], tf.string),\n",
    "            'peaks': tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "        ### stochastic sequence shift and gaussian noise\n",
    "\n",
    "        seq_shift=5\n",
    "        stupid_random_seed = g.uniform([], 0, 10000000,dtype=tf.int32)\n",
    "        input_seq_length = input_length + max_shift\n",
    "\n",
    "        ## now parse out the actual data\n",
    "        data = tf.io.parse_example(serialized_example, feature_map)\n",
    "        sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "                                     seq_shift,input_length))\n",
    "        atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                                  out_type=tf.float32),\n",
    "                               [output_length_ATAC,1])\n",
    "        peaks = tf.ensure_shape(tf.io.parse_tensor(data['peaks'],\n",
    "                                                  out_type=tf.int32),\n",
    "                               [output_length])\n",
    "        peaks = tf.expand_dims(peaks,axis=1)\n",
    "        peaks_crop = tf.slice(peaks,\n",
    "                         [crop_size,0],\n",
    "                         [output_length-2*crop_size,-1])\n",
    "\n",
    "\n",
    "        center = (output_length-2*crop_size)//2\n",
    "        ### here set up masking of one of the peaks\n",
    "        mask_indices_temp = tf.where(peaks_crop[:,0] > 0)[:,0]\n",
    "        ridx = tf.concat([tf.constant([center],dtype=tf.int64)],axis=0)   ### concatenate the middle in case theres no peaks\n",
    "        mask_indices=[[ridx[0]-3+crop_size],[ridx[0]-2+crop_size],\n",
    "                      [ridx[0]-1+crop_size],[ridx[0]+crop_size],[ridx[0]+1+crop_size],\n",
    "                      [ridx[0]+2+crop_size],[ridx[0]+3+crop_size],\n",
    "                      [ridx[0]+4+crop_size]]\n",
    "\n",
    "        st=tf.SparseTensor(\n",
    "            indices=mask_indices,\n",
    "            values=[1.0]*len(mask_indices),\n",
    "            dense_shape=[output_length])\n",
    "        dense_peak_mask=tf.sparse.to_dense(st)\n",
    "        dense_peak_mask_store = dense_peak_mask\n",
    "        dense_peak_mask=1.0-dense_peak_mask\n",
    "        dense_peak_mask = tf.expand_dims(dense_peak_mask,axis=1)\n",
    "\n",
    "        atac_target = atac ## store the target\n",
    "\n",
    "        ### here set up the ATAC masking\n",
    "        num_mask_bins = mask_size // output_res\n",
    "        out_length_cropped = output_length-2*crop_size\n",
    "        edge_append = tf.ones((crop_size,1),dtype=tf.float32)\n",
    "        atac_mask = tf.ones(out_length_cropped // num_mask_bins,dtype=tf.float32)\n",
    "        atac_mask=tf.nn.experimental.stateless_dropout(atac_mask,\n",
    "                                                  rate=(atac_mask_dropout),\n",
    "                                                  seed=[stupid_random_seed+16,stupid_random_seed+10]) / (1. / (1.0-(atac_mask_dropout))) \n",
    "        atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "        atac_mask = tf.tile(atac_mask, [1,num_mask_bins])\n",
    "        atac_mask = tf.reshape(atac_mask, [-1])\n",
    "        atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "        atac_mask_store = 1.0 - atac_mask\n",
    "        full_atac_mask = tf.concat([edge_append,atac_mask,edge_append],axis=0)\n",
    "        full_comb_mask = tf.math.floor((dense_peak_mask+full_atac_mask)/2)\n",
    "        full_comb_mask_store = 1.0 - full_comb_mask\n",
    "        full_comb_mask_store = full_comb_mask_store[crop_size:-crop_size,:]\n",
    "        tiling_req = output_length_ATAC // output_length\n",
    "        full_comb_mask = tf.expand_dims(tf.reshape(tf.tile(full_comb_mask, [1,tiling_req]),[-1]),axis=1)\n",
    "        masked_atac = atac * full_comb_mask\n",
    "\n",
    "        ### now that we have masked specific tokens by setting them to 0, we want to randomly add wrong tokens to these positions\n",
    "        ## first, invert the mask\n",
    "        random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,seed=[10,stupid_random_seed+10])\n",
    "        masked_atac = masked_atac + (1.0-full_comb_mask)*random_shuffled_tokens\n",
    "\n",
    "        if log_atac: \n",
    "            masked_atac = tf.math.log1p(masked_atac)\n",
    "\n",
    "        diff = tf.math.sqrt(tf.nn.relu(masked_atac - 100.0 * tf.ones(masked_atac.shape)))\n",
    "        masked_atac = tf.clip_by_value(masked_atac, clip_value_min=0.0, clip_value_max=100.0) + diff\n",
    "\n",
    "        atac_out = tf.reduce_sum(tf.reshape(atac_target, [-1,tiling_req]),axis=1,keepdims=True)\n",
    "        diff = tf.math.sqrt(tf.nn.relu(atac_out - 2500.0 * tf.ones(atac_out.shape)))\n",
    "        atac_out = tf.clip_by_value(atac_out, clip_value_min=0.0, clip_value_max=2500.0) + diff\n",
    "        atac_out = tf.slice(atac_out,\n",
    "                            [crop_size,0],\n",
    "                            [output_length-2*crop_size,-1])\n",
    "\n",
    "        peaks_gathered = tf.reduce_max(tf.reshape(peaks_crop, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                       axis=1,keepdims=True)\n",
    "        mask_gathered = tf.reduce_max(tf.reshape(full_comb_mask_store, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                       axis=1,keepdims=True)\n",
    "\n",
    "        random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,\n",
    "                                                                         seed=[11,stupid_random_seed+11])\n",
    "        if not use_atac:\n",
    "            masked_atac = random_shuffled_tokens\n",
    "        if not use_seq:\n",
    "            sequence = tf.random.experimental.stateless_shuffle(sequence,\n",
    "                                                                seed=[1,stupid_random_seed+12])\n",
    "\n",
    "\n",
    "        return {'sequence': tf.ensure_shape(sequence,\n",
    "                                            [input_length,4]),\n",
    "                'atac': tf.ensure_shape(masked_atac,\n",
    "                                        [output_length_ATAC,1]),\n",
    "                'mask': tf.ensure_shape(full_comb_mask_store,\n",
    "                                        [output_length-crop_size*2,1]),\n",
    "                'mask_gathered': tf.ensure_shape(mask_gathered,\n",
    "                                        [(output_length-crop_size*2)//2,1]),\n",
    "                'peaks': tf.ensure_shape(peaks_gathered,\n",
    "                                          [(output_length-2*crop_size) // 2,1]),\n",
    "                'target': tf.ensure_shape(atac_out,\n",
    "                                          [output_length-crop_size*2,1])}\n",
    "\n",
    "\n",
    "    files = tf.data.Dataset.list_files(list_files)\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(files,\n",
    "                                      compression_type='ZLIB',\n",
    "                                      num_parallel_reads=4)\n",
    "    dataset = dataset.with_options(options)\n",
    "    dataset = dataset.map(lambda record: deserialize_val(record,\n",
    "                                                        262144,\n",
    "                                                        10,\n",
    "                                                        65536,\n",
    "                                                        2048,\n",
    "                                                        256,\n",
    "                                                        128,\n",
    "                                                         #seq_mask_dropout,\n",
    "                                                        0.0,\n",
    "                                                        512,\n",
    "                                                        True,\n",
    "                                                       True,\n",
    "                                                       True,\n",
    "                                                        g),\n",
    "                  deterministic=False,\n",
    "                  num_parallel_calls=4)\n",
    "\n",
    "    dataset = dataset.batch(64,drop_remainder=True).prefetch(tf.data.AUTOTUNE).repeat(1)\n",
    "\n",
    "    test_dist = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "    test_it = iter(test_dist)\n",
    "    test_it_build = iter(test_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0305b462-08ba-4a3a-a07a-f54475f54b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran test input\n",
      "loaded weights\n"
     ]
    }
   ],
   "source": [
    "#with strategy.scope():\n",
    "with strategy.scope():\n",
    "    model = aformer.aformer(kernel_transformation='relu_kernel_transformation',\n",
    "                            dropout_rate=0.30,\n",
    "                            pointwise_dropout_rate=0.10,\n",
    "                            input_length=262144,\n",
    "                            output_length=2048,\n",
    "                            final_output_length=1536,\n",
    "                            num_heads=8,\n",
    "                            numerical_stabilizer=0.0000001,\n",
    "                            nb_random_features=256,\n",
    "                            max_seq_length=2048,\n",
    "                            rel_pos_bins=2048,\n",
    "                            norm=True,\n",
    "                            normalize = True,\n",
    "                            BN_momentum=0.90,\n",
    "                            use_rot_emb = True,\n",
    "                            use_mask_pos = False,\n",
    "                            num_transformer_layers=6,\n",
    "                            inits_type=\"enformer_performer\",\n",
    "                            load_init=True,\n",
    "                            stable_variant=False,\n",
    "                            freeze_conv_layers=False,\n",
    "                            filter_list_seq=[768,896,1024,1152,1280,1536],\n",
    "                            filter_list_atac=[32,64],\n",
    "                            output_heads=[\"human\",\"mouse\",\"rhesus\",\"rat\"],\n",
    "                            learnable_PE=True)\n",
    "\n",
    "\n",
    "    def build_step(iterator): #input_batch, model, optimizer, organism, gradient_clip):\n",
    "        @tf.function(jit_compile=True)\n",
    "        def test_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            #global_acc=tf.cast(inputs['global_acc'],dtype=tf.bfloat16)         \n",
    "            input_tuple = sequence,atac#,global_acc\n",
    "\n",
    "            output = model(input_tuple,\n",
    "                           training=False)\n",
    "\n",
    "        for _ in tf.range(1): ## for loop within @tf.fuction for improved TPU performance\n",
    "            strategy.run(test_step, args=(next(iterator),))\n",
    "            \n",
    "            \n",
    "build_step(test_it_build)\n",
    "print('ran test input')\n",
    "#model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_262k_load-True_LR-0.01_T-7_D-0.3_2023-04-13_15:39:43/final/saved_model\")\n",
    "model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_mm_rm_rat_262k_load-True_LR-0.01_T-6_D-0.3_2023-04-22_02:47:21/iteration_13/saved_model\")\n",
    "print('loaded weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71878139-2569-40ab-a0b9-744b82a1e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    metric_dict = {}\n",
    "    metric_dict[\"corr_stats_atac\"] = metrics.correlation_stats_gene_centered(name='corr_stats')\n",
    "    metric_dict[\"corr_stats_peaks\"] = metrics.correlation_stats_gene_centered(name='corr_stats')\n",
    "    def dist_test_step(iterator):\n",
    "        @tf.function(jit_compile=True)\n",
    "        def test_step(inputs):\n",
    "            sequence=tf.cast(inputs['sequence'],dtype=tf.bfloat16)\n",
    "            target=tf.cast(inputs['target'],dtype=tf.float32)\n",
    "            atac=tf.cast(inputs['atac'],dtype=tf.bfloat16)\n",
    "            mask=tf.cast(inputs['mask'],dtype=tf.int32)\n",
    "            mask_gathered=tf.cast(inputs['mask_gathered'],dtype=tf.int32)\n",
    "            peaks=tf.cast(inputs['peaks'],dtype=tf.float32)\n",
    "            \n",
    "            input_tuple = sequence,atac#,global_acc\n",
    "\n",
    "            output_profile,output_peaks = model(input_tuple,\n",
    "                                                training=False)\n",
    "            output_profile = tf.cast(output_profile['human'],dtype=tf.float32) # ensure cast to float32\n",
    "            output_peaks = tf.cast(output_peaks['human'],dtype=tf.float32)\n",
    "            \n",
    "            mask_indices = tf.where(mask[0,:,0] == 1)[:,0]\n",
    "            \n",
    "            target_atac = tf.gather(target[:,:,0], mask_indices,axis=1)\n",
    "            output_atac = tf.gather(output_profile[:,:,0], mask_indices,axis=1)\n",
    "            \n",
    "            \n",
    "            mask_gather_indices = tf.where(mask_gathered[0,:,0] == 1)[:,0]\n",
    "            target_peaks = tf.gather(peaks[:,:,0], mask_gather_indices,axis=1)\n",
    "            output_peaks = tf.gather(output_peaks[:,:,0], mask_gather_indices,axis=1)\n",
    "\n",
    "            #dummy_var = tf.ones(target_atac.shape,dtype=tf.int32)\n",
    "            \n",
    "            return target_atac, output_atac, target_peaks, output_peaks#,dummy_var\n",
    "            \n",
    "        \n",
    "        ta_pred_atac = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False) # tensor array to store preds\n",
    "        ta_true_atac = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False) # tensor array to store vals\n",
    "        ta_pred_peaks = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False) # tensor array to store preds\n",
    "        ta_true_peaks = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False)  \n",
    "        ta_dummy_pk = tf.TensorArray(tf.int32, size=0, dynamic_size=True,clear_after_read=False) \n",
    "        ta_dummy_atac = tf.TensorArray(tf.int32, size=0, dynamic_size=True,clear_after_read=False) \n",
    "            \n",
    "        for _ in tf.range(2017): ## for loop within @tf.fuction for improved TPU performance\n",
    "            pred_atac_rep,true_atac_rep, pred_peaks_rep,true_peaks_rep = \\\n",
    "                strategy.run(test_step,\n",
    "                             args=(next(iterator),))\n",
    "            \n",
    "            #print(pred_atac_rep)\n",
    "            \n",
    "            pred_atac_reshape = tf.reshape(strategy.gather(pred_atac_rep, axis=1), [-1]) # reshape to 1D\n",
    "            true_atac_reshape = tf.reshape(strategy.gather(true_atac_rep, axis=1), [-1])\n",
    "            pred_peaks_reshape = tf.reshape(strategy.gather(pred_peaks_rep, axis=1), [-1]) # reshape to 1D\n",
    "            true_peaks_reshape = tf.reshape(strategy.gather(true_peaks_rep, axis=1), [-1])\n",
    "            \n",
    "            dummy_reshape_pk = tf.ones(true_peaks_reshape.shape,dtype=tf.int32)#tf.reshape(strategy.gather(dummy_int, axis=0), [-1])\n",
    "            dummy_reshape_atac = tf.ones(true_peaks_reshape.shape,dtype=tf.int32)\n",
    "\n",
    "            ta_pred_atac = ta_pred_atac.write(_, pred_atac_reshape)\n",
    "            ta_true_atac = ta_true_atac.write(_, true_atac_reshape)\n",
    "            ta_pred_peaks = ta_pred_peaks.write(_, pred_peaks_reshape)\n",
    "            ta_true_peaks = ta_true_peaks.write(_, true_peaks_reshape)\n",
    "            \n",
    "            ta_dummy_pk = ta_dummy_pk.write(_, dummy_reshape_pk)\n",
    "            ta_dummy_atac = ta_dummy_atac.write(_, dummy_reshape_atac)\n",
    "            \n",
    "        metric_dict[\"corr_stats_atac\"].update_state(ta_pred_atac.concat(),\n",
    "                                                    ta_true_atac.concat(),\n",
    "                                                    ta_dummy_atac.concat(),\n",
    "                                                    ta_dummy_atac.concat())\n",
    "        metric_dict[\"corr_stats_peaks\"].update_state(ta_pred_peaks.concat(),\n",
    "                                                     ta_true_peaks.concat(),\n",
    "                                                     ta_dummy_pk.concat(),\n",
    "                                                     ta_dummy_pk.concat())\n",
    "        ta_pred_atac.close()\n",
    "        ta_true_atac.close()\n",
    "        ta_pred_peaks.close()\n",
    "        ta_true_peaks.close()\n",
    "        ta_dummy_pk.close()\n",
    "        ta_dummy_atac.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510472c2-3278-4a5a-84e0-f1c8d0822fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    for k in range(1):\n",
    "        dist_test_step(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0532a8-303c-48d3-884f-fed17a487ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_trues_peaks = metric_dict['corr_stats_peaks'].result()['y_trues'].numpy()\n",
    "y_preds_peaks = metric_dict['corr_stats_peaks'].result()['y_preds'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6f944f-46b3-4025-a412-f6689ea1b36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5244321032671855\n"
     ]
    }
   ],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_trues_peaks, y_preds_peaks)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.savefig(\"PR_curve_FULL.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036f9d9-e24a-43df-bb95-cd12665697ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_peaks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704a5fe-7eff-4ba2-b1d7-4b226492d671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597978de-b857-4d61-95f4-42b0e5ca9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_trues_peaks, y_preds_peaks)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()\n",
    "\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febaf41a-0d1a-4a62-b4e9-aa6c744c93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_trues_peaks, y_preds_peaks)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()\n",
    "\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd041675-44c8-49b2-bb30-687134f1a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues_atac = metric_dict['corr_stats_atac'].result()['y_trues'].numpy()\n",
    "y_preds_atac = metric_dict['corr_stats_atac'].result()['y_preds'].numpy()\n",
    "\n",
    "y_trues_atac = np.log2(1.0+y_trues_atac)\n",
    "y_preds_atac = np.log2(1.0+y_preds_atac)\n",
    "\n",
    "idx = np.random.choice(np.arange(len(y_trues_atac)), 15000, replace=False)\n",
    "\n",
    "data = np.vstack([y_trues_atac[idx],\n",
    "                  y_preds_atac[idx]])\n",
    "\n",
    "min_true = min(y_trues_atac[idx])\n",
    "max_true = max(y_trues_atac[idx])\n",
    "\n",
    "min_pred = min(y_preds_atac[idx])\n",
    "max_pred = max(y_preds_atac[idx])\n",
    "\n",
    "fig_overall,ax_overall=plt.subplots(figsize=(6,6))\n",
    "kernel = stats.gaussian_kde(data)(data)\n",
    "sns.scatterplot(\n",
    "    x=y_trues_atac[idx],\n",
    "    y=y_preds_atac[idx],\n",
    "    c=kernel,\n",
    "    cmap=\"viridis\")\n",
    "ax_overall.set_xlim(min_true,max_true)\n",
    "ax_overall.set_ylim(min_pred,max_pred)\n",
    "plt.xlabel(\"log-true\")\n",
    "plt.ylabel(\"log-pred\")\n",
    "plt.title(\"overall ATAC bin level correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18d0f3-1832-4dca-9016-8c8a7f58b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_atac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571dbf4-3fd6-49fd-89d0-75c0fdc8bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "50 * 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264baaa4-b3ad-499b-83df-ebaa9d3eb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    def one_hot(sequence):\n",
    "        '''\n",
    "        convert input string tensor to one hot encoded\n",
    "        will replace all N character with 0 0 0 0\n",
    "        '''\n",
    "        vocabulary = tf.constant(['A', 'C', 'G', 'T'])\n",
    "        mapping = tf.constant([0, 1, 2, 3])\n",
    "\n",
    "        init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                                   values=mapping)\n",
    "        table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "        input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "        out = tf.one_hot(table.lookup(input_characters), \n",
    "                          depth = 4, \n",
    "                          dtype=tf.float32)\n",
    "        return out\n",
    "\n",
    "    \n",
    "list_files = tf.io.gfile.glob(\"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_test_holdout/test/*.tfr\")\n",
    "\n",
    "files_list = []\n",
    "for list_file in list_files:\n",
    "    files = tf.data.Dataset.list_files(list_file)\n",
    "\n",
    "    g = tf.random.Generator.from_seed(42)\n",
    "    h = tf.random.Generator.from_seed(43)\n",
    "\n",
    "    with strategy.scope():\n",
    "\n",
    "            def deserialize_val(serialized_example,\n",
    "                               input_length,\n",
    "                               max_shift,\n",
    "                               output_length_ATAC,\n",
    "                               output_length,\n",
    "                               crop_size,\n",
    "                               output_res,\n",
    "                               #seq_mask_dropout,\n",
    "                               atac_mask_dropout,\n",
    "                               mask_size,\n",
    "                               log_atac,\n",
    "                               use_atac,\n",
    "                               use_seq,\n",
    "                                g,h):\n",
    "                \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "                ## parse out feature map\n",
    "                feature_map = {\n",
    "                    'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'tss_tokens': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'peaks': tf.io.FixedLenFeature([], tf.string)\n",
    "                }\n",
    "                ### stochastic sequence shift and gaussian noise\n",
    "\n",
    "                seq_shift=5\n",
    "                stupid_random_seed = g.uniform([], 0, 10000000,dtype=tf.int32)\n",
    "                stupid_random_seed2 = h.uniform([], 0, 10000000,dtype=tf.int32)\n",
    "                input_seq_length = input_length + max_shift\n",
    "\n",
    "                ## now parse out the actual data\n",
    "                data = tf.io.parse_example(serialized_example, feature_map)\n",
    "                sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "                                             seq_shift,input_length))\n",
    "                atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                                          out_type=tf.float32),\n",
    "                                       [output_length_ATAC,1])\n",
    "                peaks = tf.ensure_shape(tf.io.parse_tensor(data['peaks'],\n",
    "                                                          out_type=tf.int32),\n",
    "                                       [output_length])\n",
    "                peaks = tf.expand_dims(peaks,axis=1)\n",
    "                peaks_crop = tf.slice(peaks,\n",
    "                                 [crop_size,0],\n",
    "                                 [output_length-2*crop_size,-1])\n",
    "\n",
    "\n",
    "                center = (output_length-2*crop_size)//2\n",
    "                ### here set up masking of one of the peaks\n",
    "                mask_indices_temp = tf.where(peaks_crop[:,0] > 0)[:,0]\n",
    "                ridx = tf.concat([tf.random.experimental.stateless_shuffle(mask_indices_temp,seed=[11,stupid_random_seed+1]),\n",
    "                                  tf.constant([center],dtype=tf.int64)],axis=0)   ### concatenate the middle in case theres no peaks\n",
    "                mask_indices=[[ridx[0]-4+crop_size],[ridx[0]-3+crop_size],[ridx[0]-2+crop_size],\n",
    "                              [ridx[0]-1+crop_size],[ridx[0]+crop_size],[ridx[0]+1+crop_size],\n",
    "                              [ridx[0]+2+crop_size],[ridx[0]+3+crop_size]]\n",
    "\n",
    "                st=tf.SparseTensor(\n",
    "                    indices=mask_indices,\n",
    "                    values=[1.0]*len(mask_indices),\n",
    "                    dense_shape=[output_length])\n",
    "                dense_peak_mask=tf.sparse.to_dense(st)\n",
    "                dense_peak_mask_store = dense_peak_mask\n",
    "                dense_peak_mask=1.0-dense_peak_mask\n",
    "                dense_peak_mask = tf.expand_dims(dense_peak_mask,axis=1)\n",
    "\n",
    "                atac_target = atac ## store the target\n",
    "\n",
    "                ### here set up the ATAC masking\n",
    "                num_mask_bins = mask_size // output_res\n",
    "                out_length_cropped = output_length-2*crop_size\n",
    "                edge_append = tf.ones((crop_size,1),dtype=tf.float32)\n",
    "                atac_mask = tf.ones(out_length_cropped // num_mask_bins,dtype=tf.float32)\n",
    "                atac_mask=tf.nn.experimental.stateless_dropout(atac_mask,\n",
    "                                                          rate=(atac_mask_dropout),\n",
    "                                                          seed=[stupid_random_seed+16,stupid_random_seed+10]) / (1. / (1.0-(atac_mask_dropout))) \n",
    "                atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "                atac_mask = tf.tile(atac_mask, [1,num_mask_bins])\n",
    "                atac_mask = tf.reshape(atac_mask, [-1])\n",
    "                atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "                atac_mask_store = 1.0 - atac_mask\n",
    "                full_atac_mask = tf.concat([edge_append,atac_mask,edge_append],axis=0)\n",
    "                full_comb_mask = tf.math.floor((dense_peak_mask + full_atac_mask)/2)\n",
    "                full_comb_mask_store = 1.0 - full_comb_mask\n",
    "                full_comb_mask_store = full_comb_mask_store[crop_size:-crop_size,:]\n",
    "                tiling_req = output_length_ATAC // output_length\n",
    "                full_comb_mask = tf.expand_dims(tf.reshape(tf.tile(full_comb_mask, [1,tiling_req]),[-1]),axis=1)\n",
    "                masked_atac = atac * full_comb_mask\n",
    "\n",
    "                ### now that we have masked specific tokens by setting them to 0, we want to randomly add wrong tokens to these positions\n",
    "                ## first, invert the mask\n",
    "                random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,seed=[10,stupid_random_seed+10])\n",
    "                masked_atac = masked_atac + (1.0-full_comb_mask)*random_shuffled_tokens\n",
    "\n",
    "                if log_atac: \n",
    "                    masked_atac = tf.math.log1p(masked_atac)\n",
    "\n",
    "                diff = tf.math.sqrt(tf.nn.relu(masked_atac - 100.0 * tf.ones(masked_atac.shape)))\n",
    "                masked_atac = tf.clip_by_value(masked_atac, clip_value_min=0.0, clip_value_max=100.0) + diff\n",
    "\n",
    "                atac_out = tf.reduce_sum(tf.reshape(atac_target, [-1,tiling_req]),axis=1,keepdims=True)\n",
    "                diff = tf.math.sqrt(tf.nn.relu(atac_out - 2500.0 * tf.ones(atac_out.shape)))\n",
    "                atac_out = tf.clip_by_value(atac_out, clip_value_min=0.0, clip_value_max=2500.0) + diff\n",
    "                atac_out = tf.slice(atac_out,\n",
    "                                    [crop_size,0],\n",
    "                                    [output_length-2*crop_size,-1])\n",
    "\n",
    "                peaks_gathered = tf.reduce_max(tf.reshape(peaks_crop, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                               axis=1,keepdims=True)\n",
    "                mask_gathered = tf.reduce_max(tf.reshape(full_comb_mask_store, [(output_length-2*crop_size) // 2, -1]),\n",
    "                                               axis=1,keepdims=True)\n",
    "\n",
    "                random_shuffled_tokens= tf.random.experimental.stateless_shuffle(atac,\n",
    "                                                                                 seed=[11,stupid_random_seed+11])\n",
    "                if not use_atac:\n",
    "                    masked_atac = random_shuffled_tokens\n",
    "                if not use_seq:\n",
    "                    sequence = tf.random.experimental.stateless_shuffle(sequence,\n",
    "                                                                        seed=[12,stupid_random_seed+12])\n",
    "\n",
    "\n",
    "                mask_seed = tf.cast(full_comb_mask_store,dtype=tf.int32)*stupid_random_seed + stupid_random_seed2\n",
    "                masked_gathered_seed = tf.cast(mask_gathered,dtype=tf.int32)*stupid_random_seed + stupid_random_seed2\n",
    "\n",
    "                return {'sequence': tf.ensure_shape(sequence,\n",
    "                                                    [input_length,4]),\n",
    "                        'atac': tf.ensure_shape(masked_atac,\n",
    "                                                [output_length_ATAC,1]),\n",
    "                        'mask': tf.ensure_shape(full_comb_mask_store,\n",
    "                                                [output_length-crop_size*2,1]),\n",
    "                        'mask_seed': tf.ensure_shape(mask_seed,\n",
    "                                                [output_length-crop_size*2,1]),\n",
    "                        'mask_gathered': tf.ensure_shape(mask_gathered,\n",
    "                                                [(output_length-crop_size*2)//2,1]),\n",
    "                        'mask_gathered_seed': tf.ensure_shape(masked_gathered_seed,\n",
    "                                                [(output_length-crop_size*2)//2,1]),\n",
    "                        'peaks': tf.ensure_shape(peaks_gathered,\n",
    "                                                  [(output_length-2*crop_size) // 2,1]),\n",
    "                        'target': tf.ensure_shape(atac_out,\n",
    "                                                  [output_length-crop_size*2,1])}\n",
    "\n",
    "\n",
    "            files = tf.data.Dataset.list_files(list_file)\n",
    "\n",
    "            dataset = tf.data.TFRecordDataset(files,\n",
    "                                              compression_type='ZLIB',\n",
    "                                              num_parallel_reads=4)\n",
    "            dataset = dataset.with_options(options)\n",
    "            dataset = dataset.map(lambda record: deserialize_val(record,\n",
    "                                                                262144,\n",
    "                                                                10,\n",
    "                                                                65536,\n",
    "                                                                2048,\n",
    "                                                                256,\n",
    "                                                                128,\n",
    "                                                                 #seq_mask_dropout,\n",
    "                                                                0.10,\n",
    "                                                                1024,\n",
    "                                                                True,\n",
    "                                                               False,\n",
    "                                                               True,\n",
    "                                                                g,h),\n",
    "                          deterministic=False,\n",
    "                          num_parallel_calls=4)\n",
    "\n",
    "            dataset = dataset.batch(64,drop_remainder=True).prefetch(tf.data.AUTOTUNE).repeat()\n",
    "\n",
    "            test_dist = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "            test_it = iter(test_dist)\n",
    "            test_it_build = iter(test_dist)\n",
    "            files_list.append(test_it)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
