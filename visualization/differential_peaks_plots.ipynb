{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65a613e-ecce-4057-8216-a0dc254e6d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 01:55:27.895278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 01:55:28.082927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:55:28.082962: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-24 01:55:29.000305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:55:29.000465: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:55:29.000482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import re\n",
    "import argparse\n",
    "import collections\n",
    "import gzip\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import logging\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "os.environ['TPU_LOAD_LIBRARY']='0'\n",
    "os.environ['TF_ENABLE_EAGER_CLIENT_STREAMING_ENQUEUE']='False'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs\n",
    "from tensorflow.keras import mixed_precision\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy.stats.stats import spearmanr  \n",
    "## custom modules\n",
    "import src.aformer_atac as aformer\n",
    "#import src.aformer_TF as aformer\n",
    "from src.layers.layers import *\n",
    "import src.metrics as metrics\n",
    "from src.optimizers import *\n",
    "import src.schedulers as schedulers\n",
    "import src.utils as utils\n",
    "\n",
    "import training_utils_atac as training_utils\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7f3df-fa0e-460c-af72-e0489ea3d3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 01:55:30.384409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-24 01:55:30.384462: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-24 01:55:30.384489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-genformer-v2-6): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='node-1')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n",
    "\n",
    "with strategy.scope():\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "    options.deterministic=False\n",
    "    #options.experimental_threading.max_intra_op_parallelism = 1\n",
    "    mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    #options.num_devices = 64\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = 1\n",
    "    NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e90bea-4d6a-463c-a990-08f6cba265ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with strategy.scope():\n",
    "\n",
    "model = aformer.aformer(kernel_transformation='relu_kernel_transformation',\n",
    "                        dropout_rate=0.30,\n",
    "                        pointwise_dropout_rate=0.10,\n",
    "                        input_length=262144,\n",
    "                        output_length=2048,\n",
    "                        final_output_length=1536,\n",
    "                        num_heads=8,\n",
    "                        numerical_stabilizer=0.0000001,\n",
    "                        nb_random_features=256,\n",
    "                        max_seq_length=2048,\n",
    "                        rel_pos_bins=2048,\n",
    "                        norm=True,\n",
    "                        BN_momentum=0.90,\n",
    "                        use_rot_emb = True,\n",
    "                        use_mask_pos = False,\n",
    "                        normalize = True,\n",
    "                        num_transformer_layers=6,\n",
    "                        inits_type=\"enformer_performer\",\n",
    "                        load_init=False,\n",
    "                        stable_variant=False,\n",
    "                        freeze_conv_layers=False,\n",
    "                        filter_list_seq=[768,896,1024,1152,1280,1536],\n",
    "                        filter_list_atac=[32,64],\n",
    "                        output_heads=[\"human\",\"mouse\",\"rhesus\",\"rat\"],\n",
    "                        learnable_PE=True)\n",
    "\n",
    "\n",
    "test = tf.ones((1,262144,4)),tf.ones((1,65536,1))#,tf.ones((1,1,1536))\n",
    "model(test,training=False)\n",
    "print('ran test input')\n",
    "#model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_mm_rm_rat_262k_load-True_LR-0.01_T-6_D-0.3_2023-04-18_12:37:42/iteration_24/saved_model\")\n",
    "#model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_262k_load-True_LR-0.01_T-7_D-0.3_2023-04-13_15:39:43/final/saved_model\")\n",
    "model.load_weights(\"gs://picard-testing-176520/genformer_atac_pretrain/models/aformer_hg_262k_load-True_LR-0.01_T-6_D-0.3_2023-04-23_23:48:45/iteration_3/saved_model\")\n",
    "print('loaded weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b8c71-8cb4-49da-bea1-e979de40f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_batch(model, inputs):\n",
    "    return model.predict_on_batch(inputs)\n",
    "\n",
    "from deeplift import dinuc_shuffle\n",
    "@tf.function\n",
    "def contribution_input_grad(model, model_inputs, gradient_mask):\n",
    "    seq, atac =model_inputs\n",
    "    \n",
    "    #seq_shuffled = dinuc_shuffle.dinuc_shuffle(sequence_one_hot, 1)[0]\n",
    "    \n",
    "    gradient_mask = tf.cast(gradient_mask,dtype=tf.float32)\n",
    "    gradient_mask_mass = tf.reduce_sum(gradient_mask)\n",
    "\n",
    "    with tf.GradientTape() as input_grad_tape:\n",
    "        input_grad_tape.watch(seq)\n",
    "        input_grad_tape.watch(atac)\n",
    "        #input_grad_tape.watch(tf_acc)\n",
    "        inputs = seq,atac#,tf_acc\n",
    "        prediction, peaks_pred, embedding, att_matrices = model.predict_on_batch(inputs)\n",
    "        \n",
    "        prediction = tf.cast(prediction[\"human\"],dtype=tf.float32)\n",
    "        gradient_mask = tf.cast(gradient_mask,dtype=tf.float32)\n",
    "        \n",
    "        prediction_mask = tf.reduce_sum(gradient_mask *\n",
    "                                        prediction) / gradient_mask_mass\n",
    "        \n",
    "\n",
    "    input_grads = input_grad_tape.gradient(prediction_mask, inputs)\n",
    "\n",
    "    input_grads_seq = input_grads[0] \n",
    "    input_grads_atac = input_grads[1]\n",
    "\n",
    "    seq_grads = tf.reduce_sum(input_grads_seq[0,:,:] * seq[0,:,:],\n",
    "                              axis=1)\n",
    "\n",
    "    atac_grads = input_grads_atac[0,:,] * atac[0,:,]\n",
    "\n",
    "    return seq_grads, atac_grads, input_grads_seq[0,:,:], \\\n",
    "            prediction, att_matrices, embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5339a-7f09-494c-812c-5f6527feede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(sequence):\n",
    "    '''\n",
    "    convert input string tensor to one hot encoded\n",
    "    will replace all N character with 0 0 0 0\n",
    "    '''\n",
    "    vocabulary = tf.constant(['A', 'C', 'G', 'T'])\n",
    "    mapping = tf.constant([0, 1, 2, 3])\n",
    "\n",
    "    init = tf.lookup.KeyValueTensorInitializer(keys=vocabulary,\n",
    "                                               values=mapping)\n",
    "    table = tf.lookup.StaticHashTable(init, default_value=0)\n",
    "\n",
    "    input_characters = tfs.upper(tfs.unicode_split(sequence, 'UTF-8'))\n",
    "\n",
    "    out = tf.one_hot(table.lookup(input_characters), \n",
    "                      depth = 4, \n",
    "                      dtype=tf.float32)\n",
    "    return out\n",
    "\n",
    "\n",
    "g=tf.random.Generator.from_seed(datetime.now().timestamp())\n",
    "def deserialize_val(serialized_example,\n",
    "                   input_length,\n",
    "                   max_shift,\n",
    "                   output_length_ATAC,\n",
    "                   output_length,\n",
    "                   crop_size,\n",
    "                   output_res,\n",
    "                   atac_mask,\n",
    "                   log_atac,\n",
    "                   g):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    ## parse out feature map\n",
    "    feature_map = {\n",
    "        'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "        'atac': tf.io.FixedLenFeature([], tf.string),\n",
    "        'tss_tokens': tf.io.FixedLenFeature([], tf.string),\n",
    "        'peaks': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    ### stochastic sequence shift and gaussian noise\n",
    "\n",
    "    seq_shift=5\n",
    "    stupid_random_seed = g.uniform([], 0, 10000000,dtype=tf.int32)\n",
    "    input_seq_length = input_length + max_shift\n",
    "    \n",
    "    ## now parse out the actual data\n",
    "    data = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = one_hot(tf.strings.substr(data['sequence'],\n",
    "                                 seq_shift,input_length))\n",
    "    atac = tf.ensure_shape(tf.io.parse_tensor(data['atac'],\n",
    "                                              out_type=tf.float32),\n",
    "                           [output_length_ATAC,1])\n",
    "    peaks = tf.ensure_shape(tf.io.parse_tensor(data['peaks'],\n",
    "                                              out_type=tf.int32),\n",
    "                           [output_length])\n",
    "    peaks_crop = tf.slice(tf.expand_dims(peaks,axis=1),\n",
    "                     [crop_size,0],\n",
    "                     [output_length-2*crop_size,-1])\n",
    "    \n",
    "    atac_target = atac ## store the target\n",
    "\n",
    "    masked_atac = atac * atac_mask\n",
    "    \n",
    "    random_shuffled_tokens= tf.random.experimental.stateless_shuffle(masked_atac, \n",
    "                                                                      seed=[1, stupid_random_seed])\n",
    "    full_comb_mask = (1.0-atac_mask)*random_shuffled_tokens\n",
    "    masked_atac = masked_atac + full_comb_mask\n",
    "    \n",
    "    if log_atac: \n",
    "        masked_atac = tf.math.log1p(masked_atac)\n",
    "        \n",
    "    diff = tf.math.sqrt(tf.nn.relu(masked_atac - 100.0 * tf.ones(masked_atac.shape)))\n",
    "    masked_atac = tf.clip_by_value(masked_atac, clip_value_min=0.0, clip_value_max=100.0) + diff\n",
    "        \n",
    "    atac_out = tf.reduce_sum(tf.reshape(atac_target, [-1,32]),axis=1,keepdims=True)\n",
    "\n",
    "    atac_out = tf.cast(tf.cast(atac_out,dtype=tf.float16),dtype=tf.float32) ### round to be consistent with Enformer\n",
    "    diff = tf.math.sqrt(tf.nn.relu(atac_out - 2500.0 * tf.ones(atac_out.shape)))\n",
    "    atac_out = tf.clip_by_value(atac_out, clip_value_min=0.0, clip_value_max=2500.0) + diff\n",
    "    atac_out = tf.slice(atac_out,\n",
    "                        [crop_size,0],\n",
    "                        [output_length-2*crop_size,-1])\n",
    "\n",
    "        \n",
    "    tss_tokens = tf.ensure_shape(tf.io.parse_tensor(data['tss_tokens'],\n",
    "                                              out_type=tf.int32),\n",
    "                           [output_length-2*crop_size])\n",
    "    tss_tokens=tf.expand_dims(tss_tokens,axis=1)\n",
    "        \n",
    "        \n",
    "    return {'sequence': tf.ensure_shape(sequence,\n",
    "                                        [input_length,4]),\n",
    "            'atac': tf.ensure_shape(masked_atac,\n",
    "                                    [output_length_ATAC,1]),\n",
    "            'tss_tokens': tf.ensure_shape(tss_tokens,\n",
    "                                      [output_length-crop_size*2,1]),\n",
    "            'peaks': tf.ensure_shape(peaks_crop,\n",
    "                                      [output_length-crop_size*2,1]),\n",
    "            'target': tf.ensure_shape(atac_out,\n",
    "                                      [output_length-crop_size*2,1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead5a17-450c-47e9-9b7a-a6eeebf0d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_mask = np.ones((2048,1))\n",
    "for k in tf.range(1022,1024):\n",
    "    atac_mask[k,0] = 0.0\n",
    "#for k in tf.range(1582,1598):\n",
    "#    atac_mask[k,0] = 0.0\n",
    "\n",
    "atac_mask = tf.constant(atac_mask,dtype=tf.float32)\n",
    "\n",
    "atac_mask = tf.reshape(tf.tile(atac_mask, [1,32]),[-1])\n",
    "atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "\n",
    "filenames = [\"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_SINGLE/HG_Jurkat.chr12-9764927-9764966.CD69_promoter.tfr\",\n",
    "             \"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_SINGLE/HG_Jurkat_stim.chr12-9764927-9764966.CD69_promoter.tfr\"]\n",
    "             \n",
    "    \n",
    "seqs_out = []\n",
    "seq_grads_out = []\n",
    "atacs_out = []\n",
    "predictions_out = []\n",
    "targets_out = []\n",
    "full_grads_out = []\n",
    "for file in filenames:\n",
    "    g = tf.random.Generator.from_seed(datetime.now().timestamp())\n",
    "    dataset = tf.data.TFRecordDataset(file,\n",
    "                                      compression_type='ZLIB',\n",
    "                                      num_parallel_reads=4)\n",
    "    dataset = dataset.map(lambda record: deserialize_val(record,\n",
    "                                                         262144,\n",
    "                                                         10,\n",
    "                                                             65536,\n",
    "                                                         2048,\n",
    "                                                         256,\n",
    "                                                         128,\n",
    "                                                         atac_mask,\n",
    "                                                            True,g),\n",
    "                          deterministic=False,\n",
    "                          num_parallel_calls=4)\n",
    "    dataset=dataset.batch(1)\n",
    "    iter_test = iter(dataset)\n",
    "    test = next(iter_test)\n",
    "    inputs = test['sequence'], \\\n",
    "                test['atac']#, \\\n",
    "                    #test['global_acc']\n",
    "\n",
    "    mask = np.zeros((1,1536,1))\n",
    "    for k in range(1536):\n",
    "        if k in range(766,769):\n",
    "            mask[0,k,0]=1\n",
    "\n",
    "    seq_grads, atac_grads,full_grads, prediction,att_matrices,embedding = contribution_input_grad(model,inputs, mask)\n",
    "    \n",
    "    atacs_out.append(test['atac'])\n",
    "    predictions_out.append(prediction)\n",
    "    targets_out.append(test['target'])\n",
    "    seq_grads_out.append(seq_grads)\n",
    "    full_grads_out.append(full_grads)\n",
    "    \n",
    "def plot_tracks(tracks, peaks, start, end, height=1.5):\n",
    "    fig, axes = plt.subplots(len(tracks)+1, 1, figsize=(24, height * (len(tracks)+1)), sharex=True)\n",
    "    for ax, (title, y) in zip(axes, tracks.items()):\n",
    "        ax.fill_between(np.linspace(start, end, num=len(y[0])), y[0],color=y[1])\n",
    "        ax.set_title(title)\n",
    "    axes[-1].imshow(peaks, aspect = \"auto\", cmap=\"viridis\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "#for idx, atacs in enumerate(atacs_out):\n",
    "    \n",
    "tracks={'prediction': (predictions_out[0][0,:,0],'blue'),\n",
    "        'atac_in': (tf.reduce_sum(tf.reshape((tf.math.exp(atacs_out[0][0,:,0])-1.0), [2048,32]),axis=1)[256:-256],'red'),\n",
    "        'target': (targets_out[0][0,:,0],'orange'),\n",
    "        'prediction1': (predictions_out[1][0,:,0],'blue'),\n",
    "        'atac_in1': (tf.reduce_sum(tf.reshape((tf.math.exp(atacs_out[1][0,:,0])-1.0), [2048,32]),axis=1)[256:-256],'red'),\n",
    "        'target1': (targets_out[1][0,:,0],'orange')}\n",
    "        \n",
    "\n",
    "atac_mask_expanded = (1.0 - tf.transpose(tf.slice(tf.expand_dims(tf.reshape(tf.tile(atac_mask,[1,4]),[-1]),axis=1),\n",
    "         [32768,0],[196608,-1])))\n",
    "plot_tracks(tracks, atac_mask_expanded,0,196608)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3557b-8dad-448d-abba-620a8e6ecea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15735b-8a22-4475-b0fe-af9c9b11d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_mask = np.ones((2048,1))\n",
    "for k in tf.range(1022,1024):\n",
    "    atac_mask[k,0] = 0.0\n",
    "#for k in tf.range(1582,1598):\n",
    "#    atac_mask[k,0] = 0.0\n",
    "\n",
    "atac_mask = tf.constant(atac_mask,dtype=tf.float32)\n",
    "\n",
    "atac_mask = tf.reshape(tf.tile(atac_mask, [1,32]),[-1])\n",
    "atac_mask = tf.expand_dims(atac_mask,axis=1)\n",
    "\n",
    "filenames = [\"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_SINGLE/HG_Jurkat.chr12-9764927-9764966.CD69_promoter.tfr\",\n",
    "             \"gs://picard-testing-176520/genformer_atac_pretrain/262k/genformer_atac_pretrain_globalacc_conv_rpgc_SINGLE/HG_Jurkat_stim.chr12-9764927-9764966.CD69_promoter.tfr\"]\n",
    "             \n",
    "    \n",
    "seqs_out = []\n",
    "seq_grads_out = []\n",
    "atacs_out = []\n",
    "predictions_out = []\n",
    "targets_out = []\n",
    "full_grads_out = []\n",
    "for file in filenames:\n",
    "    g = tf.random.Generator.from_seed(datetime.now().timestamp())\n",
    "    dataset = tf.data.TFRecordDataset(file,\n",
    "                                      compression_type='ZLIB',\n",
    "                                      num_parallel_reads=4)\n",
    "    dataset = dataset.map(lambda record: deserialize_val(record,\n",
    "                                                         262144,\n",
    "                                                         10,\n",
    "                                                             65536,\n",
    "                                                         2048,\n",
    "                                                         256,\n",
    "                                                         128,\n",
    "                                                         atac_mask,\n",
    "                                                            True,g),\n",
    "                          deterministic=False,\n",
    "                          num_parallel_calls=4)\n",
    "    dataset=dataset.batch(1)\n",
    "    iter_test = iter(dataset)\n",
    "    test = next(iter_test)\n",
    "    inputs = test['sequence'], \\\n",
    "                test['atac']#, \\\n",
    "                    #test['global_acc']\n",
    "\n",
    "    mask = np.zeros((1,1536,1))\n",
    "    for k in range(1536):\n",
    "        if k in range(766,769):\n",
    "            mask[0,k,0]=1\n",
    "\n",
    "    seq_grads, atac_grads,full_grads, prediction,att_matrices,embedding = contribution_input_grad(model,inputs, mask)\n",
    "    \n",
    "    atacs_out.append(test['atac'])\n",
    "    predictions_out.append(prediction)\n",
    "    targets_out.append(test['target'])\n",
    "    seq_grads_out.append(seq_grads)\n",
    "    full_grads_out.append(full_grads)\n",
    "    \n",
    "def plot_tracks(tracks, peaks, start, end, height=1.5):\n",
    "    fig, axes = plt.subplots(len(tracks)+1, 1, figsize=(24, height * (len(tracks)+1)), sharex=True)\n",
    "    for ax, (title, y) in zip(axes, tracks.items()):\n",
    "        ax.fill_between(np.linspace(start, end, num=len(y[0])), y[0],color=y[1])\n",
    "        ax.set_title(title)\n",
    "    axes[-1].imshow(peaks, aspect = \"auto\", cmap=\"viridis\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "#for idx, atacs in enumerate(atacs_out):\n",
    "    \n",
    "tracks={'prediction': (predictions_out[0][0,:,0],'blue'),\n",
    "        'atac_in': (tf.reduce_sum(tf.reshape((tf.math.exp(atacs_out[0][0,:,0])-1.0), [2048,32]),axis=1)[256:-256],'red'),\n",
    "        'target': (targets_out[0][0,:,0],'orange'),\n",
    "        #'prediction1': (predictions_out[1][0,:,0],'blue'),\n",
    "        #'atac_in1': (tf.reduce_sum(tf.reshape(atacs_out[1][0,:,0], [2048,32]),axis=1)[256:-256],'red'),\n",
    "        #'target1': (targets_out[1][0,:,0],'orange'),\n",
    "        'prediction2': (predictions_out[1][0,:,0],'blue'),\n",
    "        'atac_in2': (tf.reduce_sum(tf.reshape((tf.math.exp(atacs_out[1][0,:,0])-1.0), [2048,32]),axis=1)[256:-256],'red'),\n",
    "        'target2': (targets_out[1][0,:,0],'orange')}\n",
    "        \n",
    "\n",
    "atac_mask_expanded = (1.0 - tf.transpose(tf.slice(tf.expand_dims(tf.reshape(tf.tile(atac_mask,[1,4]),[-1]),axis=1),\n",
    "         [32768,0],[196608,-1])))\n",
    "plot_tracks(tracks, atac_mask_expanded,0,196608)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
